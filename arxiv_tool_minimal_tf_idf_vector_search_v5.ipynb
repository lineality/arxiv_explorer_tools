{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba77c8fe-bdc2-4e48-91f2-a942055118eb"
      },
      "source": [
        "# Arxiv Explorer Tools - minimal TF-IDF Vector Search\n",
        "- extract articles on topics of interest from the too-many-to-look-through loads of articles that come out each day.\n",
        "- saves results to json and html\n",
        "- minimal TF-IDF is vanilla python (no additional packages or libraries)\n",
        "- arxiv reading uses 'beautiful soup'\n",
        "- various classic distance metrics use:\n",
        "    - scikit-learn\n",
        "    - scipy\n",
        "    - numpy\n",
        "\n",
        "### Setup & Install:\n",
        "- have python installed and use an python env\n",
        "- use a jupyter notebook or script, etc.\n",
        "\n",
        "\n",
        "## Note:\n",
        "- This is more portable than an embedding model but it is just as slow.\n",
        "- In theory distance search can be used in the vector space, in reality it is not good enough to use.\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11e7a29-5a13-4c90-b3a3-f4409a9013b2"
      },
      "source": [
        "\n",
        "- https://pypi.org/project/beautifulsoup4/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdea8fa-7a5d-4d32-a88b-1b1f8619e1b3"
      },
      "source": [
        "requirements.txt ->\n",
        "```\n",
        "scikit-learn\n",
        "scipy\n",
        "numpy\n",
        "beautifulsoup4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4c5c9be-949c-4c72-b2cf-b26df5316aa2",
        "outputId": "5b082c8d-fcb1-4409-ad55-1dde950b8449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run -> 0_min__0.0_sec\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "end_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "def duration_min_sec(start_time, end_time):\n",
        "\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    duration_seconds = duration.total_seconds()\n",
        "\n",
        "    minutes = int(duration_seconds // 60)\n",
        "    seconds = duration_seconds % 60\n",
        "    time_message = f\"{minutes}_min__{seconds:.1f}_sec\"\n",
        "\n",
        "    return time_message\n",
        "\n",
        "duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "print(f\"Duration to run -> {duration_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ba7382b1-3c53-411a-a348-fe4e60a34e6f"
      },
      "outputs": [],
      "source": [
        "# step 1: make corpus vector-matrix\n",
        "# step 2: get vector of the search-phrase\n",
        "# step 3: get vector of  each text\n",
        "# step 4: get scores\n",
        "# step 5: evaluates if score is succss or fail\n",
        "# step 6: if success: do stuff with text, else: move on"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minimal weighted matching"
      ],
      "metadata": {
        "id": "SOMfhOwlr-zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # import math\n",
        "# # from collections import Counter\n",
        "\n",
        "\n",
        "# # And an even more simplistic basic key word search (with optional weights)\n",
        "\n",
        "# import re\n",
        "\n",
        "# def rank_documents_on_weighted_matches(documents, keyword_weights):\n",
        "#     \"\"\"\n",
        "#     Ranks documents based on the presence of weighted keywords-phrases.\n",
        "#     comparison looks at text without:\n",
        "#     - captialization\n",
        "#     - spaces\n",
        "#     - newlines\n",
        "#     - special symbols\n",
        "\n",
        "#     Parameters:\n",
        "#     documents (list of str): The list of documents to be ranked.\n",
        "#     keyword_weights (list of tuple): A list of tuples, where the first element is the keyword and the\n",
        "#     second element is the corresponding weight.\n",
        "\n",
        "#     Returns:\n",
        "#     list of (str, float): A list of tuples, where the first element is the document and the\n",
        "#     second element is the ranking score.\n",
        "#     \"\"\"\n",
        "\n",
        "#     ranked_documents = []\n",
        "\n",
        "#     for document in documents:\n",
        "#         score = 0\n",
        "#         # Make the document lowercase and strip all symbols, spaces, and newline characters\n",
        "#         match_document = re.sub(r'[^\\w\\s]', '', document.lower()).replace('\\n', '').replace(' ','')\n",
        "#         # print(match_document)\n",
        "#         for keyword, weight in keyword_weights:\n",
        "\n",
        "#             # Make the keyword lowercase and strip all symbols, spaces, and newline characters\n",
        "#             match_keyword = re.sub(r'[^\\w\\s]', '', keyword.lower()).replace('\\n', '').replace(' ','')\n",
        "#             # print(match_keyword)\n",
        "#             # Check if the keyword-phrase is in the document\n",
        "#             if match_keyword in match_document:\n",
        "#                 # If the keyword-phrase is in the document, add its weight to the score\n",
        "#                 score += weight\n",
        "\n",
        "#         ranked_documents.append((document, score))\n",
        "\n",
        "#     # Sort the documents by their ranking scores in descending order\n",
        "#     ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#     return ranked_documents\n",
        "\n",
        "\n",
        "# ################\n",
        "# # Example usage\n",
        "# ################\n",
        "# documents = [\n",
        "#     \"This is the first document about machine learning.\",\n",
        "#     \"The second document discusses data analysis and visualization.\",\n",
        "#     \"The third document focuses on natural language processing.\",\n",
        "#     \"The fourth document talks about deep learning and neural networks.\",\n",
        "#     \"\"\"to test line breaks\n",
        "#     Emotion mining\n",
        "#      data\n",
        "#     analysis\n",
        "#     Keywords: emotion mining, sentiment analysis, natural disasters, psychology, technological disasters\"\"\",\n",
        "# ]\n",
        "\n",
        "# keyword_weights = [(\"machine learning\", 3), (\"data analysis\", 2), (\"natural language processing\", 4), (\"deep learning\", 5), (\"neural networks\", 6)]\n",
        "\n",
        "# ranked_documents = rank_documents_on_weighted_matches(documents, keyword_weights)\n",
        "\n",
        "# for document, score in ranked_documents:\n",
        "#     print(f\"Document: {document}\\nScore: {score}\\n\")\n"
      ],
      "metadata": {
        "id": "bqy_ZPvpr-6o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arxiv Explorerer\n"
      ],
      "metadata": {
        "id": "YepU-A4Fr_J3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "19bd0781-5480-4ec0-9709-07330763fd06"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Arxiv Explorerer\n",
        "###################\n",
        "\n",
        "# step 1: embed the search-phrase\n",
        "# step 2: embed each text\n",
        "# step 3: get scores\n",
        "# step 4: evaluates if score is succss or fail\n",
        "# step 5: if success: do stuff with text\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "# ##########################################\n",
        "# # Make comparison phrase and vectorize it\n",
        "# ##########################################\n",
        "# comparison_phrase = \"computer vision resolution enhancement\"\n",
        "# # comparison_phrase = \"cyber security\"\n",
        "# # comparison_phrase = \"natural language processing\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hght1gb699Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Article Corpus"
      ],
      "metadata": {
        "id": "ItIQ_onG-IXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_segment_time = datetime.now()\n",
        "\n",
        "#####################\n",
        "# Get Article Corpus\n",
        "#####################\n",
        "\n",
        "# List to hold all article data\n",
        "article_data = []\n",
        "\n",
        "# # Make a request to the website\n",
        "r = requests.get('https://arxiv.org/list/cs/new')\n",
        "\n",
        "url = \"https://arxiv.org/list/cs/new\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# # Find all the articles\n",
        "articles = soup.find_all('dt')\n",
        "\n",
        "# # Find all the titles\n",
        "articles_title = soup.find_all('div', {'class': 'list-title mathjax'})\n",
        "\n",
        "# Find all the subject on the page\n",
        "articles_subject = soup.find_all('dd')\n",
        "\n",
        "\n",
        "###############\n",
        "# make corpus\n",
        "###############\n",
        "\n",
        "corpus = []\n",
        "report_list = []\n",
        "article_dicts = []\n",
        "\n",
        "for this_index, article in enumerate(articles):\n",
        "\n",
        "    ################################################\n",
        "    # Extract each field of data about each article\n",
        "    ################################################\n",
        "\n",
        "    # Extract the title\n",
        "    title = articles_title[this_index].text.split('Title:')[1].strip()\n",
        "\n",
        "    # Extract the subjects\n",
        "    subjects = articles_subject[this_index].find('span', {'class': 'primary-subject'}).text\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "\n",
        "    abstract_p = article.find_next_sibling('dd').find('p', {'class': 'mathjax'})\n",
        "\n",
        "    # Extract the abstract\n",
        "    if abstract_p:\n",
        "        abstract = abstract_p.text.strip()\n",
        "    else:\n",
        "        abstract = \"\"\n",
        "\n",
        "    pdf_link_segment = article.find('a', {'title': 'Download PDF'})['href']\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "    pdf_link = f\"https://arxiv.org{pdf_link_segment}\"\n",
        "    paper_link = f\"https://arxiv.org/abs/{arxiv_id[6:]}\"\n",
        "\n",
        "    extracted_article_string = title + \" \" + abstract + \" \" + str(subjects)\n",
        "\n",
        "    # assemble corpus\n",
        "    article_characters = \"\"\n",
        "\n",
        "    article_characters += f\"'arxiv_id': {arxiv_id}, \"\n",
        "    article_characters += f\"'paper_link': {paper_link}, \"\n",
        "    article_characters += f\"'pdf_link': {pdf_link}, \"\n",
        "\n",
        "    article_characters += title + \" \"\n",
        "    article_characters += subjects + \" \"\n",
        "    article_characters += abstract\n",
        "\n",
        "    ##################################\n",
        "    # Make Bundles (sharing an index)\n",
        "    ##################################\n",
        "\n",
        "    # add to corpus: just the meaningful text\n",
        "    corpus.append(extracted_article_string)\n",
        "\n",
        "    # add to simple report_list: includes link and article ID info\n",
        "    report_list.append(article_characters)\n",
        "\n",
        "    # Append the data to the list\n",
        "    article_dicts.append({\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'paper_link': paper_link,\n",
        "        'pdf_link': pdf_link,\n",
        "        'subjects': subjects,\n",
        "        'arxiv_id': arxiv_id,\n",
        "    })\n",
        "\n",
        "    # using this because only basic search works\n",
        "    corpus = report_list\n",
        "\n",
        "\n",
        "# # Segment Timer\n",
        "# start_segment_time = datetime.now()\n",
        "end_segment_time = datetime.now()\n",
        "duration_time = duration_min_sec(start_segment_time, end_segment_time)\n",
        "print(f\"Duration to run segment -> {duration_time}\")"
      ],
      "metadata": {
        "id": "e8FPqO0u-IXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0308a9c7-d23b-4f4a-a0c3-7dccd3199834"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run segment -> 0_min__3.5_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of corpus)\n",
        "len(corpus)"
      ],
      "metadata": {
        "id": "bve1wNfDBC-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5126a2e8-30a3-4fc7-d144-3fb669449387"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1221"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of report_list)\n",
        "len(report_list)"
      ],
      "metadata": {
        "id": "5mwhGxD3ESCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbc3bbb-4a80-4f75-b6e4-5c936ed27591"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1221"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (sample of corpus)\n",
        "corpus[0]"
      ],
      "metadata": {
        "id": "Wt_6aZx8EVCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "aee32044-4cd1-41bd-a78c-6e43a93734b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'arxiv_id': arXiv:2407.17471, 'paper_link': https://arxiv.org/abs/2407.17471, 'pdf_link': https://arxiv.org/pdf/2407.17471, Real-Time Automated donning and doffing detection of PPE based on Yolov4-tiny Computer Vision and Pattern Recognition (cs.CV) Maintaining patient safety and the safety of healthcare workers (HCWs) in hospitals and clinics highly depends on following the proper protocol for donning and taking off personal protective equipment (PPE). HCWs can benefit from a feedback system during the putting on and removal process because the process is cognitively demanding and errors are common. Centers for Disease Control and Prevention (CDC) provided guidelines for correct PPE use which should be followed. A real time object detection along with a unique sequencing algorithms are used to identify and determine the donning and doffing process in real time. The purpose of this technical research is two-fold: The user gets real time alert to the step they missed in the sequence if they don't follow the proper procedure during donning or doffing. Secondly, the use of tiny machine learning (yolov4-tiny) in embedded system architecture makes it feasible and cost-effective to deploy in different healthcare settings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (sample of report_list)\n",
        "report_list[0]"
      ],
      "metadata": {
        "id": "qt7IREx_C9g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4ee189bd-01c2-4490-b9fa-5f69e5493b6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'arxiv_id': arXiv:2407.17471, 'paper_link': https://arxiv.org/abs/2407.17471, 'pdf_link': https://arxiv.org/pdf/2407.17471, Real-Time Automated donning and doffing detection of PPE based on Yolov4-tiny Computer Vision and Pattern Recognition (cs.CV) Maintaining patient safety and the safety of healthcare workers (HCWs) in hospitals and clinics highly depends on following the proper protocol for donning and taking off personal protective equipment (PPE). HCWs can benefit from a feedback system during the putting on and removal process because the process is cognitively demanding and errors are common. Centers for Disease Control and Prevention (CDC) provided guidelines for correct PPE use which should be followed. A real time object detection along with a unique sequencing algorithms are used to identify and determine the donning and doffing process in real time. The purpose of this technical research is two-fold: The user gets real time alert to the step they missed in the sequence if they don't follow the proper procedure during donning or doffing. Secondly, the use of tiny machine learning (yolov4-tiny) in embedded system architecture makes it feasible and cost-effective to deploy in different healthcare settings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Model: TF-IDF\n",
        "- olde schoole"
      ],
      "metadata": {
        "id": "kUW5FmNv5qXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"computer vision\""
      ],
      "metadata": {
        "id": "vOyEN_TVE8-S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "454642d6-8675-4b5f-bb4b-78d53c2ecd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62eab510-0704-430d-ba6a-455a4cdf1d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run segment -> 12_min__14.1_sec\n"
          ]
        }
      ],
      "source": [
        "start_segment_time = datetime.now()\n",
        "\"\"\"\n",
        "vanilla_TF-IDF_v8.ipynb\n",
        "\n",
        "This notebook is based on:\n",
        "- https://medium.com/@coldstart_coder/understanding-and-implementing-tf-idf-in-python-a325d1301484\n",
        "- https://www.kaggle.com/code/tylerpoff/understanding-and-implementing-tf-idf-in-python/notebook\n",
        "\n",
        "\n",
        "instructions:\n",
        "1. set query string\n",
        "2. set corpus list of strings\n",
        "3. create TF-IDF vector-matrix (pick an inverse_document_frequency variant)\n",
        "4. search/sort for top-N results: tfidf_vector_search_top_n()\n",
        "5. print results etc.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "\"\"\"# query\"\"\"\n",
        "query = query\n",
        "\n",
        "corpus_unsplit = corpus\n",
        "\n",
        "\n",
        "\n",
        "def term_frequency(word, document):\n",
        "    return document.count(word) / len(document)\n",
        "tf = term_frequency\n",
        "\n",
        "# # non-plus-1 variant (\"unsafe\" variant)\n",
        "# def inverse_document_frequency_unsafe(word, corpus):\n",
        "#     count_of_documents = len(corpus)\n",
        "#     count_of_documents_with_word = sum([1 for doc in corpus if word in doc])\n",
        "#     idf = math.log10(count_of_documents/count_of_documents_with_word)\n",
        "#     return idf\n",
        "\n",
        "# sklearn variant\n",
        "def inverse_document_frequency(word, corpus):\n",
        "    count_of_documents = len(corpus) + 1\n",
        "    # count_of_documents_with_word = sum([1 for doc in corpus if word in doc]) + 1\n",
        "    count_of_documents_with_word = 0\n",
        "\n",
        "    for doc in corpus:\n",
        "        count_of_documents_with_word\n",
        "        # print(f\"doc -> {doc}\")\n",
        "        # print(f\"word -> {word}\")\n",
        "\n",
        "        if word in doc:\n",
        "            # print(f\"count_of_documents_with_word -> {count_of_documents_with_word}\")\n",
        "            count_of_documents_with_word += 1\n",
        "\n",
        "    idf = math.log10(count_of_documents/count_of_documents_with_word) + 1\n",
        "    return idf\n",
        "\n",
        "idf = inverse_document_frequency\n",
        "\n",
        "def TF_IDF(word, document, corpus):\n",
        "    return tf(word, document) * idf(word, corpus)\n",
        "\n",
        "\n",
        "\"\"\"# corpus of documents\"\"\"\n",
        "split_corpus = [c.split() for c in corpus_unsplit]\n",
        "num_documents = len(split_corpus)\n",
        "\n",
        "\n",
        "\"\"\"### Optional Sample Target Word Analysis\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "optional\n",
        "\"\"\"\n",
        "# target_word = \"Expert\"\n",
        "\n",
        "# print(\"searching for the word '%s'\"%target_word)\n",
        "# for i, document in enumerate(split_corpus):\n",
        "#     tf_score = tf(target_word, document)\n",
        "#     idf_score = idf(target_word, split_corpus)\n",
        "#     tf_idf_score = TF_IDF(target_word, document, split_corpus)\n",
        "\n",
        "#     print(\"document %s: '%s'\\n    tf score: %s\\n    idf score: %s\\n    tf_idf score:%s\"%(i, document, tf_score, idf_score, tf_idf_score))\n",
        "#     print(\"-\"*30)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"## word to vector mappings\"\"\"\n",
        "\n",
        "\"\"\"\n",
        " create the word to vector mappings,\n",
        " we want each word to map to a unique point in our word vectors.\n",
        "combine the complete corpus into a single list of words; remove duplicates.\n",
        "use position in this list as the index for a word vector\n",
        "\"\"\"\n",
        "word_set = list(set(sum(split_corpus, [])))\n",
        "# create a lookup for each word to it's index,\n",
        "word_to_index = {word:i for i, word in enumerate(word_set)}\n",
        "\n",
        "num_words = len(word_set)\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "def get_tfidf_vector(query, word_set, split_corpus, word_to_index):\n",
        "\n",
        "    # Create an empty list to store the word vectors\n",
        "    word_vectors = []\n",
        "\n",
        "    # Calculate the TF-IDF score for each word in the query\n",
        "    query_keywords = query.split()\n",
        "    query_vector = [0 for _ in range(len(word_set))]\n",
        "    for word in query_keywords:\n",
        "        if word in word_set:\n",
        "            word_index = word_to_index[word]\n",
        "            query_vector[word_index] = TF_IDF(word, query_keywords, split_corpus)\n",
        "\n",
        "    return query_vector\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"## create the word vectors\"\"\"\n",
        "# create an empty list to store our word vectors\n",
        "word_vectors = []\n",
        "for document in split_corpus:\n",
        "    # for our new document create a new word vector\n",
        "    new_word_vector = [0 for i in range(num_words)]\n",
        "\n",
        "    # now we loop through each word in our document and compute the tf-idf score and populate our vector with it,\n",
        "    # we only care about words in this document because words outside of it will remain zero\n",
        "    for word in document:\n",
        "        # get the score\n",
        "        tf_idf_score = TF_IDF(word, document, split_corpus)\n",
        "        # next get the index for this word in our word vector\n",
        "        word_index = word_to_index[word]\n",
        "        # populate the vector\n",
        "        new_word_vector[word_index] = tf_idf_score\n",
        "\n",
        "    # add new word vector to list of existing word_vectors\n",
        "    word_vectors.append(new_word_vector)\n",
        "\n",
        "\n",
        "\"\"\"## one word vector in comparision to document\"\"\"\n",
        "# # inspection\n",
        "# print(corpus_unsplit[0])\n",
        "# print(word_vectors[0])\n",
        "\n",
        "\n",
        "#############\n",
        "# Exmple Use\n",
        "#############\n",
        "\n",
        "########################################\n",
        "## Searching with TF-IDF Sparse Vectors\n",
        "########################################\n",
        "query_keywords = query.split()\n",
        "\n",
        "# now we loop through each documents word vector, get the tf-idf score for each keyword, sum them up and that is our tf-idf for that document,\n",
        "# we keep track of the best document and return that as our result,\n",
        "tf_idf_scores = []\n",
        "best_document_index = 0\n",
        "best_tf_idf = 0\n",
        "\n",
        "for i, word_vector in enumerate(word_vectors):\n",
        "    document_tf_idf_score_for_query = 0\n",
        "    for word in query_keywords:\n",
        "        # first do a check, does this word appear in our split_corpus of documents?\n",
        "        # if not skip this keyword\n",
        "        if word not in word_set:\n",
        "            continue\n",
        "\n",
        "        # get the index for this keyword and directly pull it from the word vector\n",
        "        word_index = word_to_index[word]\n",
        "        document_tf_idf_score_for_query += word_vector[word_index]\n",
        "    tf_idf_scores.append(document_tf_idf_score_for_query) # keep track of all tf_idf scores, just in case we want to review them,\n",
        "\n",
        "\n",
        "    # # does this tf_idf score for this document beat our previous best?\n",
        "    # if document_tf_idf_score_for_query > best_tf_idf:\n",
        "    #     best_tf_idf = document_tf_idf_score_for_query\n",
        "    #     best_document_index = i\n",
        "\n",
        "\n",
        "\n",
        "# Inspection & Study\n",
        "\n",
        "# from pprint import pprint\n",
        "# # then print out our results\n",
        "# # print(\"results of query: \", query)\n",
        "# print(\"best tf_idf score sum for query: \", best_tf_idf)\n",
        "# print(\"best document: \", corpus_unsplit[best_document_index])\n",
        "# print(\"complete list of tf_idf scores: \", tf_idf_scores)\n",
        "# from pprint import pprint\n",
        "# print(\"tf_idf_scores -> \")\n",
        "# pprint(tf_idf_scores)\n",
        "##  pprint(corpus_unsplit)\n",
        "\n",
        "\n",
        "\n",
        "def tfidf_vector_search_top_n(query, corpus, n):\n",
        "    query_keywords = query.split()\n",
        "\n",
        "    tf_idf_scores = []\n",
        "    for i, word_vector in enumerate(word_vectors):\n",
        "        document_tf_idf_score_for_query = 0\n",
        "        for word in query_keywords:\n",
        "            if word not in word_set:\n",
        "                continue\n",
        "\n",
        "            word_index = word_to_index[word]\n",
        "            document_tf_idf_score_for_query += word_vector[word_index]\n",
        "        tf_idf_scores.append((document_tf_idf_score_for_query, i))\n",
        "\n",
        "    # Sort the TF-IDF scores in descending order\n",
        "    tf_idf_scores.sort(reverse=True)\n",
        "\n",
        "    # Extract the document indices from the top-N results\n",
        "    top_n_document_indices = [index for _, index in tf_idf_scores[:n]]\n",
        "\n",
        "    # Return the top-N documents and their TF-IDF scores\n",
        "    top_n_documents = [corpus[index] for index in top_n_document_indices]\n",
        "    top_n_tf_idf_scores = [score for score, _ in tf_idf_scores[:n]]\n",
        "\n",
        "    return top_n_documents, top_n_tf_idf_scores\n",
        "\n",
        "\n",
        "# # Set This\n",
        "# how_many_results = 5\n",
        "\n",
        "# # Search\n",
        "# top_n = how_many_results\n",
        "# start_time = time.monotonic()  # timer\n",
        "# top_n_documents, top_n_tf_idf_scores = tfidf_vector_search_top_n(query, corpus_unsplit, top_n)\n",
        "# end_time = time.monotonic()  # timer\n",
        "# elapsed_time = end_time - start_time  # timer\n",
        "\n",
        "# print(f\"Top-{top_n} results for query: {query}\")\n",
        "# for i, (document, score) in enumerate(zip(top_n_documents, top_n_tf_idf_scores)):\n",
        "#     print(f\"Result {i+1}:\")\n",
        "#     print(f\"TF-IDF score: {score}\")\n",
        "#     print(f\"Document: {document}\\n\")\n",
        "# # timer\n",
        "# print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "# # Segment Timer\n",
        "# start_segment_time = datetime.now()\n",
        "end_segment_time = datetime.now()\n",
        "duration_time = duration_min_sec(start_segment_time, end_segment_time)\n",
        "print(f\"Duration to run segment -> {duration_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # inspection\n",
        "# print(corpus_unsplit[0])\n",
        "# print(word_vectors[0])"
      ],
      "metadata": {
        "id": "CLFfVc8YN43w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf_vector(query, word_set, split_corpus, word_to_index):\n",
        "\n",
        "    # Create an empty list to store the word vectors\n",
        "    word_vectors = []\n",
        "\n",
        "    # Calculate the TF-IDF score for each word in the query\n",
        "    query_keywords = query.split()\n",
        "    query_vector = [0 for _ in range(len(word_set))]\n",
        "    for word in query_keywords:\n",
        "        if word in word_set:\n",
        "            word_index = word_to_index[word]\n",
        "            query_vector[word_index] = TF_IDF(word, query_keywords, split_corpus)\n",
        "\n",
        "    return query_vector\n"
      ],
      "metadata": {
        "id": "W4LZ5C5BRFLI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Top-N TF-IDF"
      ],
      "metadata": {
        "id": "QXYDuqnGbmf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set This\n",
        "how_many_results = 10\n",
        "\n",
        "# Search\n",
        "top_n = how_many_results\n",
        "start_tfidf_time = time.monotonic()  # timer\n",
        "top_n_documents, top_n_tf_idf_scores = tfidf_vector_search_top_n(query, corpus_unsplit, top_n)\n",
        "end_tfidf_time = time.monotonic()  # timer\n",
        "elapsed_time = end_tfidf_time - start_tfidf_time  # timer\n",
        "\n",
        "print(f\"Top-{top_n} results for query: {query}\")\n",
        "for i, (document, score) in enumerate(zip(top_n_documents, top_n_tf_idf_scores)):\n",
        "    print(f\"Result {i+1}:\")\n",
        "    print(f\"TF-IDF score: {score}\")\n",
        "    print(f\"Document: {document}\\n\")\n",
        "# timer\n",
        "print(f\"Elapsed time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "id": "oWftLrBNFDjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad9b284-323d-482b-a186-d6884ea16e12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 results for query: computer vision\n",
            "Result 1:\n",
            "TF-IDF score: 0.08576801905166966\n",
            "Document: Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies. Computer Vision and Pattern Recognition (cs.CV)\n",
            "\n",
            "Result 2:\n",
            "TF-IDF score: 0.08372592335996323\n",
            "Document: 'arxiv_id': arXiv:2407.17762, 'paper_link': https://arxiv.org/abs/2407.17762, 'pdf_link': https://arxiv.org/pdf/2407.17762, Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data Computer Vision and Pattern Recognition (cs.CV) Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies.\n",
            "\n",
            "Result 3:\n",
            "TF-IDF score: 0.07470185052424322\n",
            "Document: Exploring the Effect of Dataset Diversity in Self-Supervised Learning for Surgical Computer Vision Over the past decade, computer vision applications in minimally invasive surgery have rapidly increased. Despite this growth, the impact of surgical computer vision remains limited compared to other medical fields like pathology and radiology, primarily due to the scarcity of representative annotated data. Whereas transfer learning from large annotated datasets such as ImageNet has been conventionally the norm to achieve high-performing models, recent advancements in self-supervised learning (SSL) have demonstrated superior performance. In medical image analysis, in-domain SSL pretraining has already been shown to outperform ImageNet-based initialization. Although unlabeled data in the field of surgical computer vision is abundant, the diversity within this data is limited. This study investigates the role of dataset diversity in SSL for surgical computer vision, comparing procedure-specific datasets against a more heterogeneous general surgical dataset across three different downstream surgical applications. The obtained results show that using solely procedure-specific data can lead to substantial improvements of 13.8%, 9.5%, and 36.8% compared to ImageNet pretraining. However, extending this data with more heterogeneous surgical data further increases performance by an additional 5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is beneficial for model performance. The code and pretrained model weights are made publicly available at this https URL. Computer Vision and Pattern Recognition (cs.CV)\n",
            "\n",
            "Result 4:\n",
            "TF-IDF score: 0.0727445967987172\n",
            "Document: 'arxiv_id': arXiv:2407.17904, 'paper_link': https://arxiv.org/abs/2407.17904, 'pdf_link': https://arxiv.org/pdf/2407.17904, Exploring the Effect of Dataset Diversity in Self-Supervised Learning for Surgical Computer Vision Computer Vision and Pattern Recognition (cs.CV) Over the past decade, computer vision applications in minimally invasive surgery have rapidly increased. Despite this growth, the impact of surgical computer vision remains limited compared to other medical fields like pathology and radiology, primarily due to the scarcity of representative annotated data. Whereas transfer learning from large annotated datasets such as ImageNet has been conventionally the norm to achieve high-performing models, recent advancements in self-supervised learning (SSL) have demonstrated superior performance. In medical image analysis, in-domain SSL pretraining has already been shown to outperform ImageNet-based initialization. Although unlabeled data in the field of surgical computer vision is abundant, the diversity within this data is limited. This study investigates the role of dataset diversity in SSL for surgical computer vision, comparing procedure-specific datasets against a more heterogeneous general surgical dataset across three different downstream surgical applications. The obtained results show that using solely procedure-specific data can lead to substantial improvements of 13.8%, 9.5%, and 36.8% compared to ImageNet pretraining. However, extending this data with more heterogeneous surgical data further increases performance by an additional 5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is beneficial for model performance. The code and pretrained model weights are made publicly available at this https URL.\n",
            "\n",
            "Result 5:\n",
            "TF-IDF score: 0.057496906574596426\n",
            "Document: Tool-Assisted Learning of Computational Reductions Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science. Computers and Society (cs.CY)\n",
            "\n",
            "Result 6:\n",
            "TF-IDF score: 0.05370590174550217\n",
            "Document: 'arxiv_id': arXiv:2407.18215, 'paper_link': https://arxiv.org/abs/2407.18215, 'pdf_link': https://arxiv.org/pdf/2407.18215, Tool-Assisted Learning of Computational Reductions Computers and Society (cs.CY) Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science.\n",
            "\n",
            "Result 7:\n",
            "TF-IDF score: 0.04567511269944576\n",
            "Document: Improving engagement, diversity, and retention in computer science with RadGrad: Results of a case study RadGrad is a curriculum initiative implemented via an application that combines features of social networks, degree planners, individual learning plans, and serious games. RadGrad redefines traditional meanings of \"progress\" and \"success\" in the undergraduate computer science degree program in an attempt to improve engagement, retention, and diversity. In this paper, we describe the RadGrad Project and report on an evaluation study designed to assess the impact of RadGrad on student engagement, diversity, and retention. We also present opportunities and challenges that result from the use of the system. Computers and Society (cs.CY)\n",
            "\n",
            "Result 8:\n",
            "TF-IDF score: 0.04324988547646634\n",
            "Document: 'arxiv_id': arXiv:2407.17473, 'paper_link': https://arxiv.org/abs/2407.17473, 'pdf_link': https://arxiv.org/pdf/2407.17473, Improving engagement, diversity, and retention in computer science with RadGrad: Results of a case study Computers and Society (cs.CY) RadGrad is a curriculum initiative implemented via an application that combines features of social networks, degree planners, individual learning plans, and serious games. RadGrad redefines traditional meanings of \"progress\" and \"success\" in the undergraduate computer science degree program in an attempt to improve engagement, retention, and diversity. In this paper, we describe the RadGrad Project and report on an evaluation study designed to assess the impact of RadGrad on student engagement, diversity, and retention. We also present opportunities and challenges that result from the use of the system.\n",
            "\n",
            "Result 9:\n",
            "TF-IDF score: 0.03981763063721538\n",
            "Document: Exploring Scaling Trends in LLM Robustness Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses. Machine Learning (cs.LG)\n",
            "\n",
            "Result 10:\n",
            "TF-IDF score: 0.03790638436662905\n",
            "Document: 'arxiv_id': arXiv:2407.18213, 'paper_link': https://arxiv.org/abs/2407.18213, 'pdf_link': https://arxiv.org/pdf/2407.18213, Exploring Scaling Trends in LLM Robustness Machine Learning (cs.LG) Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses.\n",
            "\n",
            "Elapsed time: 0.5433382030000757 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set This\n",
        "how_many_results = 10\n",
        "\n",
        "# Search\n",
        "top_n = how_many_results\n",
        "start_tfidf_time = time.monotonic()  # timer\n",
        "top_n_documents, top_n_tf_idf_scores = tfidf_vector_search_top_n(query, report_list, top_n)\n",
        "end_tfidf_time = time.monotonic()  # timer\n",
        "elapsed_time = end_tfidf_time - start_tfidf_time  # timer\n",
        "\n",
        "print(f\"Top-{top_n} results for query: {query}\")\n",
        "for i, (document, score) in enumerate(zip(top_n_documents, top_n_tf_idf_scores)):\n",
        "    print(f\"Result {i+1}:\")\n",
        "    print(f\"TF-IDF score: {score}\")\n",
        "    print(f\"Document: {document}\\n\")\n",
        "# timer\n",
        "print(f\"Elapsed time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdz49GfXh_Jf",
        "outputId": "05d77a2b-d31d-4e6a-efad-8680b42dda7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 results for query: computer vision\n",
            "Result 1:\n",
            "TF-IDF score: 0.08576801905166966\n",
            "Document: Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies. Computer Vision and Pattern Recognition (cs.CV)\n",
            "\n",
            "Result 2:\n",
            "TF-IDF score: 0.08372592335996323\n",
            "Document: 'arxiv_id': arXiv:2407.17762, 'paper_link': https://arxiv.org/abs/2407.17762, 'pdf_link': https://arxiv.org/pdf/2407.17762, Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data Computer Vision and Pattern Recognition (cs.CV) Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies.\n",
            "\n",
            "Result 3:\n",
            "TF-IDF score: 0.07470185052424322\n",
            "Document: Exploring the Effect of Dataset Diversity in Self-Supervised Learning for Surgical Computer Vision Over the past decade, computer vision applications in minimally invasive surgery have rapidly increased. Despite this growth, the impact of surgical computer vision remains limited compared to other medical fields like pathology and radiology, primarily due to the scarcity of representative annotated data. Whereas transfer learning from large annotated datasets such as ImageNet has been conventionally the norm to achieve high-performing models, recent advancements in self-supervised learning (SSL) have demonstrated superior performance. In medical image analysis, in-domain SSL pretraining has already been shown to outperform ImageNet-based initialization. Although unlabeled data in the field of surgical computer vision is abundant, the diversity within this data is limited. This study investigates the role of dataset diversity in SSL for surgical computer vision, comparing procedure-specific datasets against a more heterogeneous general surgical dataset across three different downstream surgical applications. The obtained results show that using solely procedure-specific data can lead to substantial improvements of 13.8%, 9.5%, and 36.8% compared to ImageNet pretraining. However, extending this data with more heterogeneous surgical data further increases performance by an additional 5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is beneficial for model performance. The code and pretrained model weights are made publicly available at this https URL. Computer Vision and Pattern Recognition (cs.CV)\n",
            "\n",
            "Result 4:\n",
            "TF-IDF score: 0.0727445967987172\n",
            "Document: 'arxiv_id': arXiv:2407.17904, 'paper_link': https://arxiv.org/abs/2407.17904, 'pdf_link': https://arxiv.org/pdf/2407.17904, Exploring the Effect of Dataset Diversity in Self-Supervised Learning for Surgical Computer Vision Computer Vision and Pattern Recognition (cs.CV) Over the past decade, computer vision applications in minimally invasive surgery have rapidly increased. Despite this growth, the impact of surgical computer vision remains limited compared to other medical fields like pathology and radiology, primarily due to the scarcity of representative annotated data. Whereas transfer learning from large annotated datasets such as ImageNet has been conventionally the norm to achieve high-performing models, recent advancements in self-supervised learning (SSL) have demonstrated superior performance. In medical image analysis, in-domain SSL pretraining has already been shown to outperform ImageNet-based initialization. Although unlabeled data in the field of surgical computer vision is abundant, the diversity within this data is limited. This study investigates the role of dataset diversity in SSL for surgical computer vision, comparing procedure-specific datasets against a more heterogeneous general surgical dataset across three different downstream surgical applications. The obtained results show that using solely procedure-specific data can lead to substantial improvements of 13.8%, 9.5%, and 36.8% compared to ImageNet pretraining. However, extending this data with more heterogeneous surgical data further increases performance by an additional 5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is beneficial for model performance. The code and pretrained model weights are made publicly available at this https URL.\n",
            "\n",
            "Result 5:\n",
            "TF-IDF score: 0.057496906574596426\n",
            "Document: Tool-Assisted Learning of Computational Reductions Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science. Computers and Society (cs.CY)\n",
            "\n",
            "Result 6:\n",
            "TF-IDF score: 0.05370590174550217\n",
            "Document: 'arxiv_id': arXiv:2407.18215, 'paper_link': https://arxiv.org/abs/2407.18215, 'pdf_link': https://arxiv.org/pdf/2407.18215, Tool-Assisted Learning of Computational Reductions Computers and Society (cs.CY) Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science.\n",
            "\n",
            "Result 7:\n",
            "TF-IDF score: 0.04567511269944576\n",
            "Document: Improving engagement, diversity, and retention in computer science with RadGrad: Results of a case study RadGrad is a curriculum initiative implemented via an application that combines features of social networks, degree planners, individual learning plans, and serious games. RadGrad redefines traditional meanings of \"progress\" and \"success\" in the undergraduate computer science degree program in an attempt to improve engagement, retention, and diversity. In this paper, we describe the RadGrad Project and report on an evaluation study designed to assess the impact of RadGrad on student engagement, diversity, and retention. We also present opportunities and challenges that result from the use of the system. Computers and Society (cs.CY)\n",
            "\n",
            "Result 8:\n",
            "TF-IDF score: 0.04324988547646634\n",
            "Document: 'arxiv_id': arXiv:2407.17473, 'paper_link': https://arxiv.org/abs/2407.17473, 'pdf_link': https://arxiv.org/pdf/2407.17473, Improving engagement, diversity, and retention in computer science with RadGrad: Results of a case study Computers and Society (cs.CY) RadGrad is a curriculum initiative implemented via an application that combines features of social networks, degree planners, individual learning plans, and serious games. RadGrad redefines traditional meanings of \"progress\" and \"success\" in the undergraduate computer science degree program in an attempt to improve engagement, retention, and diversity. In this paper, we describe the RadGrad Project and report on an evaluation study designed to assess the impact of RadGrad on student engagement, diversity, and retention. We also present opportunities and challenges that result from the use of the system.\n",
            "\n",
            "Result 9:\n",
            "TF-IDF score: 0.03981763063721538\n",
            "Document: Exploring Scaling Trends in LLM Robustness Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses. Machine Learning (cs.LG)\n",
            "\n",
            "Result 10:\n",
            "TF-IDF score: 0.03790638436662905\n",
            "Document: 'arxiv_id': arXiv:2407.18213, 'paper_link': https://arxiv.org/abs/2407.18213, 'pdf_link': https://arxiv.org/pdf/2407.18213, Exploring Scaling Trends in LLM Robustness Machine Learning (cs.LG) Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses.\n",
            "\n",
            "Elapsed time: 0.5303173489999153 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Article Corpus"
      ],
      "metadata": {
        "id": "P3nVA8L69dKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #############\n",
        "# # Write Data\n",
        "# #############\n",
        "\n",
        "# # Posix UTC Seconds\n",
        "# # make readable time\n",
        "# from datetime import datetime, UTC\n",
        "# date_time = datetime.now(UTC)\n",
        "# clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "\n",
        "\n",
        "# # Save the data to a JSON file\n",
        "# with open(f'articles_{clean_timestamp}.json', 'w') as f:\n",
        "#     json.dump(article_data, f)\n",
        "\n",
        "\n",
        "# # Create an HTML file\n",
        "# html = '<html><body>'\n",
        "# for article in article_data:\n",
        "#     html += f'<h2><a href=\"{article[\"paper_link\"]}\">{article[\"title\"]}</a></h2>'\n",
        "#     html += f'<p>{article[\"abstract\"]}</p>'\n",
        "#     html += f'<p>Subjects: \", {str(article[\"subjects\"])}</p>'\n",
        "\n",
        "#     html += f'<a href=\"{article[\"paper_link\"]}\">{article[\"paper_link\"]}</a>'\n",
        "#     html += f'<p>paper link: \", {str(article[\"paper_link\"])}</p>'\n",
        "\n",
        "#     html += f'<a href=\"{article[\"pdf_link\"]}\">{article[\"pdf_link\"]}</a>'\n",
        "#     html += f'<p>pdf link: \", {str(article[\"pdf_link\"])}</p>'\n",
        "\n",
        "#     html += f'<p>arxiv id: \", {str(article[\"arxiv_id\"])}</p>'\n",
        "\n",
        "# html += '</body></html>'\n",
        "\n",
        "\n",
        "# # Save the HTML to a file\n",
        "# with open(f'articles{clean_timestamp}.html', 'w') as f:\n",
        "#     f.write(html)\n",
        "\n",
        "# # Duration time print\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "# duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "# print(f\"Duration to run -> {duration_time}\")\n"
      ],
      "metadata": {
        "id": "jHRKjBJorzVC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "be60f579-19ab-4ec6-ac1c-61d9e3884f57",
        "outputId": "3a45d662-ed7c-4b45-d439-f176f6a47f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'12_min__14.1_sec'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "duration_time"
      ]
    }
  ]
}