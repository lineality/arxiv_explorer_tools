{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "vanilla_TF-IDF_vN.ipynb\n",
        "\n",
        "This notebook is based on:\n",
        "- https://medium.com/@coldstart_coder/understanding-and-implementing-tf-idf-in-python-a325d1301484\n",
        "- https://www.kaggle.com/code/tylerpoff/understanding-and-implementing-tf-idf-in-python/notebook\n",
        "\n",
        "\n",
        "instructions:\n",
        "1. set query string\n",
        "2. set corpus list of strings\n",
        "3. create TF-IDF vector-matrix (pick an inverse_document_frequency variant)\n",
        "4. search/sort for top-N results: tfidf_vector_search_top_n()\n",
        "5. print results etc.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-YuKAIYDw9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query"
      ],
      "metadata": {
        "id": "-3m8B4oBt9IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "machine learning algorithms\n",
        "model building\n",
        "scikit-learn, TensorFlow, and PyTorch.\n",
        "models\n",
        "predictive analytics\n",
        "natural language processing\n",
        "Agile/Scrum\n",
        "sprints\n",
        "stand-ups\n",
        "Jira\n",
        "Confluence\n",
        "Waterfall\n",
        "Kanban\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qpJvEbtKt9Wq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus (documents / text)"
      ],
      "metadata": {
        "id": "_Dk5cT8BuHaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"the Expert\",\n",
        "    \"Proficient in Python programming and data analysis, with experience using libraries such as pandas, NumPy, and matplotlib for data manipulation and visualization. Able to write clean, efficient code and perform complex data analysis tasks.\",\n",
        "    \"Experienced in working with SQL databases, including designing schemas, writing queries, and optimizing database performance. Familiarity with database management systems such as MySQL, PostgreSQL, and Oracle.\",\n",
        "    \"Excellent communication skills, both written and verbal, with the ability to effectively collaborate with team members and stakeholders. Strong interpersonal skills and the ability to work well in a fast-paced, dynamic environment.\",\n",
        "    \"Expert in machine learning algorithms and model building, with experience using tools such as scikit-learn, TensorFlow, and PyTorch. Able to design and implement machine learning models for a variety of applications, including predictive analytics and natural language processing.\",\n",
        "    \"Experience with Agile/Scrum methodologies, including working in sprints, participating in daily stand-ups, and using tools such as Jira and Confluence. Familiarity with other project management methodologies, such as Waterfall and Kanban.\",\n",
        "    \"Proficient in front-end web development, with experience using HTML, CSS, and JavaScript to build responsive, user-friendly websites. Familiarity with front-end frameworks such as React and Angular.\",\n",
        "    \"Strong technical writing skills, with the ability to write clear, concise documentation that is easy for non-technical stakeholders to understand. Experience creating user manuals, technical specifications, and other technical documentation.\",\n",
        "    \"Experienced in using data visualization tools such as Tableau and PowerBI to create interactive dashboards and reports. Able to effectively communicate complex data insights through clear, visually appealing visualizations.\",\n",
        "    \"Experience with cloud platforms such as AWS, Google Cloud, and Azure, including deploying applications, managing infrastructure, and optimizing costs. Familiarity with cloud security best practices and compliance requirements.\",\n",
        "    \"Strong problem-solving skills and attention to detail, with the ability to troubleshoot technical issues and identify root causes. Able to work independently and take ownership of projects from start to finish.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "tSDHrPTZuHi_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla TF-IDF Code"
      ],
      "metadata": {
        "id": "V_PuKZr6sHrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "vanilla_TF-IDF_v8.ipynb\n",
        "\n",
        "This notebook is based on:\n",
        "- https://medium.com/@coldstart_coder/understanding-and-implementing-tf-idf-in-python-a325d1301484\n",
        "- https://www.kaggle.com/code/tylerpoff/understanding-and-implementing-tf-idf-in-python/notebook\n",
        "\n",
        "\n",
        "instructions:\n",
        "1. set query string\n",
        "2. set corpus list of strings\n",
        "3. create TF-IDF vector-matrix (pick an inverse_document_frequency variant)\n",
        "4. search/sort for top-N results: tfidf_vector_search_top_n()\n",
        "5. print results etc.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "\"\"\"# query\"\"\"\n",
        "query = query\n",
        "\n",
        "corpus_unsplit = corpus\n",
        "\n",
        "\n",
        "\n",
        "def term_frequency(word, document):\n",
        "    return document.count(word) / len(document)\n",
        "tf = term_frequency\n",
        "\n",
        "# # non-plus-1 variant (\"unsafe\" variant)\n",
        "# def inverse_document_frequency_unsafe(word, corpus):\n",
        "#     count_of_documents = len(corpus)\n",
        "#     count_of_documents_with_word = sum([1 for doc in corpus if word in doc])\n",
        "#     idf = math.log10(count_of_documents/count_of_documents_with_word)\n",
        "#     return idf\n",
        "\n",
        "# sklearn variant\n",
        "def inverse_document_frequency(word, corpus):\n",
        "    count_of_documents = len(corpus) + 1\n",
        "    count_of_documents_with_word = sum([1 for doc in corpus if word in doc]) + 1\n",
        "    idf = math.log10(count_of_documents/count_of_documents_with_word) + 1\n",
        "    return idf\n",
        "\n",
        "idf = inverse_document_frequency\n",
        "\n",
        "def TF_IDF(word, document, corpus):\n",
        "    return tf(word, document) * idf(word, corpus)\n",
        "\n",
        "\n",
        "\"\"\"# corpus of documents\"\"\"\n",
        "split_corpus = [c.split() for c in corpus_unsplit]\n",
        "num_documents = len(split_corpus)\n",
        "\n",
        "\n",
        "\"\"\"### Optional Sample Target Word Analysis\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "optional\n",
        "\"\"\"\n",
        "# target_word = \"Expert\"\n",
        "\n",
        "# print(\"searching for the word '%s'\"%target_word)\n",
        "# for i, document in enumerate(split_corpus):\n",
        "#     tf_score = tf(target_word, document)\n",
        "#     idf_score = idf(target_word, split_corpus)\n",
        "#     tf_idf_score = TF_IDF(target_word, document, split_corpus)\n",
        "\n",
        "#     print(\"document %s: '%s'\\n    tf score: %s\\n    idf score: %s\\n    tf_idf score:%s\"%(i, document, tf_score, idf_score, tf_idf_score))\n",
        "#     print(\"-\"*30)\n",
        "\n",
        "\"\"\"## word to vector mappings\"\"\"\n",
        "\n",
        "\"\"\"\n",
        " create the word to vector mappings,\n",
        " we want each word to map to a unique point in our word vectors.\n",
        "combine the complete corpus into a single list of words; remove duplicates.\n",
        "use position in this list as the index for a word vector\n",
        "\"\"\"\n",
        "word_set = list(set(sum(split_corpus, [])))\n",
        "# create a lookup for each word to it's index,\n",
        "word_to_index = {word:i for i, word in enumerate(word_set)}\n",
        "\n",
        "num_words = len(word_set)\n",
        "\n",
        "\n",
        "\"\"\"## create the word vectors\"\"\"\n",
        "# create an empty list to store our word vectors\n",
        "word_vectors = []\n",
        "for document in split_corpus:\n",
        "    # for our new document create a new word vector\n",
        "    new_word_vector = [0 for i in range(num_words)]\n",
        "\n",
        "    # now we loop through each word in our document and compute the tf-idf score and populate our vector with it,\n",
        "    # we only care about words in this document because words outside of it will remain zero\n",
        "    for word in document:\n",
        "        # get the score\n",
        "        tf_idf_score = TF_IDF(word, document, split_corpus)\n",
        "        # next get the index for this word in our word vector\n",
        "        word_index = word_to_index[word]\n",
        "        # populate the vector\n",
        "        new_word_vector[word_index] = tf_idf_score\n",
        "\n",
        "    # don't forget to add this new word vector to our list of existing word_vectors\n",
        "    word_vectors.append(new_word_vector)\n",
        "\n",
        "\n",
        "\"\"\"## one word vector in comparision to document\"\"\"\n",
        "# # inspection\n",
        "# print(corpus_unsplit[0])\n",
        "# print(word_vectors[0])\n",
        "\n",
        "\n",
        "\"\"\"## <b>Searching with TF-IDF Sparse Vectors</b>\"\"\"\n",
        "query_keywords = query.split()\n",
        "\n",
        "# now we loop through each documents word vector, get the tf-idf score for each keyword, sum them up and that is our tf-idf for that document,\n",
        "# we keep track of the best document and return that as our result,\n",
        "tf_idf_scores = []\n",
        "best_document_index = 0\n",
        "best_tf_idf = 0\n",
        "\n",
        "for i, word_vector in enumerate(word_vectors):\n",
        "    document_tf_idf_score_for_query = 0\n",
        "    for word in query_keywords:\n",
        "        # first do a check, does this word appear in our split_corpus of documents?\n",
        "        # if not skip this keyword\n",
        "        if word not in word_set:\n",
        "            continue\n",
        "\n",
        "        # get the index for this keyword and directly pull it from the word vector\n",
        "        word_index = word_to_index[word]\n",
        "        document_tf_idf_score_for_query += word_vector[word_index]\n",
        "    tf_idf_scores.append(document_tf_idf_score_for_query) # keep track of all tf_idf scores, just in case we want to review them,\n",
        "\n",
        "    \"\"\"\n",
        "    optional:\n",
        "    top N list...TODO\n",
        "    \"\"\"\n",
        "    # does this tf_idf score for this document beat our previous best?\n",
        "    if document_tf_idf_score_for_query > best_tf_idf:\n",
        "        best_tf_idf = document_tf_idf_score_for_query\n",
        "        best_document_index = i\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Inspection & Study\n",
        "\"\"\"\n",
        "# from pprint import pprint\n",
        "# # then print out our results\n",
        "# # print(\"results of query: \", query)\n",
        "# print(\"best tf_idf score sum for query: \", best_tf_idf)\n",
        "# print(\"best document: \", corpus_unsplit[best_document_index])\n",
        "# print(\"complete list of tf_idf scores: \", tf_idf_scores)\n",
        "# from pprint import pprint\n",
        "# print(\"tf_idf_scores -> \")\n",
        "# pprint(tf_idf_scores)\n",
        "##  pprint(corpus_unsplit)\n",
        "\n",
        "\n",
        "\n",
        "def tfidf_vector_search_top_n(query, corpus, n):\n",
        "    query_keywords = query.split()\n",
        "\n",
        "    tf_idf_scores = []\n",
        "    for i, word_vector in enumerate(word_vectors):\n",
        "        document_tf_idf_score_for_query = 0\n",
        "        for word in query_keywords:\n",
        "            if word not in word_set:\n",
        "                continue\n",
        "\n",
        "            word_index = word_to_index[word]\n",
        "            document_tf_idf_score_for_query += word_vector[word_index]\n",
        "        tf_idf_scores.append((document_tf_idf_score_for_query, i))\n",
        "\n",
        "    # Sort the TF-IDF scores in descending order\n",
        "    tf_idf_scores.sort(reverse=True)\n",
        "\n",
        "    # Extract the document indices from the top-N results\n",
        "    top_n_document_indices = [index for _, index in tf_idf_scores[:n]]\n",
        "\n",
        "    # Return the top-N documents and their TF-IDF scores\n",
        "    top_n_documents = [corpus[index] for index in top_n_document_indices]\n",
        "    top_n_tf_idf_scores = [score for score, _ in tf_idf_scores[:n]]\n",
        "\n",
        "    return top_n_documents, top_n_tf_idf_scores\n"
      ],
      "metadata": {
        "id": "vqBvjyVMsHz5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use TF-IDF"
      ],
      "metadata": {
        "id": "dT7-ZH42qcfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set This\n",
        "how_many_results = 5\n",
        "\n",
        "# Search\n",
        "top_n = how_many_results\n",
        "start_time = time.monotonic()  # timer\n",
        "top_n_documents, top_n_tf_idf_scores = tfidf_vector_search_top_n(query, corpus_unsplit, top_n)\n",
        "end_time = time.monotonic()  # timer\n",
        "elapsed_time = end_time - start_time  # timer\n",
        "\n",
        "print(f\"Top-{top_n} results for query: {query}\")\n",
        "for i, (document, score) in enumerate(zip(top_n_documents, top_n_tf_idf_scores)):\n",
        "    print(f\"Result {i+1}:\")\n",
        "    print(f\"TF-IDF score: {score}\")\n",
        "    print(f\"Document: {document}\\n\")\n",
        "# timer\n",
        "print(f\"Elapsed time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMj3aBXjqeta",
        "outputId": "951f7f4e-eaf4-4c3f-8c13-14f368132ba0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 results for query: \n",
            "machine learning algorithms\n",
            "model building\n",
            "scikit-learn, TensorFlow, and PyTorch.\n",
            "models\n",
            "predictive analytics\n",
            "natural language processing\n",
            "Agile/Scrum\n",
            "sprints\n",
            "stand-ups\n",
            "Jira\n",
            "Confluence\n",
            "Waterfall\n",
            "Kanban\n",
            "\n",
            "Result 1:\n",
            "TF-IDF score: 0.7643492565507526\n",
            "Document: Expert in machine learning algorithms and model building, with experience using tools such as scikit-learn, TensorFlow, and PyTorch. Able to design and implement machine learning models for a variety of applications, including predictive analytics and natural language processing.\n",
            "\n",
            "Result 2:\n",
            "TF-IDF score: 0.2725103043167461\n",
            "Document: Experience with Agile/Scrum methodologies, including working in sprints, participating in daily stand-ups, and using tools such as Jira and Confluence. Familiarity with other project management methodologies, such as Waterfall and Kanban.\n",
            "\n",
            "Result 3:\n",
            "TF-IDF score: 0.12209277186934114\n",
            "Document: Proficient in Python programming and data analysis, with experience using libraries such as pandas, NumPy, and matplotlib for data manipulation and visualization. Able to write clean, efficient code and perform complex data analysis tasks.\n",
            "\n",
            "Result 4:\n",
            "TF-IDF score: 0.11119163152386426\n",
            "Document: Experience with cloud platforms such as AWS, Google Cloud, and Azure, including deploying applications, managing infrastructure, and optimizing costs. Familiarity with cloud security best practices and compliance requirements.\n",
            "\n",
            "Result 5:\n",
            "TF-IDF score: 0.10043115105381288\n",
            "Document: Strong problem-solving skills and attention to detail, with the ability to troubleshoot technical issues and identify root causes. Able to work independently and take ownership of projects from start to finish.\n",
            "\n",
            "Elapsed time: 0.0008130709999818464 seconds\n"
          ]
        }
      ]
    }
  ]
}