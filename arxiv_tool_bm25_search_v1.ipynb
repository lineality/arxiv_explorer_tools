{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YepU-A4Fr_J3",
        "ItIQ_onG-IXX",
        "QXYDuqnGbmf-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba77c8fe-bdc2-4e48-91f2-a942055118eb"
      },
      "source": [
        "# Arxiv Explorer Tools - minimal BM25 Search\n",
        "- extract articles on topics of interest from the too-many-to-look-through loads of articles that come out each day.\n",
        "- saves results to json and html\n",
        "- minimal TF-IDF is vanilla python (no additional packages or libraries)\n",
        "- arxiv reading uses 'beautiful soup'\n",
        "- various classic distance metrics use:\n",
        "    - scikit-learn\n",
        "    - scipy\n",
        "    - numpy\n",
        "\n",
        "### Setup & Install:\n",
        "- have python installed and use an python env\n",
        "- use a jupyter notebook or script, etc.\n",
        "\n",
        "\n",
        "## Note:\n",
        "- Runs in about 2-sec\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11e7a29-5a13-4c90-b3a3-f4409a9013b2"
      },
      "source": [
        "\n",
        "- https://pypi.org/project/beautifulsoup4/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdea8fa-7a5d-4d32-a88b-1b1f8619e1b3"
      },
      "source": [
        "requirements.txt ->\n",
        "```\n",
        "scikit-learn\n",
        "scipy\n",
        "numpy\n",
        "beautifulsoup4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e4c5c9be-949c-4c72-b2cf-b26df5316aa2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "def duration_min_sec(start_time, end_time):\n",
        "\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    duration_seconds = duration.total_seconds()\n",
        "\n",
        "    minutes = int(duration_seconds // 60)\n",
        "    seconds = duration_seconds % 60\n",
        "    time_message = f\"{minutes}_min__{seconds:.1f}_sec\"\n",
        "\n",
        "    return time_message\n",
        "\n",
        "# # start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "# duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "# print(f\"Duration to run -> {duration_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arxiv Explorerer\n"
      ],
      "metadata": {
        "id": "YepU-A4Fr_J3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "19bd0781-5480-4ec0-9709-07330763fd06"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Arxiv Explorerer\n",
        "###################\n",
        "\n",
        "# step 1: embed the search-phrase\n",
        "# step 2: embed each text\n",
        "# step 3: get scores\n",
        "# step 4: evaluates if score is succss or fail\n",
        "# step 5: if success: do stuff with text\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "# ##########################################\n",
        "# # Make comparison phrase and vectorize it\n",
        "# ##########################################\n",
        "# comparison_phrase = \"computer vision resolution enhancement\"\n",
        "# # comparison_phrase = \"cyber security\"\n",
        "# # comparison_phrase = \"natural language processing\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hght1gb699Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Article Corpus"
      ],
      "metadata": {
        "id": "ItIQ_onG-IXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_segment_time = datetime.now()\n",
        "\n",
        "#####################\n",
        "# Get Article Corpus\n",
        "#####################\n",
        "\n",
        "# List to hold all article data\n",
        "article_data = []\n",
        "\n",
        "# # Make a request to the website\n",
        "r = requests.get('https://arxiv.org/list/cs/new')\n",
        "\n",
        "url = \"https://arxiv.org/list/cs/new\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# # Find all the articles\n",
        "articles = soup.find_all('dt')\n",
        "\n",
        "# # Find all the titles\n",
        "articles_title = soup.find_all('div', {'class': 'list-title mathjax'})\n",
        "\n",
        "# Find all the subject on the page\n",
        "articles_subject = soup.find_all('dd')\n",
        "\n",
        "\n",
        "###############\n",
        "# make corpus\n",
        "###############\n",
        "\n",
        "corpus = []\n",
        "report_list = []\n",
        "article_dicts = []\n",
        "\n",
        "for this_index, article in enumerate(articles):\n",
        "\n",
        "    ################################################\n",
        "    # Extract each field of data about each article\n",
        "    ################################################\n",
        "\n",
        "    # Extract the title\n",
        "    title = articles_title[this_index].text.split('Title:')[1].strip()\n",
        "\n",
        "    # Extract the subjects\n",
        "    subjects = articles_subject[this_index].find('span', {'class': 'primary-subject'}).text\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "\n",
        "    abstract_p = article.find_next_sibling('dd').find('p', {'class': 'mathjax'})\n",
        "\n",
        "    # Extract the abstract\n",
        "    if abstract_p:\n",
        "        abstract = abstract_p.text.strip()\n",
        "    else:\n",
        "        abstract = \"\"\n",
        "\n",
        "    pdf_link_segment = article.find('a', {'title': 'Download PDF'})['href']\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "    pdf_link = f\"https://arxiv.org{pdf_link_segment}\"\n",
        "    paper_link = f\"https://arxiv.org/abs/{arxiv_id[6:]}\"\n",
        "\n",
        "    # extracted_article_string = title + \" \" + abstract + \" \" + str(subjects)\n",
        "\n",
        "    # assemble corpus\n",
        "    article_characters = f\"{this_index}|||| \"\n",
        "\n",
        "    article_characters += f\"\\n'arxiv_id': {arxiv_id}, \"\n",
        "    article_characters += f\"\\n'paper_link': {paper_link}, \"\n",
        "    article_characters += f\"\\n'pdf_link': {pdf_link}, \"\n",
        "\n",
        "    article_characters += \"\\nTitle: \" + title + \" \"\n",
        "    article_characters += \"\\nSubjects: \" + subjects + \" \"\n",
        "    article_characters += \"\\nAbstract: \" + abstract\n",
        "\n",
        "    ##################################\n",
        "    # Make Bundles (sharing an index)\n",
        "    ##################################\n",
        "\n",
        "    # # add to corpus: just the meaningful text\n",
        "    # corpus.append(extracted_article_string)\n",
        "\n",
        "    # add to simple report_list: includes link and article ID info\n",
        "    report_list.append(article_characters)\n",
        "\n",
        "    # Append the data to the list\n",
        "    article_dicts.append({\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'paper_link': paper_link,\n",
        "        'pdf_link': pdf_link,\n",
        "        'subjects': subjects,\n",
        "        'arxiv_id': arxiv_id,\n",
        "        'article_sequence_index': this_index,\n",
        "    })\n",
        "\n",
        "    # using this because only basic search works\n",
        "    corpus = report_list\n",
        "\n",
        "\n",
        "# # Segment Timer\n",
        "# start_segment_time = datetime.now()\n",
        "end_segment_time = datetime.now()\n",
        "duration_time = duration_min_sec(start_segment_time, end_segment_time)\n",
        "print(f\"Duration to run segment -> {duration_time}\")"
      ],
      "metadata": {
        "id": "e8FPqO0u-IXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ceef56-00db-4f40-c79b-83fb1e6bb9f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run segment -> 0_min__2.0_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of corpus)\n",
        "len(corpus)"
      ],
      "metadata": {
        "id": "bve1wNfDBC-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9789119-ae8a-4e6c-8be9-23af524a2132"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "611"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of report_list)\n",
        "len(report_list)"
      ],
      "metadata": {
        "id": "5mwhGxD3ESCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33d3bc0-1415-45de-cc2b-95db4ba243a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "611"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (sample of corpus)\n",
        "corpus[0]"
      ],
      "metadata": {
        "id": "Wt_6aZx8EVCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "50af09da-e6f1-4ffd-c915-08dad1bd282a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"0|||| \\n'arxiv_id': arXiv:2407.17471, \\n'paper_link': https://arxiv.org/abs/2407.17471, \\n'pdf_link': https://arxiv.org/pdf/2407.17471, \\nTitle: Real-Time Automated donning and doffing detection of PPE based on Yolov4-tiny \\nSubjects: Computer Vision and Pattern Recognition (cs.CV) \\nAbstract: Maintaining patient safety and the safety of healthcare workers (HCWs) in hospitals and clinics highly depends on following the proper protocol for donning and taking off personal protective equipment (PPE). HCWs can benefit from a feedback system during the putting on and removal process because the process is cognitively demanding and errors are common. Centers for Disease Control and Prevention (CDC) provided guidelines for correct PPE use which should be followed. A real time object detection along with a unique sequencing algorithms are used to identify and determine the donning and doffing process in real time. The purpose of this technical research is two-fold: The user gets real time alert to the step they missed in the sequence if they don't follow the proper procedure during donning or doffing. Secondly, the use of tiny machine learning (yolov4-tiny) in embedded system architecture makes it feasible and cost-effective to deploy in different healthcare settings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (sample of report_list)\n",
        "report_list[0]"
      ],
      "metadata": {
        "id": "qt7IREx_C9g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "90d8bb91-a7c8-402c-ede3-bf6b65f3beb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"0|||| \\n'arxiv_id': arXiv:2407.17471, \\n'paper_link': https://arxiv.org/abs/2407.17471, \\n'pdf_link': https://arxiv.org/pdf/2407.17471, \\nTitle: Real-Time Automated donning and doffing detection of PPE based on Yolov4-tiny \\nSubjects: Computer Vision and Pattern Recognition (cs.CV) \\nAbstract: Maintaining patient safety and the safety of healthcare workers (HCWs) in hospitals and clinics highly depends on following the proper protocol for donning and taking off personal protective equipment (PPE). HCWs can benefit from a feedback system during the putting on and removal process because the process is cognitively demanding and errors are common. Centers for Disease Control and Prevention (CDC) provided guidelines for correct PPE use which should be followed. A real time object detection along with a unique sequencing algorithms are used to identify and determine the donning and doffing process in real time. The purpose of this technical research is two-fold: The user gets real time alert to the step they missed in the sequence if they don't follow the proper procedure during donning or doffing. Secondly, the use of tiny machine learning (yolov4-tiny) in embedded system architecture makes it feasible and cost-effective to deploy in different healthcare settings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Model: TF-IDF\n",
        "- olde schoole"
      ],
      "metadata": {
        "id": "kUW5FmNv5qXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BM25 Code\n"
      ],
      "metadata": {
        "id": "QXYDuqnGbmf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "https://www.cs.otago.ac.nz/homepages/andrew/papers/2014-2.pdf\n",
        "    BM25: https://www.cs.otago.ac.nz/homepages/andrew/papers/2014-2.pdf\n",
        "    https://github.com/dorianbrown/rank_bm25\n",
        "    https://github.com/dorianbrown/rank_bm25/blob/master/rank_bm25.py\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "\"\"\"\n",
        "All of these algorithms have been taken from the paper:\n",
        "Trotmam et al, Improvements to BM25 and Language Models Examined\n",
        "\n",
        "Here we implement all the BM25 variations mentioned.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BM25:\n",
        "    def __init__(self, corpus, tokenizer=None):\n",
        "        self.corpus_size = 0\n",
        "        self.avgdl = 0\n",
        "        self.doc_freqs = []\n",
        "        self.idf = {}\n",
        "        self.doc_len = []\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if tokenizer:\n",
        "            corpus = self._tokenize_corpus(corpus)\n",
        "\n",
        "        nd = self._initialize(corpus)\n",
        "        self._calc_idf(nd)\n",
        "\n",
        "    def _initialize(self, corpus):\n",
        "        nd = {}  # word -> number of documents with word\n",
        "        num_doc = 0\n",
        "        for document in corpus:\n",
        "            self.doc_len.append(len(document))\n",
        "            num_doc += len(document)\n",
        "\n",
        "            frequencies = {}\n",
        "            for word in document:\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 0\n",
        "                frequencies[word] += 1\n",
        "            self.doc_freqs.append(frequencies)\n",
        "\n",
        "            for word, freq in frequencies.items():\n",
        "                try:\n",
        "                    nd[word]+=1\n",
        "                except KeyError:\n",
        "                    nd[word] = 1\n",
        "\n",
        "            self.corpus_size += 1\n",
        "\n",
        "        self.avgdl = num_doc / self.corpus_size\n",
        "        return nd\n",
        "\n",
        "    def _tokenize_corpus(self, corpus):\n",
        "        pool = Pool(cpu_count())\n",
        "        tokenized_corpus = pool.map(self.tokenizer, corpus)\n",
        "        return tokenized_corpus\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_top_n(self, query, documents, n=5):\n",
        "\n",
        "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "\n",
        "        scores = self.get_scores(query)\n",
        "        top_n = np.argsort(scores)[::-1][:n]\n",
        "        return [documents[i] for i in top_n]\n",
        "\n",
        "\n",
        "class BM25Okapi(BM25):\n",
        "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.epsilon = epsilon\n",
        "        super().__init__(corpus, tokenizer)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        \"\"\"\n",
        "        Calculates frequencies of terms in documents and in corpus.\n",
        "        This algorithm sets a floor on the idf values to eps * average_idf\n",
        "        \"\"\"\n",
        "        # collect idf sum to calculate an average idf for epsilon value\n",
        "        idf_sum = 0\n",
        "        # collect words with negative idf to set them a special epsilon value.\n",
        "        # idf can be negative if word is contained in more than half of documents\n",
        "        negative_idfs = []\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "            self.idf[word] = idf\n",
        "            idf_sum += idf\n",
        "            if idf < 0:\n",
        "                negative_idfs.append(word)\n",
        "        self.average_idf = idf_sum / len(self.idf)\n",
        "\n",
        "        eps = self.epsilon * self.average_idf\n",
        "        for word in negative_idfs:\n",
        "            self.idf[word] = eps\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        \"\"\"\n",
        "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
        "        this algorithm also adds a floor to the idf value of epsilon.\n",
        "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
        "        :param query:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        \"\"\"\n",
        "        Calculate bm25 scores between query and subset of all docs\n",
        "        \"\"\"\n",
        "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
        "        score = np.zeros(len(doc_ids))\n",
        "        doc_len = np.array(self.doc_len)[doc_ids]\n",
        "        for q in query:\n",
        "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score.tolist()\n",
        "\n",
        "\n",
        "class BM25L(BM25):\n",
        "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=0.5):\n",
        "        # Algorithm specific parameters\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.delta = delta\n",
        "        super().__init__(corpus, tokenizer)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log(self.corpus_size + 1) - math.log(freq + 0.5)\n",
        "            self.idf[word] = idf\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
        "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
        "                     (self.k1 + ctd + self.delta)\n",
        "        return score\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        \"\"\"\n",
        "        Calculate bm25 scores between query and subset of all docs\n",
        "        \"\"\"\n",
        "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
        "        score = np.zeros(len(doc_ids))\n",
        "        doc_len = np.array(self.doc_len)[doc_ids]\n",
        "        for q in query:\n",
        "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
        "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
        "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
        "                     (self.k1 + ctd + self.delta)\n",
        "        return score.tolist()\n",
        "\n",
        "\n",
        "class BM25Plus(BM25):\n",
        "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=1):\n",
        "        # Algorithm specific parameters\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.delta = delta\n",
        "        super().__init__(corpus, tokenizer)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log(self.corpus_size + 1) - math.log(freq)\n",
        "            self.idf[word] = idf\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
        "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
        "        return score\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        \"\"\"\n",
        "        Calculate bm25 scores between query and subset of all docs\n",
        "        \"\"\"\n",
        "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
        "        score = np.zeros(len(doc_ids))\n",
        "        doc_len = np.array(self.doc_len)[doc_ids]\n",
        "        for q in query:\n",
        "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
        "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
        "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
        "        return score.tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "BM25Adpt and BM25T are a bit more complicated than the previous algorithms here. Here a term-specific k1\n",
        "parameter is calculated before scoring is done\n",
        "\"\"\"\n",
        "\n",
        "class BM25Adpt(BM25):\n",
        "    def __init__(self, corpus, k1=1.5, b=0.75, delta=1):\n",
        "        # Algorithm specific parameters\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.delta = delta\n",
        "        super().__init__(corpus)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log((self.corpus_size + 1) / freq)\n",
        "            self.idf[word] = idf\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
        "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
        "        return score\n",
        "\n",
        "    def get_top_n(self, query, documents, n=5):\n",
        "\n",
        "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "\n",
        "        scores = self.get_scores(query)\n",
        "        top_n = np.argsort(scores)[::-1][:n]\n",
        "        return [documents[i] for i in top_n]\n",
        "\n",
        "class BM25T(BM25):\n",
        "    def __init__(self, corpus, k1=1.5, b=0.75, delta=1):\n",
        "        # Algorithm specific parameters\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.delta = delta\n",
        "        super().__init__(corpus)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log((self.corpus_size + 1) / freq)\n",
        "            self.idf[word] = idf\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
        "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
        "        return score\n",
        "\n",
        "\n",
        "    def get_top_n(self, query, documents, n=5):\n",
        "\n",
        "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "\n",
        "        scores = self.get_scores(query)\n",
        "        top_n = np.argsort(scores)[::-1][:n]\n",
        "        return [documents[i] for i in top_n]"
      ],
      "metadata": {
        "id": "cVVdHuRSwHGm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Use BM-25"
      ],
      "metadata": {
        "id": "ySJ9rWcnrz2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"computer vision\""
      ],
      "metadata": {
        "id": "vOyEN_TVE8-S"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set This\n",
        "how_many_results = 5\n",
        "\n",
        "# Preprocessing Text\n",
        "start_time = time.monotonic()  # timer\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)  # Create a BM25 object\n",
        "tokenized_query = query.split(\" \")  # Tokenize the query\n",
        "\n",
        "# Search\n",
        "top_n = bm25.get_top_n(tokenized_query, corpus, n=how_many_results)\n",
        "end_time = time.monotonic()  # timer\n",
        "elapsed_time = end_time - start_time   # timer\n",
        "\n",
        "# Print\n",
        "for i in top_n:\n",
        "    print(i)\n",
        "    print(\"\\n\")\n",
        "# timer\n",
        "print(f\"Elapsed time: {elapsed_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdlK4k8ir0G_",
        "outputId": "0e60ec45-257d-448e-d989-059e805d3b19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137|||| \n",
            "'arxiv_id': arXiv:2407.17762, \n",
            "'paper_link': https://arxiv.org/abs/2407.17762, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.17762, \n",
            "Title: Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies.\n",
            "\n",
            "\n",
            "203|||| \n",
            "'arxiv_id': arXiv:2407.17904, \n",
            "'paper_link': https://arxiv.org/abs/2407.17904, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.17904, \n",
            "Title: Exploring the Effect of Dataset Diversity in Self-Supervised Learning for Surgical Computer Vision \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Over the past decade, computer vision applications in minimally invasive surgery have rapidly increased. Despite this growth, the impact of surgical computer vision remains limited compared to other medical fields like pathology and radiology, primarily due to the scarcity of representative annotated data. Whereas transfer learning from large annotated datasets such as ImageNet has been conventionally the norm to achieve high-performing models, recent advancements in self-supervised learning (SSL) have demonstrated superior performance. In medical image analysis, in-domain SSL pretraining has already been shown to outperform ImageNet-based initialization. Although unlabeled data in the field of surgical computer vision is abundant, the diversity within this data is limited. This study investigates the role of dataset diversity in SSL for surgical computer vision, comparing procedure-specific datasets against a more heterogeneous general surgical dataset across three different downstream surgical applications. The obtained results show that using solely procedure-specific data can lead to substantial improvements of 13.8%, 9.5%, and 36.8% compared to ImageNet pretraining. However, extending this data with more heterogeneous surgical data further increases performance by an additional 5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is beneficial for model performance. The code and pretrained model weights are made publicly available at this https URL.\n",
            "\n",
            "\n",
            "9|||| \n",
            "'arxiv_id': arXiv:2407.17480, \n",
            "'paper_link': https://arxiv.org/abs/2407.17480, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.17480, \n",
            "Title: Universal Approximation Theory: The basic theory for deep learning-based computer vision models \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Computer vision (CV) is one of the most crucial fields in artificial intelligence. In recent years, a variety of deep learning models based on convolutional neural networks (CNNs) and Transformers have been designed to tackle diverse problems in CV. These algorithms have found practical applications in areas such as robotics and facial recognition. Despite the increasing power of current CV models, several fundamental questions remain unresolved: Why do CNNs require deep layers? What ensures the generalization ability of CNNs? Why do residual-based networks outperform fully convolutional networks like VGG? What is the fundamental difference between residual-based CNNs and Transformer-based networks? Why can CNNs utilize LoRA and pruning techniques? The root cause of these questions lies in the lack of a robust theoretical foundation for deep learning models in CV. To address these critical issues and techniques, we employ the Universal Approximation Theorem (UAT) to provide a theoretical basis for convolution- and Transformer-based models in CV. By doing so, we aim to elucidate these questions from a theoretical perspective.\n",
            "\n",
            "\n",
            "323|||| \n",
            "'arxiv_id': arXiv:2407.18213, \n",
            "'paper_link': https://arxiv.org/abs/2407.18213, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.18213, \n",
            "Title: Exploring Scaling Trends in LLM Robustness \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses.\n",
            "\n",
            "\n",
            "321|||| \n",
            "'arxiv_id': arXiv:2407.18207, \n",
            "'paper_link': https://arxiv.org/abs/2407.18207, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.18207, \n",
            "Title: Geometry Fidelity for Spherical Images \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Spherical or omni-directional images offer an immersive visual format appealing to a wide range of computer vision applications. However, geometric properties of spherical images pose a major challenge for models and metrics designed for ordinary 2D images. Here, we show that direct application of FrÃ©chet Inception Distance (FID) is insufficient for quantifying geometric fidelity in spherical images. We introduce two quantitative metrics accounting for geometric constraints, namely Omnidirectional FID (OmniFID) and Discontinuity Score (DS). OmniFID is an extension of FID tailored to additionally capture field-of-view requirements of the spherical format by leveraging cubemap projections. DS is a kernel-based seam alignment score of continuity across borders of 2D representations of spherical images. In experiments, OmniFID and DS quantify geometry fidelity issues that are undetected by FID.\n",
            "\n",
            "\n",
            "Elapsed time: 0.13774290699998915 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Article Corpus"
      ],
      "metadata": {
        "id": "P3nVA8L69dKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "be60f579-19ab-4ec6-ac1c-61d9e3884f57",
        "outputId": "771b19b4-6e71-4f32-bcb0-1a93a4ea2a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0_min__2.0_sec'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "duration_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "adbdeb05-8327-46a1-b64b-85973fc763ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1d4ba7-911c-4a26-9702-f9daa3202317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run -> 0_min__2.3_sec\n"
          ]
        }
      ],
      "source": [
        "# start_time_whole_single_task = datetime.now()\n",
        "end_time_whole_single_task = datetime.now()\n",
        "duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "print(f\"Duration to run -> {duration_time}\")"
      ]
    }
  ]
}