{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SOMfhOwlr-zu",
        "MaYRyhUgm1ol"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba77c8fe-bdc2-4e48-91f2-a942055118eb"
      },
      "source": [
        "# Arxiv Explorer Tools - minimal weighted match\n",
        "- Fast: ~5-10 sec to run vs. 5-10 min for embedding or TFIDF versions.\n",
        "- multi-topic: use as many pre-set seaches as you want\n",
        "- extracts articles on topics of interest from the too-many-to-look-through daily pages of articles that come out each day.\n",
        "- saves results to json (for automation later) and html (for easy reading and linking)\n",
        "- minimal weighted match uses a list of phrases and an integer weight for each\n",
        "- arxiv reading uses 'beautiful soup'\n",
        "\n",
        "### Setup & Install:\n",
        "- have python installed and use an python env\n",
        "- use a jupyter notebook or script, etc.\n",
        "- for specialty topics you can create extensive weighted search profiles.\n",
        "\n",
        "### See:\n",
        "- https://medium.com/@GeoffreyGordonAshbrook/search-with-non-generative-ai-d0a3cc77164b\n",
        "- https://github.com/lineality/arxiv_explorer_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11e7a29-5a13-4c90-b3a3-f4409a9013b2"
      },
      "source": [
        "\n",
        "- https://pypi.org/project/beautifulsoup4/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdea8fa-7a5d-4d32-a88b-1b1f8619e1b3"
      },
      "source": [
        "requirements.txt ->\n",
        "```\n",
        "scikit-learn\n",
        "scipy\n",
        "numpy\n",
        "beautifulsoup4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4c5c9be-949c-4c72-b2cf-b26df5316aa2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "def duration_min_sec(start_time, end_time):\n",
        "\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    duration_seconds = duration.total_seconds()\n",
        "\n",
        "    minutes = int(duration_seconds // 60)\n",
        "    seconds = duration_seconds % 60\n",
        "    time_message = f\"{minutes}_min__{seconds:.1f}_sec\"\n",
        "\n",
        "    return time_message\n",
        "\n",
        "# # start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "# duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "# print(f\"Duration to run -> {duration_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minimal weighted matching code"
      ],
      "metadata": {
        "id": "SOMfhOwlr-zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "# from collections import Counter\n",
        "\n",
        "\n",
        "# And an even more simplistic basic key word search (with optional weights)\n",
        "\n",
        "import re\n",
        "\n",
        "def rank_documents_on_weighted_matches(documents, keyword_weights):\n",
        "    \"\"\"\n",
        "    Ranks documents based on the presence of weighted keywords-phrases.\n",
        "    comparison looks at text without:\n",
        "    - captialization\n",
        "    - spaces\n",
        "    - newlines\n",
        "    - special symbols\n",
        "\n",
        "    Parameters:\n",
        "    documents (list of str): The list of documents to be ranked.\n",
        "    keyword_weights (list of tuple): A list of tuples, where the first element is the keyword and the\n",
        "    second element is the corresponding weight.\n",
        "\n",
        "    Returns:\n",
        "    list of (str, float): A list of tuples, where the first element is the document and the\n",
        "    second element is the ranking score.\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    string cleaning steps:\n",
        "    - lower\n",
        "    - strip extra spaces\n",
        "    - remove symbols\n",
        "    - remove newlines\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ranked_documents = []\n",
        "\n",
        "    for document in documents:\n",
        "        score = 0\n",
        "        # Make the document lowercase and strip all symbols, spaces, and newline characters\n",
        "        match_this_cleaned_document = re.sub(r'[^\\w\\s]', '', document.lower()).replace('\\n', '').replace(' ','')\n",
        "        # print(match_this_cleaned_document)\n",
        "        for keyword, weight in keyword_weights:\n",
        "\n",
        "            # Make the keyword lowercase and strip all symbols, spaces, and newline characters\n",
        "            match_this_cleaned_keyword = re.sub(r'[^\\w\\s]', '', keyword.lower()).replace('\\n', '').replace(' ','')\n",
        "            # print(match_this_cleaned_keyword)\n",
        "            # Check if the keyword-phrase is in the document\n",
        "            if match_this_cleaned_keyword in match_this_cleaned_document:\n",
        "                # If the keyword-phrase is in the document, add its weight to the score\n",
        "                score += weight\n",
        "\n",
        "        ranked_documents.append((document, score))\n",
        "\n",
        "    # Sort the documents by their ranking scores in descending order\n",
        "    ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return ranked_documents\n",
        "\n",
        "\n",
        "# ################\n",
        "# # Example usage\n",
        "# ################\n",
        "# corpus = [\n",
        "#     \"This is the first document about machine learning.\",\n",
        "#     \"The second document discusses data analysis and visualization.\",\n",
        "#     \"The third document focuses on natural language processing.\",\n",
        "#     \"The fourth document talks about deep learning and neural networks.\",\n",
        "#     \"\"\"to test line breaks\n",
        "#     Emotion mining\n",
        "#      data\n",
        "#     analysis\n",
        "#     Keywords: emotion mining, sentiment analysis, natural disasters, psychology, technological disasters\"\"\",\n",
        "# ]\n",
        "\n",
        "# keyword_weights = [(\"machine learning\", 3), (\"data analysis\", 2), (\"natural language processing\", 4), (\"deep learning\", 5), (\"neural networks\", 6)]\n",
        "\n",
        "# ranked_documents = rank_documents_on_weighted_matches(corpus, keyword_weights)\n",
        "\n",
        "# for document, score in ranked_documents:\n",
        "#     print(f\"Document: {document}\\nScore: {score}\\n\")\n"
      ],
      "metadata": {
        "id": "bqy_ZPvpr-6o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arxiv Explorerer\n"
      ],
      "metadata": {
        "id": "YepU-A4Fr_J3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "19bd0781-5480-4ec0-9709-07330763fd06"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Arxiv Explorerer\n",
        "###################\n",
        "\n",
        "# step 1: embed the search-phrase\n",
        "# step 2: embed each text\n",
        "# step 3: get scores\n",
        "# step 4: evaluates if score is succss or fail\n",
        "# step 5: if success: do stuff with text\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "# ##########################################\n",
        "# # Make comparison phrase and vectorize it\n",
        "# ##########################################\n",
        "# comparison_phrase = \"computer vision resolution enhancement\"\n",
        "# # comparison_phrase = \"cyber security\"\n",
        "# # comparison_phrase = \"natural language processing\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Article Corpus"
      ],
      "metadata": {
        "id": "ItIQ_onG-IXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_segment_time = datetime.now()\n",
        "\n",
        "#####################\n",
        "# Get Article Corpus\n",
        "#####################\n",
        "\n",
        "# List to hold all article data\n",
        "article_data = []\n",
        "\n",
        "# # Make a request to the website\n",
        "r = requests.get('https://arxiv.org/list/cs/new')\n",
        "\n",
        "url = \"https://arxiv.org/list/cs/new\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# # Find all the articles\n",
        "articles = soup.find_all('dt')\n",
        "\n",
        "# # Find all the titles\n",
        "articles_title = soup.find_all('div', {'class': 'list-title mathjax'})\n",
        "\n",
        "# Find all the subject on the page\n",
        "articles_subject = soup.find_all('dd')\n",
        "\n",
        "\n",
        "###############\n",
        "# make corpus\n",
        "###############\n",
        "\n",
        "corpus = []\n",
        "report_list = []\n",
        "article_dicts = []\n",
        "\n",
        "for this_index, article in enumerate(articles):\n",
        "\n",
        "    ################################################\n",
        "    # Extract each field of data about each article\n",
        "    ################################################\n",
        "\n",
        "    # Extract the title\n",
        "    title = articles_title[this_index].text.split('Title:')[1].strip()\n",
        "\n",
        "    # Extract the subjects\n",
        "    subjects = articles_subject[this_index].find('span', {'class': 'primary-subject'}).text\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "\n",
        "    abstract_p = article.find_next_sibling('dd').find('p', {'class': 'mathjax'})\n",
        "\n",
        "    # Extract the abstract\n",
        "    if abstract_p:\n",
        "        abstract = abstract_p.text.strip()\n",
        "    else:\n",
        "        abstract = \"\"\n",
        "\n",
        "    pdf_link_segment = article.find('a', {'title': 'Download PDF'})['href']\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "    pdf_link = f\"https://arxiv.org{pdf_link_segment}\"\n",
        "    paper_link = f\"https://arxiv.org/abs/{arxiv_id[6:]}\"\n",
        "\n",
        "    # extracted_article_string = title + \" \" + abstract + \" \" + str(subjects)\n",
        "\n",
        "    # assemble corpus\n",
        "    article_characters = f\"{this_index}|||| \"\n",
        "\n",
        "    article_characters += f\"\\n'arxiv_id': {arxiv_id}, \"\n",
        "    article_characters += f\"\\n'paper_link': {paper_link}, \"\n",
        "    article_characters += f\"\\n'pdf_link': {pdf_link}, \"\n",
        "\n",
        "    article_characters += \"\\nTitle: \" + title + \" \"\n",
        "    article_characters += \"\\nSubjects: \" + subjects + \" \"\n",
        "    article_characters += \"\\nAbstract: \" + abstract\n",
        "\n",
        "    ##################################\n",
        "    # Make Bundles (sharing an index)\n",
        "    ##################################\n",
        "\n",
        "    # # add to corpus: just the meaningful text\n",
        "    # corpus.append(extracted_article_string)\n",
        "\n",
        "    # add to simple report_list: includes link and article ID info\n",
        "    report_list.append(article_characters)\n",
        "\n",
        "    # Append the data to the list\n",
        "    article_dicts.append({\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'paper_link': paper_link,\n",
        "        'pdf_link': pdf_link,\n",
        "        'subjects': subjects,\n",
        "        'arxiv_id': arxiv_id,\n",
        "        'article_sequence_index': this_index,\n",
        "    })\n",
        "\n",
        "    # using this because only basic search works\n",
        "    corpus = report_list\n",
        "\n",
        "\n",
        "# # Segment Timer\n",
        "# start_segment_time = datetime.now()\n",
        "end_segment_time = datetime.now()\n",
        "duration_time = duration_min_sec(start_segment_time, end_segment_time)\n",
        "print(f\"Duration to run segment -> {duration_time}\")\n",
        "\n",
        "# ALL Save the data to a JSON file\n",
        "date_time = datetime.now()\n",
        "all_article_dicts_clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "with open(f'all_arxiv_article_dicts_{all_article_dicts_clean_timestamp}.json', 'a') as f:\n",
        "    json.dump(article_dicts, f)"
      ],
      "metadata": {
        "id": "e8FPqO0u-IXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4ff206-0a89-4afa-c154-b4e4664ae013"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run segment -> 0_min__9.0_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of corpus)\n",
        "len(corpus)"
      ],
      "metadata": {
        "id": "bve1wNfDBC-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f024e43c-a64e-4c0a-c6b7-e1278764abe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1099"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# print and save: code"
      ],
      "metadata": {
        "id": "WPnLaV3fpCkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "########################################\n",
        "# Filter, Save, & Print the Raw Results\n",
        "########################################\n",
        "# ALL Save the data to a JSON file\n",
        "date_time = datetime.now()\n",
        "all_arxiv_results_clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "all_articles_list = []\n",
        "all_results_json_list = []\n",
        "\n",
        "def result_counter(ranked_documents):\n",
        "    \"\"\"\n",
        "    count non-zero scored results\n",
        "    \"\"\"\n",
        "\n",
        "    result_count = 0\n",
        "\n",
        "    for this_doc in ranked_documents:\n",
        "        score = this_doc[1]\n",
        "\n",
        "        if score != 0:\n",
        "            result_count += 1\n",
        "\n",
        "    return result_count\n",
        "\n",
        "\n",
        "\n",
        "def score_filtered_result_counter(ranked_documents, score_floor=0):\n",
        "    \"\"\"\n",
        "    count non-zero scored results that are greater than or equal to score_floor\n",
        "    \"\"\"\n",
        "\n",
        "    result_count = 0\n",
        "\n",
        "    for this_doc in ranked_documents:\n",
        "        score = this_doc[1]\n",
        "\n",
        "        if score != 0 and score >= score_floor:\n",
        "            result_count += 1\n",
        "\n",
        "    return result_count\n",
        "\n",
        "\n",
        "def print_and_save(ranked_documents, top_n, name_of_set, score_floor=5):\n",
        "    # Posix UTC Seconds\n",
        "    # make readable time\n",
        "    # from datetime import datetime\n",
        "    date_time = datetime.now()\n",
        "    clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    results_json_list = []\n",
        "\n",
        "    for document, score in ranked_documents:\n",
        "\n",
        "        if score >= score_floor:\n",
        "\n",
        "            blurb = f\"Document: {document}\\nScore: {score}\\n\"\n",
        "\n",
        "            print(blurb)\n",
        "\n",
        "        this_index = int(document.split('||||')[0])\n",
        "\n",
        "        data_dict = article_dicts[this_index]\n",
        "\n",
        "        results_json_list.append(data_dict)\n",
        "        all_results_json_list.append(data_dict)\n",
        "\n",
        "        counter += 1\n",
        "        if counter >= top_n:\n",
        "            break\n",
        "\n",
        "    #############\n",
        "    # Write Data\n",
        "    #############\n",
        "\n",
        "    # Save the data to a JSON file\n",
        "    with open(f'{name_of_set}_articles_{clean_timestamp}.json', 'w') as f:\n",
        "        json.dump(results_json_list, f)\n",
        "\n",
        "    # Create an HTML file\n",
        "    html = '<html><body>'\n",
        "    for article in results_json_list:\n",
        "        html += f'<h2><a href=\"{article[\"paper_link\"]}\">{article[\"title\"]}</a></h2>'\n",
        "        html += f'<p>{article[\"abstract\"]}</p>'\n",
        "        html += f'<p>Subjects: {str(article[\"subjects\"])}</p>'\n",
        "\n",
        "        html += f'<a href=\"{article[\"paper_link\"]}\">{article[\"paper_link\"]}</a>'\n",
        "        html += f'<p>paper link: {str(article[\"paper_link\"])}</p>'\n",
        "\n",
        "        html += f'<a href=\"{article[\"pdf_link\"]}\">{article[\"pdf_link\"]}</a>'\n",
        "        html += f'<p>pdf link: {str(article[\"pdf_link\"])}</p>'\n",
        "\n",
        "        html += f'<p>arxiv id: {str(article[\"arxiv_id\"])}</p>'\n",
        "        html += f'<p>article_sequence_index id: {str(article[\"article_sequence_index\"])}</p>'\n",
        "\n",
        "    html += '</body></html>'\n",
        "\n",
        "\n",
        "    # Save the HTML to a file\n",
        "    with open(f'{name_of_set}_articles{clean_timestamp}.html', 'w') as f:\n",
        "        f.write(html)\n",
        "\n",
        "\n",
        "def match_print_save(list_of_lists_of_weights, top_n, score_floor):\n",
        "    date_time = datetime.now()\n",
        "    clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "\n",
        "    counter = 0\n",
        "    for keyword_weights in list_of_lists_of_weights:\n",
        "\n",
        "        ranked_documents = rank_documents_on_weighted_matches(corpus, keyword_weights)\n",
        "\n",
        "        # user first list item as name of set\n",
        "        name_of_set = list_of_lists_of_weights[counter][0][0]\n",
        "\n",
        "        result_quantity = result_counter(ranked_documents)\n",
        "\n",
        "        score_floor_filtered_quantity = score_filtered_result_counter(ranked_documents, score_floor)\n",
        "\n",
        "        this_max_number = top_n\n",
        "\n",
        "        if top_n > result_quantity:\n",
        "            this_max_number = result_quantity\n",
        "\n",
        "        print(f\"\\n\\nSet Name: {name_of_set}\")\n",
        "        print(f\"Total Matches in Set: {result_quantity}\")\n",
        "        print(f\"Matches Above Score-Floor in Set: {score_floor_filtered_quantity}\")\n",
        "        print(clean_timestamp)\n",
        "\n",
        "        print(f\"\\nShowing {score_floor_filtered_quantity} in top-{this_max_number} out of {result_quantity} total results.     -> {score_floor_filtered_quantity} of {this_max_number}/{result_quantity}\")\n",
        "        print(f\"(Ceiling set at {top_n} (top_n) filtered results.)    -> {top_n}\")\n",
        "        print(f\"(Minimum-included-score, 'Score-Floor' set at {score_floor}) -> {score_floor}\\n\\n\")\n",
        "\n",
        "        print_and_save(ranked_documents, top_n, name_of_set, score_floor)\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "        # ALL Save the data to a JSON file\n",
        "        with open(f'all_arxiv_results_{all_arxiv_results_clean_timestamp}.json', 'a') as f:\n",
        "            json.dump(all_results_json_list, f)"
      ],
      "metadata": {
        "id": "peVzbe-Di2xH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set of searches\n",
        "(optional)"
      ],
      "metadata": {
        "id": "MaYRyhUgm1ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ########\n",
        "# # Batch\n",
        "# ########\n",
        "\n",
        "# # example multi-list\n",
        "\n",
        "# list_of_lists_of_weights = [\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"computer vision\", 3),\n",
        "#         (\"resolution\", 2),\n",
        "#         # (\"natural language processing\", 4),\n",
        "#         # (\"deep learning\", 5),\n",
        "#         (\"neural networks\", 6),\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"distance measure\", 10),\n",
        "#         (\"similarity measure\", 10),\n",
        "#         (\"vector distance\", 10),\n",
        "#         (\"distance metric\", 10),\n",
        "#         (\"similarity metric\", 10),\n",
        "#         (\"dimension reduction\", 10),\n",
        "\n",
        "\n",
        "#         (\"similarity\", 1),\n",
        "#         (\"distance\", 1),\n",
        "#         (\"metric\", 1),\n",
        "\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     # (\"cognitive science\", 2),  # much too broad...\n",
        "#     [\n",
        "#         (\"mental health\", 5),\n",
        "#         (\"psychological health\", 5),\n",
        "#         (\"psycholog\", 2),  # stem vs. lemma\n",
        "\n",
        "\n",
        "#         (\"mental health care\", 3),\n",
        "#         (\"neuroscience\", 2),\n",
        "#         (\"psychological assessment\", 2),\n",
        "#         (\"personality assessment\", 2),\n",
        "#         (\"personality inference\", 2),\n",
        "#         (\"personality traits\", 2),\n",
        "#         (\"personality dimensions\", 2),\n",
        "#         (\"emotion\", 15),\n",
        "#         (\"sports psychology\", 15),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "\n",
        "\n",
        "\n",
        "#         # disease terms\n",
        "#         (\"depression\", 5),\n",
        "#         (\"anxiety\", 5),\n",
        "#         (\"mental disorders\", 2),\n",
        "#         (\"social anxiety disorder\", 4),\n",
        "#         (\"mental illness\", 2),\n",
        "#         (\"Major Depressive Disorder\", 2),\n",
        "#         (\"MDD\", 2),\n",
        "#         (\"psychological stressors\", 2),\n",
        "#         (\"cognitive impairment\", 2),\n",
        "#         (\"mci\", 2),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "\n",
        "#         ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     [\n",
        "#         (\"benchmark\", 5),\n",
        "#         (\"model evaluation\", 5),\n",
        "#         (\"test\", 2),\n",
        "#         (\"measure\", 2),\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     [\n",
        "#         (\"training set\", 5),\n",
        "#         (\"synthetic\", 2),\n",
        "#         (\"generate\", 2),\n",
        "#         (\"measure\", 2),\n",
        "#     ],\n",
        "\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"graph\", 5),\n",
        "#         (\"graph generation\", 8),\n",
        "#         (\"subgraph\", 2),\n",
        "#         (\"hierarchical graph\", 2),\n",
        "#         (\"embedding\", 2),\n",
        "#         (\"knowledge graph\", 2),\n",
        "\n",
        "#         (\"graph neural networks\", 2),\n",
        "#         (\"graph representation\", 2),\n",
        "#         (\"node\", 2),\n",
        "#          ## collisions: cryptograph, geograph,\n",
        "#     ],\n",
        "\n",
        "# ]\n",
        "\n",
        "# top_n = 45\n",
        "# score_floor = 3\n",
        "# match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "id": "Sn35USTbt3MM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find top-n articles: use keyword/weights"
      ],
      "metadata": {
        "id": "bt_SeRE_l345"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"Manifold Approximation\", 10),\n",
        "        (\"UMAP\", 10),\n",
        "        (\"Uniform Manifold Approximation and Projection\", 10),\n",
        "        (\"Manifold hypothesis\", 10),\n",
        "        (\"dimensionality reduction\", 10),\n",
        "        (\"dimension reduction\", 10),\n",
        "        (\"dimension reduction technique\", 10),\n",
        "\n",
        "        (\"stress\", 1),\n",
        "        (\"Manifold\", 1),\n",
        "        (\"lower-dimensional\", 1),\n",
        "        (\"visualiz\", 1),\n",
        "        (\"projection\", 1),\n",
        "        (\"project\", 1),\n",
        "        (\"dimensionality\", 1),\n",
        "        (\"reduction\", 1),\n",
        "    ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLOy8bu3elSO",
        "outputId": "84bb6075-86d3-43ee-80cb-4a67c331ad4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: Manifold Approximation\n",
            "Total Matches in Set: 132\n",
            "Matches Above Score-Floor in Set: 30\n",
            "2024-09-10__122809159498\n",
            "\n",
            "Showing 30 in top-45 out of 132 total results.     -> 30 of 45/132\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 946|||| \n",
            "'arxiv_id': arXiv:2408.02761, \n",
            "'paper_link': https://arxiv.org/abs/2408.02761, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.02761, \n",
            "Title: Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (KNN). KNN drastically improved scalability and performance over MD when both were applied to raw and average-pooled bottleneck features.\n",
            "Score: 35\n",
            "\n",
            "Document: 1049|||| \n",
            "'arxiv_id': arXiv:2309.13478, \n",
            "'paper_link': https://arxiv.org/abs/2309.13478, \n",
            "'pdf_link': https://arxiv.org/pdf/2309.13478, \n",
            "Title: CA-PCA: Manifold Dimension Estimation, Adapted for Curvature \n",
            "Subjects: Machine Learning (stat.ML) \n",
            "Abstract: The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.\n",
            "Score: 22\n",
            "\n",
            "Document: 749|||| \n",
            "'arxiv_id': arXiv:2312.14810, \n",
            "'paper_link': https://arxiv.org/abs/2312.14810, \n",
            "'pdf_link': https://arxiv.org/pdf/2312.14810, \n",
            "Title: Accurate, scalable, and efficient Bayesian optimal experimental design with derivative-informed neural operators \n",
            "Subjects: Computational Engineering, Finance, and Science (cs.CE) \n",
            "Abstract: We consider optimal experimental design (OED) problems in selecting the most informative observation sensors to estimate model parameters in a Bayesian framework. Such problems are computationally prohibitive when the parameter-to-observable (PtO) map is expensive to evaluate, the parameters are high-dimensional, and the optimization for sensor selection is combinatorial and high-dimensional. To address these challenges, we develop an accurate, scalable, and efficient computational framework based on derivative-informed neural operators (DINO). We propose to use derivative-informed dimension reduction to reduce the parameter dimensions, based on which we train DINO with derivative information as an accurate and efficient surrogate for the PtO map and its derivative. Moreover, we derive DINO-enabled efficient formulations in computing the maximum a posteriori (MAP) point, the eigenvalues of approximate posterior covariance, and three commonly used optimality criteria for the OED problems. Furthermore, we provide detailed error analysis for the approximations of the MAP point, the eigenvalues, and the optimality criteria. We also propose a modified swapping greedy algorithm for the sensor selection optimization and demonstrate that the proposed computational framework is scalable to preserve the accuracy for increasing parameter dimensions and achieves high computational efficiency, with an over 1000$\\times$ speedup accounting for both offline construction and online evaluation costs, compared to high-fidelity Bayesian OED solutions for a three-dimensional nonlinear convection-diffusion-reaction example with tens of thousands of parameters.\n",
            "Score: 21\n",
            "\n",
            "Document: 603|||| \n",
            "'arxiv_id': arXiv:2409.04922, \n",
            "'paper_link': https://arxiv.org/abs/2409.04922, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04922, \n",
            "Title: Nearest Neighbor CCP-Based Molecular Sequence Analysis \n",
            "Subjects: Genomics (q-bio.GN) \n",
            "Abstract: Molecular sequence analysis is crucial for comprehending several biological processes, including protein-protein interactions, functional annotation, and disease classification. The large number of sequences and the inherently complicated nature of protein structures make it challenging to analyze such data. Finding patterns and enhancing subsequent research requires the use of dimensionality reduction and feature selection approaches. Recently, a method called Correlated Clustering and Projection (CCP) has been proposed as an effective method for biological sequencing data. The CCP technique is still costly to compute even though it is effective for sequence visualization. Furthermore, its utility for classifying molecular sequences is still uncertain. To solve these two problems, we present a Nearest Neighbor Correlated Clustering and Projection (CCP-NN)-based technique for efficiently preprocessing molecular sequence data. To group related molecular sequences and produce representative supersequences, CCP makes use of sequence-to-sequence correlations. As opposed to conventional methods, CCP doesn't rely on matrix diagonalization, therefore it can be applied to a range of machine-learning problems. We estimate the density map and compute the correlation using a nearest-neighbor search technique. We performed molecular sequence classification using CCP and CCP-NN representations to assess the efficacy of our proposed approach. Our findings show that CCP-NN considerably improves classification task accuracy as well as significantly outperforms CCP in terms of computational runtime.\n",
            "Score: 15\n",
            "\n",
            "Document: 289|||| \n",
            "'arxiv_id': arXiv:2409.05135, \n",
            "'paper_link': https://arxiv.org/abs/2409.05135, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05135, \n",
            "Title: Imputation of Time-varying Edge Flows in Graphs by Multilinear Kernel Regression and Manifold Learning \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: This paper extends the recently developed framework of multilinear kernel regression and imputation via manifold learning (MultiL-KRIM) to impute time-varying edge flows in a graph. MultiL-KRIM uses simplicial-complex arguments and Hodge Laplacians to incorporate the graph topology, and exploits manifold-learning arguments to identify latent geometries within features which are modeled as a point-cloud around a smooth manifold embedded in a reproducing kernel Hilbert space (RKHS). Following the concept of tangent spaces to smooth manifolds, linear approximating patches are used to add a collaborative-filtering flavor to the point-cloud approximations. Together with matrix factorizations, MultiL-KRIM effects dimensionality reduction, and enables efficient computations, without any training data or additional information. Numerical tests on real-network time-varying edge flows demonstrate noticeable improvements of MultiL-KRIM over several state-of-the-art schemes.\n",
            "Score: 13\n",
            "\n",
            "Document: 642|||| \n",
            "'arxiv_id': arXiv:2409.05635, \n",
            "'paper_link': https://arxiv.org/abs/2409.05635, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05635, \n",
            "Title: Optimal Projections for Classification with Naive Bayes \n",
            "Subjects: Machine Learning (stat.ML) \n",
            "Abstract: In the Naive Bayes classification model the class conditional densities are estimated as the products of their marginal densities along the cardinal basis directions. We study the problem of obtaining an alternative basis for this factorisation with the objective of enhancing the discriminatory power of the associated classification model. We formulate the problem as a projection pursuit to find the optimal linear projection on which to perform classification. Optimality is determined based on the multinomial likelihood within which probabilities are estimated using the Naive Bayes factorisation of the projected data. Projection pursuit offers the added benefits of dimension reduction and visualisation. We discuss an intuitive connection with class conditional independent components analysis, and show how this is realised visually in practical applications. The performance of the resulting classification models is investigated using a large collection of (162) publicly available benchmark data sets and in comparison with relevant alternatives. We find that the proposed approach substantially outperforms other popular probabilistic discriminant analysis models and is highly competitive with Support Vector Machines.\n",
            "Score: 13\n",
            "\n",
            "Document: 665|||| \n",
            "'arxiv_id': arXiv:2204.00740, \n",
            "'paper_link': https://arxiv.org/abs/2204.00740, \n",
            "'pdf_link': https://arxiv.org/pdf/2204.00740, \n",
            "Title: Path Development Network with Finite-dimensional Lie Group Representation \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Signature, lying at the heart of rough path theory, is a central tool for analysing controlled differential equations driven by irregular paths. Recently it has also found extensive applications in machine learning and data science as a mathematically principled, universal feature that boosts the performance of deep learning-based models in sequential data tasks. It, nevertheless, suffers from the curse of dimensionality when paths are high-dimensional.\n",
            "We propose a novel, trainable path development layer, which exploits representations of sequential data through finite-dimensional Lie groups, thus resulting in dimension reduction. Its backpropagation algorithm is designed via optimization on manifolds. Our proposed layer, analogous to recurrent neural networks (RNN), possesses an explicit, simple recurrent unit that alleviates the gradient issues.\n",
            "Our layer demonstrates its strength in irregular time series modelling. Empirical results on a range of datasets show that the development layer consistently and significantly outperforms signature features on accuracy and dimensionality. The compact hybrid model (stacking one-layer LSTM with the development layer) achieves state-of-the-art against various RNN and continuous time series models. Our layer also enhances the performance of modelling dynamics constrained to Lie groups. Code is available at this https URL.\n",
            "Score: 13\n",
            "\n",
            "Document: 613|||| \n",
            "'arxiv_id': arXiv:2409.05047, \n",
            "'paper_link': https://arxiv.org/abs/2409.05047, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05047, \n",
            "Title: Machine Learning-Based Prediction of Key Genes Correlated to the Subretinal Lesion Severity in a Mouse Model of Age-Related Macular Degeneration \n",
            "Subjects: Genomics (q-bio.GN) \n",
            "Abstract: Age-related macular degeneration (AMD) is a major cause of blindness in older adults, severely affecting vision and quality of life. Despite advances in understanding AMD, the molecular factors driving the severity of subretinal scarring (fibrosis) remain elusive, hampering the development of effective therapies. This study introduces a machine learning-based framework to predict key genes that are strongly correlated with lesion severity and to identify potential therapeutic targets to prevent subretinal fibrosis in AMD. Using an original RNA sequencing (RNA-seq) dataset from the diseased retinas of JR5558 mice, we developed a novel and specific feature engineering technique, including pathway-based dimensionality reduction and gene-based feature expansion, to enhance prediction accuracy. Two iterative experiments were conducted by leveraging Ridge and ElasticNet regression models to assess biological relevance and gene impact. The results highlight the biological significance of several key genes and demonstrate the framework's effectiveness in identifying novel therapeutic targets. The key findings provide valuable insights for advancing drug discovery efforts and improving treatment strategies for AMD, with the potential to enhance patient outcomes by targeting the underlying genetic mechanisms of subretinal lesion development.\n",
            "Score: 12\n",
            "\n",
            "Document: 649|||| \n",
            "'arxiv_id': arXiv:2409.05709, \n",
            "'paper_link': https://arxiv.org/abs/2409.05709, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05709, \n",
            "Title: Real-time optimal control of high-dimensional parametrized systems by deep learning-based reduced order models \n",
            "Subjects: Optimization and Control (math.OC) \n",
            "Abstract: Steering a system towards a desired target in a very short amount of time is challenging from a computational standpoint. Indeed, the intrinsically iterative nature of optimal control problems requires multiple simulations of the physical system to be controlled. Moreover, the control action needs to be updated whenever the underlying scenario undergoes variations. Full-order models based on, e.g., the Finite Element Method, do not meet these requirements due to the computational burden they usually entail. On the other hand, conventional reduced order modeling techniques such as the Reduced Basis method, are intrusive, rely on a linear superimposition of modes, and lack of efficiency when addressing nonlinear time-dependent dynamics. In this work, we propose a non-intrusive Deep Learning-based Reduced Order Modeling (DL-ROM) technique for the rapid control of systems described in terms of parametrized PDEs in multiple scenarios. In particular, optimal full-order snapshots are generated and properly reduced by either Proper Orthogonal Decomposition or deep autoencoders (or a combination thereof) while feedforward neural networks are exploited to learn the map from scenario parameters to reduced optimal solutions. Nonlinear dimensionality reduction therefore allows us to consider state variables and control actions that are both low-dimensional and distributed. After (i) data generation, (ii) dimensionality reduction, and (iii) neural networks training in the offline phase, optimal control strategies can be rapidly retrieved in an online phase for any scenario of interest. The computational speedup and the high accuracy obtained with the proposed approach are assessed on different PDE-constrained optimization problems, ranging from the minimization of energy dissipation in incompressible flows modelled through Navier-Stokes equations to the thermal active cooling in heat transfer.\n",
            "Score: 12\n",
            "\n",
            "Document: 1053|||| \n",
            "'arxiv_id': arXiv:2311.04748, \n",
            "'paper_link': https://arxiv.org/abs/2311.04748, \n",
            "'pdf_link': https://arxiv.org/pdf/2311.04748, \n",
            "Title: Intrinsic Bayesian Cram\\'er-Rao Bound with an Application to Covariance Matrix Estimation \n",
            "Subjects: Statistics Theory (math.ST) \n",
            "Abstract: This paper presents a new performance bound for estimation problems where the parameter to estimate lies in a Riemannian manifold (a smooth manifold endowed with a Riemannian metric) and follows a given prior distribution. In this setup, the chosen Riemannian metric induces a geometry for the parameter manifold, as well as an intrinsic notion of the estimation error measure. Performance bound for such error measure were previously obtained in the non-Bayesian case (when the unknown parameter is assumed to deterministic), and referred to as \\textit{intrinsic} Cramér-Rao bound. The presented result then appears either as: \\textit{a}) an extension of the intrinsic Cramér-Rao bound to the Bayesian estimation framework; \\textit{b}) a generalization of the Van-Trees inequality (Bayesian Cramér-Rao bound) that accounts for the aforementioned geometric structures. In a second part, we leverage this formalism to study the problem of covariance matrix estimation when the data follow a Gaussian distribution, and whose covariance matrix is drawn from an inverse Wishart distribution. Performance bounds for this problem are obtained for both the mean squared error (Euclidean metric) and the natural Riemannian distance for Hermitian positive definite matrices (affine invariant metric). Numerical simulation illustrate that assessing the error with the affine invariant metric is revealing of interesting properties of the maximum a posteriori and minimum mean square error estimator, which are not observed when using the Euclidean metric.\n",
            "Score: 11\n",
            "\n",
            "Document: 910|||| \n",
            "'arxiv_id': arXiv:2407.05453, \n",
            "'paper_link': https://arxiv.org/abs/2407.05453, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.05453, \n",
            "Title: Active Collaborative Visual SLAM exploiting ORB Features \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: In autonomous robotics, a significant challenge involves devising robust solutions for Active Collaborative SLAM (AC-SLAM). This process requires multiple robots to cooperatively explore and map an unknown environment by intelligently coordinating their movements and sensor data acquisition. In this article, we present an efficient visual AC-SLAM method using aerial and ground robots for environment exploration and mapping. We propose an efficient frontiers filtering method that takes into account the common IoU map frontiers and reduces the frontiers for each robot. Additionally, we also present an approach to guide robots to previously visited goal positions to promote loop closure to reduce SLAM uncertainty. The proposed method is implemented in ROS and evaluated through simulations on publicly available datasets and similar methods, achieving an accumulative average of 59% of increase in area coverage.\n",
            "Score: 10\n",
            "\n",
            "Document: 171|||| \n",
            "'arxiv_id': arXiv:2409.04868, \n",
            "'paper_link': https://arxiv.org/abs/2409.04868, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04868, \n",
            "Title: Moment Constraints and Phase Recovery for Multireference Alignment \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: Multireference alignment (MRA) refers to the problem of recovering a signal from noisy samples subject to random circular shifts. Expectation maximization (EM) and variational approaches use statistical modeling to achieve high accuracy at the cost of solving computationally expensive optimization problems. The method of moments, instead, achieves fast reconstructions by utilizing the power spectrum and bispectrum to determine the signal up to shift. Our approach combines the two philosophies by viewing the power spectrum as a manifold on which to constrain the signal. We then maximize the data likelihood function on this manifold with a gradient-based approach to estimate the true signal. Algorithmically, our method involves iterating between template alignment and projections onto the manifold. The method offers increased speed compared to EM and demonstrates improved accuracy over bispectrum-based methods.\n",
            "Score: 3\n",
            "\n",
            "Document: 88|||| \n",
            "'arxiv_id': arXiv:2409.04702, \n",
            "'paper_link': https://arxiv.org/abs/2409.04702, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04702, \n",
            "Title: Mel-RoFormer for Vocal Separation and Vocal Melody Transcription \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Developing a versatile deep neural network to model music audio is crucial in MIR. This task is challenging due to the intricate spectral variations inherent in music signals, which convey melody, harmonics, and timbres of diverse instruments. In this paper, we introduce Mel-RoFormer, a spectrogram-based model featuring two key designs: a novel Mel-band Projection module at the front-end to enhance the model's capability to capture informative features across multiple frequency bands, and interleaved RoPE Transformers to explicitly model the frequency and time dimensions as two separate sequences. We apply Mel-RoFormer to tackle two essential MIR tasks: vocal separation and vocal melody transcription, aimed at isolating singing voices from audio mixtures and transcribing their lead melodies, respectively. Despite their shared focus on singing signals, these tasks possess distinct optimization objectives. Instead of training a unified model, we adopt a two-step approach. Initially, we train a vocal separation model, which subsequently serves as a foundation model for fine-tuning for vocal melody transcription. Through extensive experiments conducted on benchmark datasets, we showcase that our models achieve state-of-the-art performance in both vocal separation and melody transcription tasks, underscoring the efficacy and versatility of Mel-RoFormer in modeling complex music audio signals.\n",
            "Score: 2\n",
            "\n",
            "Document: 112|||| \n",
            "'arxiv_id': arXiv:2409.04751, \n",
            "'paper_link': https://arxiv.org/abs/2409.04751, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04751, \n",
            "Title: Fisheye-GS: Lightweight and Extensible Gaussian Splatting Module for Fisheye Cameras \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Recently, 3D Gaussian Splatting (3DGS) has garnered attention for its high fidelity and real-time rendering. However, adapting 3DGS to different camera models, particularly fisheye lenses, poses challenges due to the unique 3D to 2D projection calculation. Additionally, there are inefficiencies in the tile-based splatting, especially for the extreme curvature and wide field of view of fisheye lenses, which are crucial for its broader real-life applications. To tackle these challenges, we introduce Fisheye-GS.This innovative method recalculates the projection transformation and its gradients for fisheye cameras. Our approach can be seamlessly integrated as a module into other efficient 3D rendering methods, emphasizing its extensibility, lightweight nature, and modular design. Since we only modified the projection component, it can also be easily adapted for use with different camera models. Compared to methods that train after undistortion, our approach demonstrates a clear improvement in visual quality.\n",
            "Score: 2\n",
            "\n",
            "Document: 164|||| \n",
            "'arxiv_id': arXiv:2409.04851, \n",
            "'paper_link': https://arxiv.org/abs/2409.04851, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04851, \n",
            "Title: AdaptiveFusion: Adaptive Multi-Modal Multi-View Fusion for 3D Human Body Reconstruction \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Recent advancements in sensor technology and deep learning have led to significant progress in 3D human body reconstruction. However, most existing approaches rely on data from a specific sensor, which can be unreliable due to the inherent limitations of individual sensing modalities. On the other hand, existing multi-modal fusion methods generally require customized designs based on the specific sensor combinations or setups, which limits the flexibility and generality of these methods. Furthermore, conventional point-image projection-based and Transformer-based fusion networks are susceptible to the influence of noisy modalities and sensor poses. To address these limitations and achieve robust 3D human body reconstruction in various conditions, we propose AdaptiveFusion, a generic adaptive multi-modal multi-view fusion framework that can effectively incorporate arbitrary combinations of uncalibrated sensor inputs. By treating different modalities from various viewpoints as equal tokens, and our handcrafted modality sampling module by leveraging the inherent flexibility of Transformer models, AdaptiveFusion is able to cope with arbitrary numbers of inputs and accommodate noisy modalities with only a single training network. Extensive experiments on large-scale human datasets demonstrate the effectiveness of AdaptiveFusion in achieving high-quality 3D human body reconstruction in various environments. In addition, our method achieves superior accuracy compared to state-of-the-art fusion methods.\n",
            "Score: 2\n",
            "\n",
            "Document: 309|||| \n",
            "'arxiv_id': arXiv:2409.05200, \n",
            "'paper_link': https://arxiv.org/abs/2409.05200, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05200, \n",
            "Title: Lung-DETR: Deformable Detection Transformer for Sparse Lung Nodule Anomaly Detection \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Accurate lung nodule detection for computed tomography (CT) scan imagery is challenging in real-world settings due to the sparse occurrence of nodules and similarity to other anatomical structures. In a typical positive case, nodules may appear in as few as 3% of CT slices, complicating detection. To address this, we reframe the problem as an anomaly detection task, targeting rare nodule occurrences in a predominantly normal dataset. We introduce a novel solution leveraging custom data preprocessing and Deformable Detection Transformer (Deformable- DETR). A 7.5mm Maximum Intensity Projection (MIP) is utilized to combine adjacent lung slices into single images, reducing the slice count and decreasing nodule sparsity. This enhances spatial context, allowing for better differentiation between nodules and other structures such as complex vascular structures and bronchioles. Deformable-DETR is employed to detect nodules, with a custom focal loss function to better handle the imbalanced dataset. Our model achieves state-of-the-art performance on the LUNA16 dataset with an F1 score of 94.2% (95.2% recall, 93.3% precision) on a dataset sparsely populated with lung nodules that is reflective of real-world clinical data.\n",
            "Score: 2\n",
            "\n",
            "Document: 325|||| \n",
            "'arxiv_id': arXiv:2409.05239, \n",
            "'paper_link': https://arxiv.org/abs/2409.05239, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05239, \n",
            "Title: Inner Product Free Krylov Methods for Large-Scale Inverse Problems \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: In this study, we introduce two new Krylov subspace methods for solving rectangular large-scale linear inverse problems. The first approach is a modification of the Hessenberg iterative algorithm that is based off an LU factorization and is therefore referred to as the least squares LU (LSLU) method. The second approach incorporates Tikhonov regularization in an efficient manner; we call this the Hybrid LSLU method. Both methods are inner-product free, making them advantageous for high performance computing and mixed precision arithmetic. Theoretical findings and numerical results show that Hybrid LSLU can be effective in solving large-scale inverse problems and has comparable performance with existing iterative projection methods.\n",
            "Score: 2\n",
            "\n",
            "Document: 405|||| \n",
            "'arxiv_id': arXiv:2409.05407, \n",
            "'paper_link': https://arxiv.org/abs/2409.05407, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05407, \n",
            "Title: KRONC: Keypoint-based Robust Camera Optimization for 3D Car Reconstruction \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The three-dimensional representation of objects or scenes starting from a set of images has been a widely discussed topic for years and has gained additional attention after the diffusion of NeRF-based approaches. However, an underestimated prerequisite is the knowledge of camera poses or, more specifically, the estimation of the extrinsic calibration parameters. Although excellent general-purpose Structure-from-Motion methods are available as a pre-processing step, their computational load is high and they require a lot of frames to guarantee sufficient overlapping among the views. This paper introduces KRONC, a novel approach aimed at inferring view poses by leveraging prior knowledge about the object to reconstruct and its representation through semantic keypoints. With a focus on vehicle scenes, KRONC is able to estimate the position of the views as a solution to a light optimization problem targeting the convergence of keypoints' back-projections to a singular point. To validate the method, a specific dataset of real-world car scenes has been collected. Experiments confirm KRONC's ability to generate excellent estimates of camera poses starting from very coarse initialization. Results are comparable with Structure-from-Motion methods with huge savings in computation. Code and data will be made publicly available.\n",
            "Score: 2\n",
            "\n",
            "Document: 423|||| \n",
            "'arxiv_id': arXiv:2409.05459, \n",
            "'paper_link': https://arxiv.org/abs/2409.05459, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05459, \n",
            "Title: Beyond Flatland: A Geometric Take on Matching Methods for Treatment Effect Estimation \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Matching is a popular approach in causal inference to estimate treatment effects by pairing treated and control units that are most similar in terms of their covariate information. However, classic matching methods completely ignore the geometry of the data manifold, which is crucial to define a meaningful distance for matching, and struggle when covariates are noisy and high-dimensional. In this work, we propose GeoMatching, a matching method to estimate treatment effects that takes into account the intrinsic data geometry induced by existing causal mechanisms among the confounding variables. First, we learn a low-dimensional, latent Riemannian manifold that accounts for uncertainty and geometry of the original input data. Second, we estimate treatment effects via matching in the latent space based on the learned latent Riemannian metric. We provide theoretical insights and empirical results in synthetic and real-world scenarios, demonstrating that GeoMatching yields more effective treatment effect estimators, even as we increase input dimensionality, in the presence of outliers, or in semi-supervised scenarios.\n",
            "Score: 2\n",
            "\n",
            "Document: 455|||| \n",
            "'arxiv_id': arXiv:2409.05528, \n",
            "'paper_link': https://arxiv.org/abs/2409.05528, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05528, \n",
            "Title: A divergence-free projection method for quasiperiodic photonic crystals in three dimensions \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: This paper presents a point-wise divergence-free projection method for numerical approximations of photonic quasicrystals problems. The original three-dimensional quasiperiodic Maxwell's system is transformed into a periodic one in higher dimensions through a variable substitution involving the projection matrix, such that periodic boundary condition can be readily applied. To deal with the intrinsic divergence-free constraint of the Maxwell's equations, we present a quasiperiodic de Rham complex and its associated commuting diagram, based on which a point-wise divergence-free quasiperiodic Fourier spectral basis is proposed. With the help of this basis, we then propose an efficient solution algorithm for the quasiperiodic source problem and conduct its rigorous error estimate. Moreover, by analyzing the decay rate of the Fourier coefficients of the eigenfunctions, we further propose a divergence-free reduced projection method for the quasiperiodic Maxwell eigenvalue problem, which significantly alleviates the computational cost. Several numerical experiments are presented to validate the efficiency and accuracy of the proposed method.\n",
            "Score: 2\n",
            "\n",
            "Document: 539|||| \n",
            "'arxiv_id': arXiv:2409.05771, \n",
            "'paper_link': https://arxiv.org/abs/2409.05771, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05771, \n",
            "Title: Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.\n",
            "Score: 2\n",
            "\n",
            "Document: 549|||| \n",
            "'arxiv_id': arXiv:2409.05791, \n",
            "'paper_link': https://arxiv.org/abs/2409.05791, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05791, \n",
            "Title: Uniform Approximation of Eigenproblems of a Large-Scale Parameter-Dependent Hermitian Matrix \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: We consider the approximation of the smallest eigenvalue of a large parameter-dependent Hermitian matrix over a continuum compact domain. Our approach is based on approximating the smallest eigenvalue by the one obtained by projecting the large matrix onto a suitable small subspace, a practice widely employed in the literature. The projection subspaces are constructed iteratively (to reduce the error of the approximation where it is large) with the addition of the eigenvectors of the parameter-dependent matrix at the parameter values where a surrogate error is maximal. The surrogate error is the gap between the approximation and a lower bound for the smallest eigenvalue proposed in [Sirkovic and Kressner, SIAM J. Matrix Anal. Appl., 37(2), 2016]. Unlike the classical approaches, such as the successive constraint method, that maximize such surrogate errors over a discrete and finite set, we maximize the surrogate error over the continuum of all permissible parameter values globally. We put particular attention to the lower bound, which enables us to formally prove the global convergence of our framework both in finite-dimensional and infinite-dimensional settings. In the second part, we focus on the approximation of the smallest singular value of a large parameter-dependent matrix, in case it is non-Hermitian, and propose another subspace framework to construct a small parameter-dependent non-Hermitian matrix whose smallest singular value approximates the original large-scale smallest singular value. We perform numerical experiments on synthetic examples, as well as on real examples arising from parametric PDEs. The numerical experiments show that the proposed techniques are able to drastically reduce the size of the large parameter-dependent matrix, while ensuring an approximation error for the smallest eigenvalue/singular value below the prescribed tolerance.\n",
            "Score: 2\n",
            "\n",
            "Document: 588|||| \n",
            "'arxiv_id': arXiv:2409.04596, \n",
            "'paper_link': https://arxiv.org/abs/2409.04596, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04596, \n",
            "Title: NeCA: 3D Coronary Artery Tree Reconstruction from Two 2D Projections by Neural Implicit Representation \n",
            "Subjects: Image and Video Processing (eess.IV) \n",
            "Abstract: Cardiovascular diseases (CVDs) are the most common health threats worldwide. 2D x-ray invasive coronary angiography (ICA) remains as the most widely adopted imaging modality for CVDs diagnosis. However, in current clinical practice, it is often difficult for the cardiologists to interpret the 3D geometry of coronary vessels based on 2D planes. Moreover, due to the radiation limit, in general only two angiographic projections are acquired, providing limited information of the vessel geometry and necessitating 3D coronary tree reconstruction based only on two ICA projections. In this paper, we propose a self-supervised deep learning method called NeCA, which is based on implicit neural representation using the multiresolution hash encoder and differentiable cone-beam forward projector layer in order to achieve 3D coronary artery tree reconstruction from two projections. We validate our method using six different metrics on coronary computed tomography angiography data in terms of right coronary artery and left anterior descending respectively. The evaluation results demonstrate that our NeCA method, without 3D ground truth for supervision and large datasets for training, achieves promising performance in both vessel topology preservation and branch-connectivity maintaining compared to the supervised deep learning model.\n",
            "Score: 2\n",
            "\n",
            "Document: 660|||| \n",
            "'arxiv_id': arXiv:2106.15277, \n",
            "'paper_link': https://arxiv.org/abs/2106.15277, \n",
            "'pdf_link': https://arxiv.org/pdf/2106.15277, \n",
            "Title: EPMF: Efficient Perception-aware Multi-sensor Fusion for 3D Semantic Segmentation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: We study multi-sensor fusion for 3D semantic segmentation that is important to scene understanding for many applications, such as autonomous driving and robotics. Existing fusion-based methods, however, may not achieve promising performance due to the vast difference between the two modalities. In this work, we investigate a collaborative fusion scheme called perception-aware multi-sensor fusion (PMF) to effectively exploit perceptual information from two modalities, namely, appearance information from RGB images and spatio-depth information from point clouds. To this end, we project point clouds to the camera coordinate using perspective projection, and process both inputs from LiDAR and cameras in 2D space while preventing the information loss of RGB images. Then, we propose a two-stream network to extract features from the two modalities, separately. The extracted features are fused by effective residual-based fusion modules. Moreover, we introduce additional perception-aware losses to measure the perceptual difference between the two modalities. Last, we propose an improved version of PMF, i.e., EPMF, which is more efficient and effective by optimizing data pre-processing and network architecture under perspective projection. Specifically, we propose cross-modal alignment and cropping to obtain tight inputs and reduce unnecessary computational costs. We then explore more efficient contextual modules under perspective projection and fuse the LiDAR features into the camera stream to boost the performance of the two-stream network. Extensive experiments on benchmark data sets show the superiority of our method. For example, on nuScenes test set, our EPMF outperforms the state-of-the-art method, i.e., RangeFormer, by 0.9% in mIoU. Our source code is available at this https URL.\n",
            "Score: 2\n",
            "\n",
            "Document: 709|||| \n",
            "'arxiv_id': arXiv:2309.04209, \n",
            "'paper_link': https://arxiv.org/abs/2309.04209, \n",
            "'pdf_link': https://arxiv.org/pdf/2309.04209, \n",
            "Title: Computable error bounds for quasi-Monte Carlo using points with non-negative local discrepancy \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: Let $f:[0,1]^d\\to\\mathbb{R}$ be a completely monotone integrand as defined by Aistleitner and Dick (2015) and let points $\\boldsymbol{x}_0,\\dots,\\boldsymbol{x}_{n-1}\\in[0,1]^d$ have a non-negative local discrepancy (NNLD) everywhere in $[0,1]^d$. We show how to use these properties to get a non-asymptotic and computable upper bound for the integral of $f$ over $[0,1]^d$. An analogous non-positive local discrepancy (NPLD) property provides a computable lower bound. It has been known since Gabai (1967) that the two dimensional Hammersley points in any base $b\\ge2$ have non-negative local discrepancy. Using the probabilistic notion of associated random variables, we generalize Gabai's finding to digital nets in any base $b\\ge2$ and any dimension $d\\ge1$ when the generator matrices are permutation matrices. We show that permutation matrices cannot attain the best values of the digital net quality parameter when $d\\ge3$. As a consequence the computable absolutely sure bounds we provide come with less accurate estimates than the usual digital net estimates do in high dimensions. We are also able to construct high dimensional rank one lattice rules that are NNLD. We show that those lattices do not have good discrepancy properties: any lattice rule with the NNLD property in dimension $d\\ge2$ either fails to be projection regular or has all its points on the main diagonal. Complete monotonicity is a very strict requirement that for some integrands can be mitigated via a control variate.\n",
            "Score: 2\n",
            "\n",
            "Document: 740|||| \n",
            "'arxiv_id': arXiv:2311.18799, \n",
            "'paper_link': https://arxiv.org/abs/2311.18799, \n",
            "'pdf_link': https://arxiv.org/pdf/2311.18799, \n",
            "Title: X-InstructBLIP: A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Recent research has achieved significant advancements in visual reasoning tasks through learning image-to-language projections and leveraging the impressive reasoning abilities of Large Language Models (LLMs). This paper introduces an efficient and effective framework that integrates multiple modalities (images, 3D, audio and video) to a frozen LLM and demonstrates an emergent ability for cross-modal reasoning (2+ modality inputs). Our approach explores two distinct projection mechanisms: Q-Formers and Linear Projections (LPs). Through extensive experimentation across all four modalities on 16 benchmarks, we explore both methods and assess their adaptability in integrated and separate cross-modal reasoning. The Q-Former projection demonstrates superior performance in single modality scenarios and adaptability in joint versus discriminative reasoning involving two or more modalities. However, it exhibits lower generalization capabilities than linear projection in contexts where task-modality data are limited. To enable this framework, we devise a scalable pipeline that automatically generates high-quality, instruction-tuning datasets from readily available captioning data across different modalities, and contribute 24K QA data for audio and 250K QA data for 3D. To facilitate further research in cross-modal reasoning, we introduce the DisCRn (Discriminative Cross-modal Reasoning) benchmark comprising 9K audio-video QA samples and 28K image-3D QA samples that require the model to reason discriminatively across disparate input modalities.\n",
            "Score: 2\n",
            "\n",
            "Document: 815|||| \n",
            "'arxiv_id': arXiv:2404.06841, \n",
            "'paper_link': https://arxiv.org/abs/2404.06841, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.06841, \n",
            "Title: Projection method for quasiperiodic elliptic equations and application to quasiperiodic homogenization \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: In this study, our main objective is to address the challenge of solving elliptic equations with quasiperiodic coefficients. To achieve accurate and efficient computation, we introduce the projection method, which enables the embedding of quasiperiodic systems into higher-dimensional periodic systems. To enhance the computational efficiency, we propose a compressed storage strategy for the stiffness matrix by its multi-level block circulant structure, significantly reducing memory requirements. Furthermore, we design a diagonal preconditioner to efficiently solve the resulting high-dimensional linear system by reducing the condition number of the stiffness matrix. These techniques collectively contribute to the computational effectiveness of our proposed approach. Convergence analysis shows the spectral accuracy of our proposed method. We demonstrate the effectiveness and accuracy of our approach through a series of numerical examples. Moreover, we apply our method to achieve a highly accurate computation of the homogenized coefficients for a quasiperiodic multiscale elliptic equation.\n",
            "Score: 2\n",
            "\n",
            "Document: 837|||| \n",
            "'arxiv_id': arXiv:2404.16322, \n",
            "'paper_link': https://arxiv.org/abs/2404.16322, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.16322, \n",
            "Title: Effective and General Distance Computation for Approximate Nearest Neighbor Search \n",
            "Subjects: Databases (cs.DB) \n",
            "Abstract: Approximate K Nearest Neighbor (AKNN) search in high-dimensional spaces is a critical yet challenging problem. In AKNN search, distance computation is the core task that dominates the runtime. Existing approaches typically use approximate distances to improve computational efficiency, often at the cost of reduced search accuracy. To address this issue, the state-of-the-art method, ADSampling, employs random projections to estimate approximate distances and introduces an additional distance correction process to mitigate accuracy loss. However, ADSampling has limitations in both effectiveness and generality, primarily due to its reliance on random projections for distance approximation and correction. To address the effectiveness limitations of ADSampling, we leverage data distribution to improve distance computation via orthogonal projection. Furthermore, to overcome the generality limitations of ADSampling, we adopt a data-driven approach to distance correction, decoupling the correction process from the distance approximation process. Extensive experiments demonstrate the superiority and effectiveness of our method. In particular, compared to ADSampling, our method achieves a speedup of 1.6 to 2.1 times on real-world datasets while providing higher accuracy.\n",
            "Score: 2\n",
            "\n",
            "Document: 898|||| \n",
            "'arxiv_id': arXiv:2407.00548, \n",
            "'paper_link': https://arxiv.org/abs/2407.00548, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.00548, \n",
            "Title: KOROL: Learning Visualizable Object Feature with Koopman Operator Rollout for Manipulation \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Learning dexterous manipulation skills presents significant challenges due to complex nonlinear dynamics that underlie the interactions between objects and multi-fingered hands. Koopman operators have emerged as a robust method for modeling such nonlinear dynamics within a linear framework. However, current methods rely on runtime access to ground-truth (GT) object states, making them unsuitable for vision-based practical applications. Unlike image-to-action policies that implicitly learn visual features for control, we use a dynamics model, specifically the Koopman operator, to learn visually interpretable object features critical for robotic manipulation within a scene. We construct a Koopman operator using object features predicted by a feature extractor and utilize it to auto-regressively advance system states. We train the feature extractor to embed scene information into object features, thereby enabling the accurate propagation of robot trajectories. We evaluate our approach on simulated and real-world robot tasks, with results showing that it outperformed the model-based imitation learning NDP by 1.08$\\times$ and the image-to-action Diffusion Policy by 1.16$\\times$. The results suggest that our method maintains task success rates with learned features and extends applicability to real-world manipulation without GT object states. Project video and code are available at: \\url{this https URL}.\n",
            "Score: 2\n",
            "\n",
            "Document: 928|||| \n",
            "'arxiv_id': arXiv:2407.14066, \n",
            "'paper_link': https://arxiv.org/abs/2407.14066, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.14066, \n",
            "Title: 360VFI: A Dataset and Benchmark for Omnidirectional Video Frame Interpolation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Head-mounted 360° displays and portable 360° cameras have significantly progressed, providing viewers a realistic and immersive experience. However, many omnidirectional videos have low frame rates that can lead to visual fatigue, and the prevailing plane frame interpolation methodologies are unsuitable for omnidirectional video interpolation because they are designed solely for traditional videos. This paper introduces the benchmark dataset, 360VFI, for Omnidirectional Video Frame Interpolation. We present a practical implementation that introduces a distortion prior from omnidirectional video into the network to modulate distortions. Specifically, we propose a pyramid distortion-sensitive feature extractor that uses the unique characteristics of equirectangular projection (ERP) format as prior information. Moreover, we devise a decoder that uses an affine transformation to further facilitate the synthesis of intermediate frames. 360VFI is the first dataset and benchmark that explores the challenge of Omnidirectional Video Frame Interpolation. Through our benchmark analysis, we present four different distortion condition scenes in the proposed 360VFI dataset to evaluate the challenges triggered by distortion during interpolation. Besides, experimental results demonstrate that Omnidirectional Video Interpolation can be effectively improved by modeling for omnidirectional distortion.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 3\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"distance measure\", 10),\n",
        "        (\"similarity measure\", 10),\n",
        "        (\"vector distance\", 10),\n",
        "        (\"distance metric\", 10),\n",
        "        (\"similarity metric\", 10),\n",
        "        (\"dimension reduction\", 10),\n",
        "\n",
        "        (\"similarity\", 1),\n",
        "        (\"distance\", 1),\n",
        "        (\"metric\", 1),\n",
        "    ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HOGJ_6VhZtO",
        "outputId": "31a7575c-b979-4830-f839-36aa03b4ff27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: distance measure\n",
            "Total Matches in Set: 198\n",
            "Matches Above Score-Floor in Set: 6\n",
            "2024-09-10__122809545359\n",
            "\n",
            "Showing 6 in top-45 out of 198 total results.     -> 6 of 45/198\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 3) -> 3\n",
            "\n",
            "\n",
            "Document: 678|||| \n",
            "'arxiv_id': arXiv:2304.01397, \n",
            "'paper_link': https://arxiv.org/abs/2304.01397, \n",
            "'pdf_link': https://arxiv.org/pdf/2304.01397, \n",
            "Title: LTM: Scalable and Black-box Similarity-based Test Suite Minimization based on Language Models \n",
            "Subjects: Software Engineering (cs.SE) \n",
            "Abstract: Test suites tend to grow when software evolves, making it often infeasible to execute all test cases with the allocated testing budgets, especially for large software systems. Test suite minimization (TSM) is employed to improve the efficiency of software testing by removing redundant test cases, thus reducing testing time and resources, while maintaining the fault detection capability of the test suite. Most existing TSM approaches rely on code coverage (white-box) or model-based features, which are not always available to test engineers. Recent TSM approaches that rely only on test code (black-box) have been proposed, such as ATM and FAST-R. To address the scalability, we propose LTM (Language model-based Test suite Minimization), a novel, scalable, and black-box similarity-based TSM approach based on large language models (LLMs), which is the first application of LLMs in the context of TSM. To support similarity measurement for test code embeddings, we investigate five pre-trained language models: CodeBERT, GraphCodeBERT, UniXcoder, StarEncoder, and CodeLlama, on which we compute two similarity measures: Cosine Similarity and Euclidean Distance. Our goal is to find similarity measures that are not only computationally more efficient but can also better guide a Genetic Algorithm (GA) to search for optimal minimized test suites, thus reducing the overall search time. Experimental results show that the best configuration of LTM (UniXcoder/Cosine) outperforms ATM in three aspects: (a) achieving a slightly greater saving rate of testing time (41.72% versus 41.02%, on average); (b) attaining a significantly higher fault detection rate (0.84 versus 0.81, on average); and, most importantly, (c) minimizing test suites nearly five times faster on average, with higher gains for larger test suites and systems, thus achieving much higher scalability.\n",
            "Score: 12\n",
            "\n",
            "Document: 320|||| \n",
            "'arxiv_id': arXiv:2409.05225, \n",
            "'paper_link': https://arxiv.org/abs/2409.05225, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05225, \n",
            "Title: Comparison of Two Augmentation Methods in Improving Detection Accuracy of Hemarthrosis \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: With the increase of computing power, machine learning models in medical imaging have been introduced to help in rending medical diagnosis and inspection, like hemophilia, a rare disorder in which blood cannot clot normally. Often, one of the bottlenecks of detecting hemophilia is the lack of data available to train the algorithm to increase the accuracy. As a possible solution, this research investigated whether introducing augmented data by data synthesis or traditional augmentation techniques can improve model accuracy, helping to diagnose the diseases. To tackle this research, features of ultrasound images were extracted by the pre-trained VGG-16, and similarities were compared by cosine similarity measure based on extracted features in different distributions among real images, synthetic images, and augmentation images (Real vs. Real, Syn vs. Syn, Real vs. Different Batches of Syn, Real vs. Augmentation Techniques). Model testing performance was investigated using EffientNet-B4 to recognize \"blood\" images with two augmentation methods. In addition, a gradient-weighted class activation mapping (Grad-CAM) visualization was used to interpret the unexpected results like loss of accuracy. Synthetic and real images do not show high similarity, with a mean similarity score of 0.4737. Synthetic batch 1 dataset and images by horizontal flip are more similar to the original images. Classic augmentation techniques and data synthesis can improve model accuracy, and data by traditional augmentation techniques have a better performance than synthetic data. In addition, the Grad-CAM heatmap figured out the loss of accuracy is due to a shift in the domain. Overall, this research found that two augmentation methods, data synthesis and traditional augmentation techniques, both can improve accuracy to a certain extent to help to diagnose rare diseases.\n",
            "Score: 11\n",
            "\n",
            "Document: 642|||| \n",
            "'arxiv_id': arXiv:2409.05635, \n",
            "'paper_link': https://arxiv.org/abs/2409.05635, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05635, \n",
            "Title: Optimal Projections for Classification with Naive Bayes \n",
            "Subjects: Machine Learning (stat.ML) \n",
            "Abstract: In the Naive Bayes classification model the class conditional densities are estimated as the products of their marginal densities along the cardinal basis directions. We study the problem of obtaining an alternative basis for this factorisation with the objective of enhancing the discriminatory power of the associated classification model. We formulate the problem as a projection pursuit to find the optimal linear projection on which to perform classification. Optimality is determined based on the multinomial likelihood within which probabilities are estimated using the Naive Bayes factorisation of the projected data. Projection pursuit offers the added benefits of dimension reduction and visualisation. We discuss an intuitive connection with class conditional independent components analysis, and show how this is realised visually in practical applications. The performance of the resulting classification models is investigated using a large collection of (162) publicly available benchmark data sets and in comparison with relevant alternatives. We find that the proposed approach substantially outperforms other popular probabilistic discriminant analysis models and is highly competitive with Support Vector Machines.\n",
            "Score: 10\n",
            "\n",
            "Document: 665|||| \n",
            "'arxiv_id': arXiv:2204.00740, \n",
            "'paper_link': https://arxiv.org/abs/2204.00740, \n",
            "'pdf_link': https://arxiv.org/pdf/2204.00740, \n",
            "Title: Path Development Network with Finite-dimensional Lie Group Representation \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Signature, lying at the heart of rough path theory, is a central tool for analysing controlled differential equations driven by irregular paths. Recently it has also found extensive applications in machine learning and data science as a mathematically principled, universal feature that boosts the performance of deep learning-based models in sequential data tasks. It, nevertheless, suffers from the curse of dimensionality when paths are high-dimensional.\n",
            "We propose a novel, trainable path development layer, which exploits representations of sequential data through finite-dimensional Lie groups, thus resulting in dimension reduction. Its backpropagation algorithm is designed via optimization on manifolds. Our proposed layer, analogous to recurrent neural networks (RNN), possesses an explicit, simple recurrent unit that alleviates the gradient issues.\n",
            "Our layer demonstrates its strength in irregular time series modelling. Empirical results on a range of datasets show that the development layer consistently and significantly outperforms signature features on accuracy and dimensionality. The compact hybrid model (stacking one-layer LSTM with the development layer) achieves state-of-the-art against various RNN and continuous time series models. Our layer also enhances the performance of modelling dynamics constrained to Lie groups. Code is available at this https URL.\n",
            "Score: 10\n",
            "\n",
            "Document: 749|||| \n",
            "'arxiv_id': arXiv:2312.14810, \n",
            "'paper_link': https://arxiv.org/abs/2312.14810, \n",
            "'pdf_link': https://arxiv.org/pdf/2312.14810, \n",
            "Title: Accurate, scalable, and efficient Bayesian optimal experimental design with derivative-informed neural operators \n",
            "Subjects: Computational Engineering, Finance, and Science (cs.CE) \n",
            "Abstract: We consider optimal experimental design (OED) problems in selecting the most informative observation sensors to estimate model parameters in a Bayesian framework. Such problems are computationally prohibitive when the parameter-to-observable (PtO) map is expensive to evaluate, the parameters are high-dimensional, and the optimization for sensor selection is combinatorial and high-dimensional. To address these challenges, we develop an accurate, scalable, and efficient computational framework based on derivative-informed neural operators (DINO). We propose to use derivative-informed dimension reduction to reduce the parameter dimensions, based on which we train DINO with derivative information as an accurate and efficient surrogate for the PtO map and its derivative. Moreover, we derive DINO-enabled efficient formulations in computing the maximum a posteriori (MAP) point, the eigenvalues of approximate posterior covariance, and three commonly used optimality criteria for the OED problems. Furthermore, we provide detailed error analysis for the approximations of the MAP point, the eigenvalues, and the optimality criteria. We also propose a modified swapping greedy algorithm for the sensor selection optimization and demonstrate that the proposed computational framework is scalable to preserve the accuracy for increasing parameter dimensions and achieves high computational efficiency, with an over 1000$\\times$ speedup accounting for both offline construction and online evaluation costs, compared to high-fidelity Bayesian OED solutions for a three-dimensional nonlinear convection-diffusion-reaction example with tens of thousands of parameters.\n",
            "Score: 10\n",
            "\n",
            "Document: 1049|||| \n",
            "'arxiv_id': arXiv:2309.13478, \n",
            "'paper_link': https://arxiv.org/abs/2309.13478, \n",
            "'pdf_link': https://arxiv.org/pdf/2309.13478, \n",
            "Title: CA-PCA: Manifold Dimension Estimation, Adapted for Curvature \n",
            "Subjects: Machine Learning (stat.ML) \n",
            "Abstract: The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.\n",
            "Score: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 3\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"parametric\", 10),\n",
        "    ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAncfvGn6URQ",
        "outputId": "9c688f8f-1fb1-4649-fab2-bad1277f1229"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: parametric\n",
            "Total Matches in Set: 16\n",
            "Matches Above Score-Floor in Set: 16\n",
            "2024-09-10__123003825033\n",
            "\n",
            "Showing 16 in top-16 out of 16 total results.     -> 16 of 16/16\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 3) -> 3\n",
            "\n",
            "\n",
            "Document: 6|||| \n",
            "'arxiv_id': arXiv:2409.04462, \n",
            "'paper_link': https://arxiv.org/abs/2409.04462, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04462, \n",
            "Title: New parametric identification method for a preference model \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: This article presents a contribution to multi-criteria decision support intended for industrial decision-makers in order to determine the best compromise between design criteria when working on risky or innovative products. In (RENAUD et al. 2008) we used the OWA operator (Ordered Weighted Average), a well-known multi-criteria analysis technique introduced by (YAGER 1988). The interest of this aggregation method is, beyond its ease of use, its ability to evaluate a product according to a single scale. When using the OWA method, the choice of criterion weights and their values remains an important and delicate operation. Indeed, the weights are not fixed by criterion but according to a level of utility (FISHBURN 1967). The weights can, in addition, be determined using different methods. A traditional approach consists in estimating the weights from an a priori selection of the most representative samples by an expert. We propose a new approach based on applied D-Optimality to determine the best sample. The results of the two approaches are compared. Indeed, in some multi-criteria decision problems, it is difficult to choose the method that best describes the behavior of the decision maker. As said above, the first part of this paper presents an original method based on D-optimality to determine the most representative set of samples to determine the decision parameters. This method has been applied and validated in an OWA approach. It has been shown that the accuracy and reliability of the method have been improved. Since the OWA application has been improved, the other goal of this paper is to verify whether the real decision maker has an OWA-based behavior or not. To achieve this, the D-optimality approach is applied to the MAUT (Multi-Attribute Utility Theory) approach to find the best set of samples. The results of the two methods are compared. Both approaches show that, while OWA better simulates the decision maker's behavior, there is still a gap between its scores and that of OWA. The question here is how to improve the accuracy of the score estimated by OWA compared to those given by the expert. Subsequently, a hybrid approach is tested, such as a linear combination of the MAUT and OWA approaches. The results obtained with this combination were found to be more accurate than those of OWA. However, we also tested the CHOQUET discrete integral approach. In other words, it is possible to find a model capable of better describing the decision maker's behavior.\n",
            "Score: 10\n",
            "\n",
            "Document: 27|||| \n",
            "'arxiv_id': arXiv:2409.04538, \n",
            "'paper_link': https://arxiv.org/abs/2409.04538, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04538, \n",
            "Title: Operator Learning with Gaussian Processes \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Operator learning focuses on approximating mappings $\\mathcal{G}^\\dagger:\\mathcal{U} \\rightarrow\\mathcal{V}$ between infinite-dimensional spaces of functions, such as $u: \\Omega_u\\rightarrow\\mathbb{R}$ and $v: \\Omega_v\\rightarrow\\mathbb{R}$. This makes it particularly suitable for solving parametric nonlinear partial differential equations (PDEs). While most machine learning methods for operator learning rely on variants of deep neural networks (NNs), recent studies have shown that Gaussian Processes (GPs) are also competitive while offering interpretability and theoretical guarantees. In this paper, we introduce a hybrid GP/NN-based framework for operator learning that leverages the strengths of both methods. Instead of approximating the function-valued operator $\\mathcal{G}^\\dagger$, we use a GP to approximate its associated real-valued bilinear form $\\widetilde{\\mathcal{G}}^\\dagger: \\mathcal{U}\\times\\mathcal{V}^*\\rightarrow\\mathbb{R}.$ This bilinear form is defined by $\\widetilde{\\mathcal{G}}^\\dagger(u,\\varphi) := [\\varphi,\\mathcal{G}^\\dagger(u)],$ which allows us to recover the operator $\\mathcal{G}^\\dagger$ through $\\mathcal{G}^\\dagger(u)(y)=\\widetilde{\\mathcal{G}}^\\dagger(u,\\delta_y).$ The GP mean function can be zero or parameterized by a neural operator and for each setting we develop a robust training mechanism based on maximum likelihood estimation (MLE) that can optionally leverage the physics involved. Numerical benchmarks show that (1) it improves the performance of a base neural operator by using it as the mean function of a GP, and (2) it enables zero-shot data-driven models for accurate predictions without prior training. Our framework also handles multi-output operators where $\\mathcal{G}^\\dagger:\\mathcal{U} \\rightarrow\\prod_{s=1}^S\\mathcal{V}^s$, and benefits from computational speed-ups via product kernel structures and Kronecker product matrix representations.\n",
            "Score: 10\n",
            "\n",
            "Document: 116|||| \n",
            "'arxiv_id': arXiv:2409.04760, \n",
            "'paper_link': https://arxiv.org/abs/2409.04760, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04760, \n",
            "Title: Training-Free Point Cloud Recognition Based on Geometric and Semantic Information Fusion \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The trend of employing training-free methods for point cloud recognition is becoming increasingly popular due to its significant reduction in computational resources and time costs. However, existing approaches are limited as they typically extract either geometric or semantic features. To address this limitation, we propose a novel method that integrates both geometric and semantic features, thereby enhancing the comprehensive understanding of point clouds. For the geometric branch, we adopt a non-parametric strategy to extract geometric features. In the semantic branch, we leverage a model pre-trained through contrastive learning and aligned with text features to obtain semantic features. Experimental results demonstrate that our method outperforms existing state-of-the-art training-free approaches on several popular benchmark datasets, including ModelNet and ScanObiectNN.\n",
            "Score: 10\n",
            "\n",
            "Document: 207|||| \n",
            "'arxiv_id': arXiv:2409.04953, \n",
            "'paper_link': https://arxiv.org/abs/2409.04953, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04953, \n",
            "Title: Evaluating Neural Networks Architectures for Spring Reverb Modelling \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Reverberation is a key element in spatial audio perception, historically achieved with the use of analogue devices, such as plate and spring reverb, and in the last decades with digital signal processing techniques that have allowed different approaches for Virtual Analogue Modelling (VAM). The electromechanical functioning of the spring reverb makes it a nonlinear system that is difficult to fully emulate in the digital domain with white-box modelling techniques. In this study, we compare five different neural network architectures, including convolutional and recurrent models, to assess their effectiveness in replicating the characteristics of this audio effect. The evaluation is conducted on two datasets at sampling rates of 16 kHz and 48 kHz. This paper specifically focuses on neural audio architectures that offer parametric control, aiming to advance the boundaries of current black-box modelling techniques in the domain of spring reverberation.\n",
            "Score: 10\n",
            "\n",
            "Document: 259|||| \n",
            "'arxiv_id': arXiv:2409.05050, \n",
            "'paper_link': https://arxiv.org/abs/2409.05050, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05050, \n",
            "Title: Sampling recovery in Bochner spaces and applications to parametric PDEs with random inputs \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: We proved convergence rates of linear sampling recovery by extended least squares methods of functions in Bochner space satisfying some $\\ell_2$-summability of their generalized polynomial chaos expansion coefficients. As applications we derive convergence rates of linear collocation approximation of solutions to parametric elliptic PDEs with random inputs, and of infinite dimensional holomorphic functions. These convergence rates significantly improve the known results.\n",
            "Score: 10\n",
            "\n",
            "Document: 262|||| \n",
            "'arxiv_id': arXiv:2409.05061, \n",
            "'paper_link': https://arxiv.org/abs/2409.05061, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05061, \n",
            "Title: Dynamic Demand Management for Parcel Lockers \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: In pursuit of a more sustainable and cost-efficient last mile, parcel lockers have gained a firm foothold in the parcel delivery landscape. To fully exploit their potential and simultaneously ensure customer satisfaction, successful management of the locker's limited capacity is crucial. This is challenging as future delivery requests and pickup times are stochastic from the provider's perspective. In response, we propose to dynamically control whether the locker is presented as an available delivery option to each incoming customer with the goal of maximizing the number of served requests weighted by their priority. Additionally, we take different compartment sizes into account, which entails a second type of decision as parcels scheduled for delivery must be allocated. We formalize the problem as an infinite-horizon sequential decision problem and find that exact methods are intractable due to the curses of dimensionality. In light of this, we develop a solution framework that orchestrates multiple algorithmic techniques rooted in Sequential Decision Analytics and Reinforcement Learning, namely cost function approximation and an offline trained parametric value function approximation together with a truncated online rollout. Our innovative approach to combine these techniques enables us to address the strong interrelations between the two decision types. As a general methodological contribution, we enhance the training of our value function approximation with a modified version of experience replay that enforces structure in the value function. Our computational study shows that our method outperforms a myopic benchmark by 13.7% and an industry-inspired policy by 12.6%.\n",
            "Score: 10\n",
            "\n",
            "Document: 270|||| \n",
            "'arxiv_id': arXiv:2409.05084, \n",
            "'paper_link': https://arxiv.org/abs/2409.05084, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05084, \n",
            "Title: Adaptive $k$-nearest neighbor classifier based on the local estimation of the shape operator \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: The $k$-nearest neighbor ($k$-NN) algorithm is one of the most popular methods for nonparametric classification. However, a relevant limitation concerns the definition of the number of neighbors $k$. This parameter exerts a direct impact on several properties of the classifier, such as the bias-variance tradeoff, smoothness of decision boundaries, robustness to noise, and class imbalance handling. In the present paper, we introduce a new adaptive $k$-nearest neighbours ($kK$-NN) algorithm that explores the local curvature at a sample to adaptively defining the neighborhood size. The rationale is that points with low curvature could have larger neighborhoods (locally, the tangent space approximates well the underlying data shape), whereas points with high curvature could have smaller neighborhoods (locally, the tangent space is a loose approximation). We estimate the local Gaussian curvature by computing an approximation to the local shape operator in terms of the local covariance matrix as well as the local Hessian matrix. Results on many real-world datasets indicate that the new $kK$-NN algorithm yields superior balanced accuracy compared to the established $k$-NN method and also another adaptive $k$-NN algorithm. This is particularly evident when the number of samples in the training data is limited, suggesting that the $kK$-NN is capable of learning more discriminant functions with less data considering many relevant cases.\n",
            "Score: 10\n",
            "\n",
            "Document: 447|||| \n",
            "'arxiv_id': arXiv:2409.05508, \n",
            "'paper_link': https://arxiv.org/abs/2409.05508, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05508, \n",
            "Title: A general reduced-order neural operator for spatio-temporal predictive learning on complex spatial domains \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Predictive learning for spatio-temporal processes (PL-STP) on complex spatial domains plays a critical role in various scientific and engineering fields, with its essence being the construction of operators between infinite-dimensional function spaces. This paper focuses on the unequal-domain mappings in PL-STP and categorising them into increase-domain and decrease-domain mapping. Recent advances in deep learning have revealed the great potential of neural operators (NOs) to learn operators directly from observational data. However, existing NOs require input space and output space to be the same domain, which pose challenges in ensuring predictive accuracy and stability for unequal-domain mappings. To this end, this study presents a general reduced-order neural operator named Reduced-Order Neural Operator on Riemannian Manifolds (RO-NORM), which consists of two parts: the unequal-domain encoder/decoder and the same-domain approximator. Motivated by the variable separation in classical modal decomposition, the unequal-domain encoder/decoder uses the pre-computed bases to reformulate the spatio-temporal function as a sum of products between spatial (or temporal) bases and corresponding temporally (or spatially) distributed weight functions, thus the original unequal-domain mapping can be converted into a same-domain mapping. Consequently, the same-domain approximator NORM is applied to model the transformed mapping. The performance of our proposed method has been evaluated on six benchmark cases, including parametric PDEs, engineering and biomedical applications, and compared with four baseline algorithms: DeepONet, POD-DeepONet, PCA-Net, and vanilla NORM. The experimental results demonstrate the superiority of RO-NORM in prediction accuracy and training efficiency for PL-STP.\n",
            "Score: 10\n",
            "\n",
            "Document: 549|||| \n",
            "'arxiv_id': arXiv:2409.05791, \n",
            "'paper_link': https://arxiv.org/abs/2409.05791, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05791, \n",
            "Title: Uniform Approximation of Eigenproblems of a Large-Scale Parameter-Dependent Hermitian Matrix \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: We consider the approximation of the smallest eigenvalue of a large parameter-dependent Hermitian matrix over a continuum compact domain. Our approach is based on approximating the smallest eigenvalue by the one obtained by projecting the large matrix onto a suitable small subspace, a practice widely employed in the literature. The projection subspaces are constructed iteratively (to reduce the error of the approximation where it is large) with the addition of the eigenvectors of the parameter-dependent matrix at the parameter values where a surrogate error is maximal. The surrogate error is the gap between the approximation and a lower bound for the smallest eigenvalue proposed in [Sirkovic and Kressner, SIAM J. Matrix Anal. Appl., 37(2), 2016]. Unlike the classical approaches, such as the successive constraint method, that maximize such surrogate errors over a discrete and finite set, we maximize the surrogate error over the continuum of all permissible parameter values globally. We put particular attention to the lower bound, which enables us to formally prove the global convergence of our framework both in finite-dimensional and infinite-dimensional settings. In the second part, we focus on the approximation of the smallest singular value of a large parameter-dependent matrix, in case it is non-Hermitian, and propose another subspace framework to construct a small parameter-dependent non-Hermitian matrix whose smallest singular value approximates the original large-scale smallest singular value. We perform numerical experiments on synthetic examples, as well as on real examples arising from parametric PDEs. The numerical experiments show that the proposed techniques are able to drastically reduce the size of the large parameter-dependent matrix, while ensuring an approximation error for the smallest eigenvalue/singular value below the prescribed tolerance.\n",
            "Score: 10\n",
            "\n",
            "Document: 634|||| \n",
            "'arxiv_id': arXiv:2409.05475, \n",
            "'paper_link': https://arxiv.org/abs/2409.05475, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05475, \n",
            "Title: Reinforcement Learning for Variational Quantum Circuits Design \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: Variational Quantum Algorithms have emerged as promising tools for solving optimization problems on quantum computers. These algorithms leverage a parametric quantum circuit called ansatz, where its parameters are adjusted by a classical optimizer with the goal of optimizing a certain cost function. However, a significant challenge lies in designing effective circuits for addressing specific problems. In this study, we leverage the powerful and flexible Reinforcement Learning paradigm to train an agent capable of autonomously generating quantum circuits that can be used as ansatzes in variational algorithms to solve optimization problems. The agent is trained on diverse problem instances, including Maximum Cut, Maximum Clique and Minimum Vertex Cover, built from different graph topologies and sizes. Our analysis of the circuits generated by the agent and the corresponding solutions shows that the proposed method is able to generate effective ansatzes. While our goal is not to propose any new specific ansatz, we observe how the agent has discovered a novel family of ansatzes effective for Maximum Cut problems, which we call $R_{yz}$-connected. We study the characteristics of one of these ansatzes by comparing it against state-of-the-art quantum algorithms across instances of varying graph topologies, sizes, and problem types. Our results indicate that the $R_{yz}$-connected circuit achieves high approximation ratios for Maximum Cut problems, further validating our proposed agent. In conclusion, our study highlights the potential of Reinforcement Learning techniques in assisting researchers to design effective quantum circuits which could have applications in a wide number of tasks.\n",
            "Score: 10\n",
            "\n",
            "Document: 638|||| \n",
            "'arxiv_id': arXiv:2409.05577, \n",
            "'paper_link': https://arxiv.org/abs/2409.05577, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05577, \n",
            "Title: Approximation Bounds for Recurrent Neural Networks with Application to Regression \n",
            "Subjects: Machine Learning (stat.ML) \n",
            "Abstract: We study the approximation capacity of deep ReLU recurrent neural networks (RNNs) and explore the convergence properties of nonparametric least squares regression using RNNs. We derive upper bounds on the approximation error of RNNs for Hölder smooth functions, in the sense that the output at each time step of an RNN can approximate a Hölder function that depends only on past and current information, termed a past-dependent function. This allows a carefully constructed RNN to simultaneously approximate a sequence of past-dependent Hölder functions. We apply these approximation results to derive non-asymptotic upper bounds for the prediction error of the empirical risk minimizer in regression problem. Our error bounds achieve minimax optimal rate under both exponentially $\\beta$-mixing and i.i.d. data assumptions, improving upon existing ones. Our results provide statistical guarantees on the performance of RNNs.\n",
            "Score: 10\n",
            "\n",
            "Document: 734|||| \n",
            "'arxiv_id': arXiv:2310.20605, \n",
            "'paper_link': https://arxiv.org/abs/2310.20605, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.20605, \n",
            "Title: Learning Lyapunov-Stable Polynomial Dynamical Systems through Imitation \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Imitation learning is a paradigm to address complex motion planning problems by learning a policy to imitate an expert's behavior. However, relying solely on the expert's data might lead to unsafe actions when the robot deviates from the demonstrated trajectories. Stability guarantees have previously been provided utilizing nonlinear dynamical systems, acting as high-level motion planners, in conjunction with the Lyapunov stability theorem. Yet, these methods are prone to inaccurate policies, high computational cost, sample inefficiency, or quasi stability when replicating complex and highly nonlinear trajectories. To mitigate this problem, we present an approach for learning a globally stable nonlinear dynamical system as a motion planning policy. We model the nonlinear dynamical system as a parametric polynomial and learn the polynomial's coefficients jointly with a Lyapunov candidate. To showcase its success, we compare our method against the state of the art in simulation and conduct real-world experiments with the Kinova Gen3 Lite manipulator arm. Our experiments demonstrate the sample efficiency and reproduction accuracy of our method for various expert trajectories, while remaining stable in the face of perturbations.\n",
            "Score: 10\n",
            "\n",
            "Document: 902|||| \n",
            "'arxiv_id': arXiv:2407.03627, \n",
            "'paper_link': https://arxiv.org/abs/2407.03627, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.03627, \n",
            "Title: DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks. However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module. Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information. Therefore, in this work, we propose DSLR (Document Refinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages. We experimentally validate DSLR on multiple open-domain QA datasets and the results demonstrate that DSLR significantly enhances the RAG performance over conventional fixed-size passage. Furthermore, our DSLR enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems.\n",
            "Score: 10\n",
            "\n",
            "Document: 946|||| \n",
            "'arxiv_id': arXiv:2408.02761, \n",
            "'paper_link': https://arxiv.org/abs/2408.02761, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.02761, \n",
            "Title: Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (KNN). KNN drastically improved scalability and performance over MD when both were applied to raw and average-pooled bottleneck features.\n",
            "Score: 10\n",
            "\n",
            "Document: 1000|||| \n",
            "'arxiv_id': arXiv:2409.01421, \n",
            "'paper_link': https://arxiv.org/abs/2409.01421, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.01421, \n",
            "Title: DiffCSG: Differentiable CSG via Rasterization \n",
            "Subjects: Graphics (cs.GR) \n",
            "Abstract: Differentiable rendering is a key ingredient for inverse rendering and machine learning, as it allows to optimize scene parameters (shape, materials, lighting) to best fit target images. Differentiable rendering requires that each scene parameter relates to pixel values through differentiable operations. While 3D mesh rendering algorithms have been implemented in a differentiable way, these algorithms do not directly extend to Constructive-Solid-Geometry (CSG), a popular parametric representation of shapes, because the underlying boolean operations are typically performed with complex black-box mesh-processing libraries. We present an algorithm, DiffCSG, to render CSG models in a differentiable manner. Our algorithm builds upon CSG rasterization, which displays the result of boolean operations between primitives without explicitly computing the resulting mesh and, as such, bypasses black-box mesh processing. We describe how to implement CSG rasterization within a differentiable rendering pipeline, taking special care to apply antialiasing along primitive intersections to obtain gradients in such critical areas. Our algorithm is simple and fast, can be easily incorporated into modern machine learning setups, and enables a range of applications for computer-aided design, including direct and image-based editing of CSG primitives. Code and data: this https URL.\n",
            "Score: 10\n",
            "\n",
            "Document: 1007|||| \n",
            "'arxiv_id': arXiv:2409.02064, \n",
            "'paper_link': https://arxiv.org/abs/2409.02064, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.02064, \n",
            "Title: Personalized Federated Learning via Active Sampling \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Consider a collection of data generators which could represent, e.g., humans equipped with a smart-phone or wearables. We want to train a personalized (or tailored) model for each data generator even if they provide only small local datasets. The available local datasets might fail to provide sufficient statistical power to train high-dimensional models (such as deep neural networks) effectively. One possible solution is to identify similar data generators and pool their local datasets to obtain a sufficiently large training set. This paper proposes a novel method for sequentially identifying similar (or relevant) data generators. Our method is similar in spirit to active sampling methods but does not require exchange of raw data. Indeed, our method evaluates the relevance of a data generator by evaluating the effect of a gradient step using its local dataset. This evaluation can be performed in a privacy-friendly fashion without sharing raw data. We extend this method to non-parametric models by a suitable generalization of the gradient step to update a hypothesis using the local dataset provided by a data generator.\n",
            "Score: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"survey\", 1),\n",
        "        (\"election\", 1),\n",
        "        (\"voting\", 1),\n",
        "        (\"poll\", 1),\n",
        "        (\"vote\", 1),\n",
        "        (\"candidate\", 1),\n",
        "\n",
        "        (\"selection\", .5),\n",
        "        (\"coordination\", .5),\n",
        "        (\"consensus\", .5),\n",
        "        (\"campaign\", .5),\n",
        "\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Po_ipgoynfr",
        "outputId": "78f14735-5ae5-470a-a884-c6a4af408e58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: survey\n",
            "Total Matches in Set: 113\n",
            "Matches Above Score-Floor in Set: 7\n",
            "2024-09-10__122809723833\n",
            "\n",
            "Showing 7 in top-45 out of 113 total results.     -> 7 of 45/113\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 968|||| \n",
            "'arxiv_id': arXiv:2408.11755, \n",
            "'paper_link': https://arxiv.org/abs/2408.11755, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11755, \n",
            "Title: On the Distortion of Committee Election with 1-Euclidean Preferences and Few Distance Queries \n",
            "Subjects: Computer Science and Game Theory (cs.GT) \n",
            "Abstract: We consider committee election of $k \\geq 2$ (out of $m \\geq k+1$) candidates, where the voters and the candidates are associated with locations on the real line. Each voter's cardinal preferences over candidates correspond to her distance to the candidate locations, and each voter's cardinal preferences over committees is defined as her distance to the nearest candidate elected in the committee. We consider a setting where the true distances and the locations are unknown. We can nevertheless have access to degraded information which consists of an order of candidates for each voter. We investigate the best possible distortion (a worst-case performance criterion) wrt. the social cost achieved by deterministic committee election rules based on ordinal preferences submitted by $n$ voters and few additional distance queries. For $k = 2$, we achieve bounded distortion without any distance queries; we show that the distortion is $3$ for $m = 3$, and that the best possible distortion achieved by deterministic algorithms is at least $n-1$ and at most $n+1$, for any $m \\geq 4$. For any $k \\geq 3$, we show that the best possible distortion of any deterministic algorithm that uses at most $k-3$ distance queries cannot be bounded by any function of $n$, $m$ and $k$. We present deterministic algorithms for $k$-committee election with distortion of $O(n)$ with $O(k)$ distance queries and $O(1)$ with $O(k \\log n)$ distance queries.\n",
            "Score: 3\n",
            "\n",
            "Document: 123|||| \n",
            "'arxiv_id': arXiv:2409.04777, \n",
            "'paper_link': https://arxiv.org/abs/2409.04777, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04777, \n",
            "Title: Optimization Hyper-parameter Laws for Large Language Models \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Large Language Models have driven significant AI advancements, yet their training is resource-intensive and highly sensitive to hyper-parameter selection. While scaling laws provide valuable guidance on model size and data requirements, they fall short in choosing dynamic hyper-parameters, such as learning-rate (LR) schedules, that evolve during training. To bridge this gap, we present Optimization Hyper-parameter Laws (Opt-Laws), a framework that effectively captures the relationship between hyper-parameters and training outcomes, enabling the pre-selection of potential optimal schedules. Grounded in stochastic differential equations, Opt-Laws introduce novel mathematical interpretability and offer a robust theoretical foundation for some popular LR schedules. Our extensive validation across diverse model sizes and data scales demonstrates Opt-Laws' ability to accurately predict training loss and identify optimal LR schedule candidates in pre-training, continual training, and fine-tuning scenarios. This approach significantly reduces computational costs while enhancing overall model performance.\n",
            "Score: 2.5\n",
            "\n",
            "Document: 181|||| \n",
            "'arxiv_id': arXiv:2409.04897, \n",
            "'paper_link': https://arxiv.org/abs/2409.04897, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04897, \n",
            "Title: Centralized Selection with Preferences in the Presence of Biases \n",
            "Subjects: Data Structures and Algorithms (cs.DS) \n",
            "Abstract: This paper considers the scenario in which there are multiple institutions, each with a limited capacity for candidates, and candidates, each with preferences over the institutions. A central entity evaluates the utility of each candidate to the institutions, and the goal is to select candidates for each institution in a way that maximizes utility while also considering the candidates' preferences. The paper focuses on the setting in which candidates are divided into multiple groups and the observed utilities of candidates in some groups are biased--systematically lower than their true utilities. The first result is that, in these biased settings, prior algorithms can lead to selections with sub-optimal true utility and significant discrepancies in the fraction of candidates from each group that get their preferred choices. Subsequently, an algorithm is presented along with proof that it produces selections that achieve near-optimal group fairness with respect to preferences while also nearly maximizing the true utility under distributional assumptions. Further, extensive empirical validation of these results in real-world and synthetic settings, in which the distributional assumptions may not hold, are presented.\n",
            "Score: 2.5\n",
            "\n",
            "Document: 241|||| \n",
            "'arxiv_id': arXiv:2409.05021, \n",
            "'paper_link': https://arxiv.org/abs/2409.05021, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05021, \n",
            "Title: Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: While neural machine translation (NMT) models achieve success in our daily lives, they show vulnerability to adversarial attacks. Despite being harmful, these attacks also offer benefits for interpreting and enhancing NMT models, thus drawing increased research attention. However, existing studies on adversarial attacks are insufficient in both attacking ability and human imperceptibility due to their sole focus on the scope of language. This paper proposes a novel vision-fused attack (VFA) framework to acquire powerful adversarial text, i.e., more aggressive and stealthy. Regarding the attacking ability, we design the vision-merged solution space enhancement strategy to enlarge the limited semantic solution space, which enables us to search for adversarial candidates with higher attacking ability. For human imperceptibility, we propose the perception-retained adversarial text selection strategy to align the human text-reading mechanism. Thus, the finally selected adversarial text could be more deceptive. Extensive experiments on various models, including large language models (LLMs) like LLaMA and GPT-3.5, strongly support that VFA outperforms the comparisons by large margins (up to 81%/14% improvements on ASR/SSIM).\n",
            "Score: 2.5\n",
            "\n",
            "Document: 935|||| \n",
            "'arxiv_id': arXiv:2407.18611, \n",
            "'paper_link': https://arxiv.org/abs/2407.18611, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.18611, \n",
            "Title: IOVS4NeRF:Incremental Optimal View Selection for Large-Scale NeRFs \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Neural Radiance Fields (NeRF) have recently demonstrated significant efficiency in the reconstruction of three-dimensional scenes and the synthesis of novel perspectives from a limited set of two-dimensional images. However, large-scale reconstruction using NeRF requires a substantial amount of aerial imagery for training, making it impractical in resource-constrained environments. This paper introduces an innovative incremental optimal view selection framework, IOVS4NeRF, designed to model a 3D scene within a restricted input budget. Specifically, our approach involves adding the existing training set with newly acquired samples, guided by a computed novel hybrid uncertainty of candidate views, which integrates rendering uncertainty and positional uncertainty. By selecting views that offer the highest information gain, the quality of novel view synthesis can be enhanced with minimal additional resources. Comprehensive experiments substantiate the efficiency of our model in realistic scenes, outperforming baselines and similar prior works, particularly under conditions of sparse training data.\n",
            "Score: 2.5\n",
            "\n",
            "Document: 940|||| \n",
            "'arxiv_id': arXiv:2408.00523, \n",
            "'paper_link': https://arxiv.org/abs/2408.00523, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.00523, \n",
            "Title: Jailbreaking Text-to-Image Models with LLM-Based Agents \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: Recent advancements have significantly improved automated task-solving capabilities using autonomous agents powered by large language models (LLMs). However, most LLM-based agents focus on dialogue, programming, or specialized domains, leaving their potential for addressing generative AI safety tasks largely unexplored. In this paper, we propose Atlas, an advanced LLM-based multi-agent framework targeting generative AI models, specifically focusing on jailbreak attacks against text-to-image (T2I) models with built-in safety filters. Atlas consists of two agents, namely the mutation agent and the selection agent, each comprising four key modules: a vision-language model (VLM) or LLM brain, planning, memory, and tool usage. The mutation agent uses its VLM brain to determine whether a prompt triggers the T2I model's safety filter. It then collaborates iteratively with the LLM brain of the selection agent to generate new candidate jailbreak prompts with the highest potential to bypass the filter. In addition to multi-agent communication, we leverage in-context learning (ICL) memory mechanisms and the chain-of-thought (COT) approach to learn from past successes and failures, thereby enhancing Atlas's performance. Our evaluation demonstrates that Atlas successfully jailbreaks several state-of-the-art T2I models equipped with multi-modal safety filters in a black-box setting. Additionally, Atlas outperforms existing methods in both query efficiency and the quality of generated images. This work convincingly demonstrates the successful application of LLM-based agents in studying the safety vulnerabilities of popular text-to-image generation models. We urge the community to consider advanced techniques like ours in response to the rapidly evolving text-to-image generation field.\n",
            "Score: 2.5\n",
            "\n",
            "Document: 982|||| \n",
            "'arxiv_id': arXiv:2408.15915, \n",
            "'paper_link': https://arxiv.org/abs/2408.15915, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.15915, \n",
            "Title: Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The cultivation of expertise for large language models (LLMs) to solve tasks of specific areas often requires special-purpose tuning with calibrated behaviors on the expected stable outputs. To avoid huge cost brought by manual preparation of instruction datasets and training resources up to hundreds of hours, the exploitation of open knowledge including a wealth of low rank adaptation (LoRA) models and instruction datasets serves as a good starting point. However, existing methods on model and data selection focus on the performance of general-purpose capabilities while neglecting the knowledge gap exposed in domain-specific deployment. In the present study, we propose to bridge such gap by introducing few human-annotated samples (i.e., K-shot) for advancing task expertise of LLMs with open knowledge. Specifically, we develop an efficient and scalable pipeline to cost-efficiently produce task experts where K-shot data intervene in selecting the most promising expert candidates and the task-relevant instructions. A mixture-of-expert (MoE) system is built to make the best use of individual-yet-complementary knowledge between multiple experts. We unveil the two keys to the success of a MoE system, 1) the abidance by K-shot, and 2) the insistence on diversity. For the former, we ensure that models that truly possess problem-solving abilities on K-shot are selected rather than those blind guessers. Besides, during data selection, instructions that share task-relevant contexts with K-shot are prioritized. For the latter, we highlight the diversity of constituting experts and that of the fine-tuning instructions throughout the model and data selection process. Extensive experimental results confirm the superiority of our approach over existing methods on utilization of open knowledge across various tasks. Our codes will be available at this https URL.\n",
            "Score: 2.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 1\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"disinformation\", 1),\n",
        "        (\"manipulate public opinion\", 1),\n",
        "        (\"conspiracy\", 1),\n",
        "        (\"radicalization\", 1),\n",
        "        (\"conspiracy theories\", 1),\n",
        "        (\"violent extremism\", 2),\n",
        "\n",
        "        (\"extremism\", 1),\n",
        "        (\"extremist\", 1),\n",
        "        (\"extreme views\", 1),\n",
        "        (\"extreme beliefs\", 1),\n",
        "        (\"extreme action\", 1),\n",
        "        (\"ideology\", .5),        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdmCM3canYCW",
        "outputId": "d56f7955-fc9b-4dcb-90f2-663f40e52cc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: disinformation\n",
            "Total Matches in Set: 0\n",
            "Matches Above Score-Floor in Set: 0\n",
            "2024-09-10__122809886302\n",
            "\n",
            "Showing 0 in top-0 out of 0 total results.     -> 0 of 0/0\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 1) -> 1\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 1\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"Speech-LLM\", 1),\n",
        "\n",
        "        (\"spoken language understanding\", 1),\n",
        "\n",
        "        (\"speech to text\", 1),\n",
        "        (\"text to speech\", 1),\n",
        "\n",
        "        (\"audio modality\", .5),\n",
        "        (\"speech encoder\", .5),\n",
        "        (\"SLU\", .5),\n",
        "        (\"stt\", .5),\n",
        "        (\"tts\", .5),\n",
        "\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHUhj_4zWLME",
        "outputId": "a6a555c0-c774-4180-d906-27047eb36662"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: Speech-LLM\n",
            "Total Matches in Set: 171\n",
            "Matches Above Score-Floor in Set: 4\n",
            "2024-09-10__122810053756\n",
            "\n",
            "Showing 4 in top-45 out of 171 total results.     -> 4 of 45/171\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 1) -> 1\n",
            "\n",
            "\n",
            "Document: 378|||| \n",
            "'arxiv_id': arXiv:2409.05356, \n",
            "'paper_link': https://arxiv.org/abs/2409.05356, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05356, \n",
            "Title: IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source all data and code, releasing the first TTS model for all 22 official Indian languages.\n",
            "Score: 2.0\n",
            "\n",
            "Document: 194|||| \n",
            "'arxiv_id': arXiv:2409.04927, \n",
            "'paper_link': https://arxiv.org/abs/2409.04927, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04927, \n",
            "Title: Just ASR + LLM? A Study on Speech Large Language Models' Ability to Identify and Understand Speaker in Spoken Dialogue \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: In recent years, we have observed a rapid advancement in speech language models (SpeechLLMs), catching up with humans' listening and reasoning abilities. Remarkably, SpeechLLMs have demonstrated impressive spoken dialogue question-answering (SQA) performance in benchmarks like Gaokao, the English listening test of the college entrance exam in China, which seemingly requires understanding both the spoken content and voice characteristics of speakers in a conversation. However, after carefully examining Gaokao's questions, we find the correct answers to many questions can be inferred from the conversation context alone without identifying the speaker asked in the question. Our evaluation of state-of-the-art models Qwen-Audio and WavLLM in both Gaokao and our proposed \"What Do You Like?\" dataset shows a significantly higher accuracy in these context-based questions than in identity-critical questions, which can only be answered correctly with correct speaker identification. Our results and analysis suggest that when solving SQA, the current SpeechLLMs exhibit limited speaker awareness from the audio and behave similarly to an LLM reasoning from the conversation transcription without sound. We propose that our definitions and automated classification of context-based and identity-critical questions could offer a more accurate evaluation framework of SpeechLLMs in SQA tasks.\n",
            "Score: 1.5\n",
            "\n",
            "Document: 231|||| \n",
            "'arxiv_id': arXiv:2409.05004, \n",
            "'paper_link': https://arxiv.org/abs/2409.05004, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05004, \n",
            "Title: Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Voice conversion (VC) aims to modify the speaker's timbre while retaining speech content. Previous approaches have tokenized the outputs from self-supervised into semantic tokens, facilitating disentanglement of speech content information. Recently, in-context learning (ICL) has emerged in text-to-speech (TTS) systems for effectively modeling specific characteristics such as timbre through context conditioning. This paper proposes an ICL capability enhanced VC system (ICL-VC) employing a mask and reconstruction training strategy based on flow-matching generative models. Augmented with semantic tokens, our experiments on the LibriTTS dataset demonstrate that ICL-VC improves speaker similarity. Additionally, we find that k-means is a versatile tokenization method applicable to various pre-trained models. However, the ICL-VC system faces challenges in preserving the prosody of the source speech. To mitigate this issue, we propose incorporating prosody embeddings extracted from a pre-trained emotion recognition model into our system. Integration of prosody embeddings notably enhances the system's capability to preserve source speech prosody, as validated on the Emotional Speech Database.\n",
            "Score: 1.5\n",
            "\n",
            "Document: 510|||| \n",
            "'arxiv_id': arXiv:2409.05674, \n",
            "'paper_link': https://arxiv.org/abs/2409.05674, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05674, \n",
            "Title: Evaluation of real-time transcriptions using end-to-end ASR models \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly evolved in the last few years. Traditional architectures based on pipelines have been replaced by joint end-to-end (E2E) architectures that simplify and streamline the model training process. In addition, new AI training methods, such as weak-supervised learning have reduced the need for high-quality audio datasets for model training. However, despite all these advancements, little to no research has been done on real-time transcription. In real-time scenarios, the audio is not pre-recorded, and the input audio must be fragmented to be processed by the ASR systems. To achieve real-time requirements, these fragments must be as short as possible to reduce latency. However, audio cannot be split at any point as dividing an utterance into two separate fragments will generate an incorrect transcription. Also, shorter fragments provide less context for the ASR model. For this reason, it is necessary to design and test different splitting algorithms to optimize the quality and delay of the resulting transcription. In this paper, three audio splitting algorithms are evaluated with different ASR models to determine their impact on both the quality of the transcription and the end-to-end delay. The algorithms are fragmentation at fixed intervals, voice activity detection (VAD), and fragmentation with feedback. The results are compared to the performance of the same model, without audio fragmentation, to determine the effects of this division. The results show that VAD fragmentation provides the best quality with the highest delay, whereas fragmentation at fixed intervals provides the lowest quality and the lowest delay. The newly proposed feedback algorithm exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively, to the VAD splitting.\n",
            "Score: 1.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = .5\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"multiple agents\", 1),\n",
        "        (\"Multiagent Systems\", 1),\n",
        "        (\"Multiagent\", 1),\n",
        "        (\"(cs.MA)\", 1),\n",
        "        (\"multi-agent and multi-rack path finding\", 1),  #  (MARPF)\n",
        "\n",
        "        (\"agent interactions\", 1),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdHdGAdC9U1a",
        "outputId": "4a0ebfd5-a17b-4bfb-a262-40af473cfdf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: multiple agents\n",
            "Total Matches in Set: 28\n",
            "Matches Above Score-Floor in Set: 28\n",
            "2024-09-10__122810203970\n",
            "\n",
            "Showing 28 in top-28 out of 28 total results.     -> 28 of 28/28\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 0.5) -> 0.5\n",
            "\n",
            "\n",
            "Document: 251|||| \n",
            "'arxiv_id': arXiv:2409.05037, \n",
            "'paper_link': https://arxiv.org/abs/2409.05037, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05037, \n",
            "Title: Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: Deep reinforcement learning (DRL) methods that incorporate graph neural networks (GNNs) have been extensively studied for intelligent traffic signal control, which aims to coordinate traffic signals effectively across multiple intersections. Despite this progress, the standard graph learning used in these methods still struggles to capture higher-order correlations in real-world traffic flow. In this paper, we propose a multi-agent proximal policy optimization framework DHG-PPO, which incorporates PPO and directed hypergraph module to extract the spatio-temporal attributes of the road networks. DHG-PPO enables multiple agents to ingeniously interact through the dynamical construction of hypergraph. The effectiveness of DHG-PPO is validated in terms of average travel time and throughput against state-of-the-art baselines through extensive experiments.\n",
            "Score: 4\n",
            "\n",
            "Document: 55|||| \n",
            "'arxiv_id': arXiv:2409.04613, \n",
            "'paper_link': https://arxiv.org/abs/2409.04613, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04613, \n",
            "Title: Decentralized Learning in General-sum Markov Games \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: The Markov game framework is widely used to model interactions among agents with heterogeneous utilities in dynamic and uncertain societal-scale systems. In these systems, agents typically operate in a decentralized manner due to privacy and scalability concerns, often acting without any information about other agents. The design and analysis of decentralized learning algorithms that provably converge to rational outcomes remain elusive, especially beyond Markov zero-sum games and Markov potential games, which do not adequately capture the nature of many real-world interactions that is neither fully competitive nor fully cooperative. This paper investigates the design of decentralized learning algorithms for general-sum Markov games, aiming to provide provable guarantees of convergence to approximate Nash equilibria in the long run. Our approach builds on constructing a Markov Near-Potential Function (MNPF) to address the intractability of designing algorithms that converge to exact Nash equilibria. We demonstrate that MNPFs play a central role in ensuring the convergence of an actor-critic-based decentralized learning algorithm to approximate Nash equilibria. By leveraging a two-timescale approach, where Q-function estimates are updated faster than policy updates, we show that the system converges to a level set of the MNPF over the set of approximate Nash equilibria. This convergence result is further strengthened if the set of Nash equilibria is assumed to be finite. Our findings provide a new perspective on the analysis and design of decentralized learning algorithms in multi-agent systems.\n",
            "Score: 3\n",
            "\n",
            "Document: 283|||| \n",
            "'arxiv_id': arXiv:2409.05119, \n",
            "'paper_link': https://arxiv.org/abs/2409.05119, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05119, \n",
            "Title: Enhancing the Performance of Multi-Vehicle Navigation in Unstructured Environments using Hard Sample Mining \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: Contemporary research in autonomous driving has demonstrated tremendous potential in emulating the traits of human driving. However, they primarily cater to areas with well built road infrastructure and appropriate traffic management systems. Therefore, in the absence of traffic signals or in unstructured environments, these self-driving algorithms are expected to fail. This paper proposes a strategy for autonomously navigating multiple vehicles in close proximity to their desired destinations without traffic rules in unstructured environments.\n",
            "Graphical Neural Networks (GNNs) have demonstrated good utility for this task of multi-vehicle control. Among the different alternatives of training GNNs, supervised methods have proven to be most data-efficient, albeit require ground truth labels. However, these labels may not always be available, particularly in unstructured environments without traffic regulations. Therefore, a tedious optimization process may be required to determine them while ensuring that the vehicles reach their desired destination and do not collide with each other or any obstacles. Therefore, in order to expedite the training process, it is essential to reduce the optimization time and select only those samples for labeling that add most value to the training. In this paper, we propose a warm start method that first uses a pre-trained model trained on a simpler subset of data. Inference is then done on more complicated scenarios, to determine the hard samples wherein the model faces the greatest predicament. This is measured by the difficulty vehicles encounter in reaching their desired destination without collision. Experimental results demonstrate that mining for hard samples in this manner reduces the requirement for supervised training data by 10 fold. Videos and code can be found here: \\url{this https URL}.\n",
            "Score: 3\n",
            "\n",
            "Document: 856|||| \n",
            "'arxiv_id': arXiv:2405.07541, \n",
            "'paper_link': https://arxiv.org/abs/2405.07541, \n",
            "'pdf_link': https://arxiv.org/pdf/2405.07541, \n",
            "Title: Random walk model that universally generates inverse square L\\'evy walk by eliminating search cost minimization constraint \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: The Lévy walk, a type of random walk characterized by linear step lengths that follow a power-law distribution, is observed in the migratory behaviors of various organisms, ranging from bacteria to humans. Notably, Lévy walks with power exponents close to two are frequently observed, though their underlying causes remain elusive. This study introduces a simplified, abstract random walk model designed to produce inverse square Lévy walks, also known as Cauchy walks and explores the conditions that facilitate these phenomena. In our model, agents move toward a randomly selected destination in multi-dimensional space, and their movement strategy is parameterized by the extent to which they pursue the shortest path. When the search cost is proportional to the distance traveled, this parameter effectively reflects the emphasis on minimizing search costs. Our findings reveal that strict adherence to this cost minimization constraint results in a Brownian walk pattern. However, removing this constraint transitions the movement to an inverse square Lévy walk. Therefore, by modulating the prioritization of search costs, our model can seamlessly alternate between Brownian and Cauchy walk dynamics. This model has the potential to be utilized for exploring the parameter space of an optimization problem.\n",
            "Score: 3\n",
            "\n",
            "Document: 880|||| \n",
            "'arxiv_id': arXiv:2406.04231, \n",
            "'paper_link': https://arxiv.org/abs/2406.04231, \n",
            "'pdf_link': https://arxiv.org/pdf/2406.04231, \n",
            "Title: Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and/or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agents' weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications.\n",
            "Score: 3\n",
            "\n",
            "Document: 899|||| \n",
            "'arxiv_id': arXiv:2407.00629, \n",
            "'paper_link': https://arxiv.org/abs/2407.00629, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.00629, \n",
            "Title: Identification of LFT Structured Descriptor Systems with Slow and Non-uniform Sampling \n",
            "Subjects: Multiagent Systems (cs.MA) \n",
            "Abstract: Time domain identification is studied in this paper for parameters of a continuous-time multi-input multi-output descriptor system, with these parameters affecting system matrices through a linear fractional transformation. Sampling is permitted to be slow and non-uniform, and there are no necessities to satisfy the Nyquist frequency restrictions. This model can be used to described the behaviors of a networked dynamic system, and the obtained results can be straightforwardly applied to an ordinary state-space model, as well as a lumped system. An explicit formula is obtained respectively for the transient and steady-state responses of the system stimulated by an arbitrary signal. Some relations have been derived between the system steady-state response and its transfer function matrix (TFM), which reveal that the value of a TFM at almost any interested point, as well as its derivatives and a right tangential interpolation along an arbitrary direction, can in principle be estimated from input-output experimental data. Based on these relations, an estimation algorithm is suggested respectively for the parameters of the descriptor system and the values of its TFM. Their properties like asymptotic unbiasedness, consistency, etc., are analyzed. A simple numerical example is included to illustrate characteristics of the suggested estimation algorithms.\n",
            "Score: 3\n",
            "\n",
            "Document: 165|||| \n",
            "'arxiv_id': arXiv:2409.04854, \n",
            "'paper_link': https://arxiv.org/abs/2409.04854, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04854, \n",
            "Title: Adaptation Procedure in Misinformation Games \n",
            "Subjects: Computer Science and Game Theory (cs.GT) \n",
            "Abstract: We study interactions between agents in multi-agent systems, in which the agents are misinformed with regards to the game that they play, essentially having a subjective and incorrect understanding of the setting, without being aware of it. For that, we introduce a new game-theoretic concept, called misinformation games, that provides the necessary toolkit to study this situation. Subsequently, we enhance this framework by developing a time-discrete procedure (called the Adaptation Procedure) that captures iterative interactions in the above context. During the Adaptation Procedure, the agents update their information and reassess their behaviour in each step. We demonstrate our ideas through an implementation, which is used to study the efficiency and characteristics of the Adaptation Procedure.\n",
            "Score: 2\n",
            "\n",
            "Document: 280|||| \n",
            "'arxiv_id': arXiv:2409.05106, \n",
            "'paper_link': https://arxiv.org/abs/2409.05106, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05106, \n",
            "Title: Decentralized Control of Multi-Agent Systems Under Acyclic Spatio-Temporal Task Dependencies \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: We introduce a novel distributed sampled-data control method tailored for heterogeneous multi-agent systems under a global spatio-temporal task with acyclic dependencies. Specifically, we consider the global task as a conjunction of independent and collaborative tasks, defined over the absolute and relative states of agent pairs. Task dependencies in this form are then represented by a task graph, which we assume to be acyclic. From the given task graph, we provide an algorithmic approach to define a distributed sampled-data controller prioritizing the fulfilment of collaborative tasks as the primary objective, while fulfilling independent tasks unless they conflict with collaborative ones. Moreover, communication maintenance among collaborating agents is seamlessly enforced within the proposed control framework. A numerical simulation is provided to showcase the potential of our control framework.\n",
            "Score: 2\n",
            "\n",
            "Document: 282|||| \n",
            "'arxiv_id': arXiv:2409.05113, \n",
            "'paper_link': https://arxiv.org/abs/2409.05113, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05113, \n",
            "Title: Nonlinear Cooperative Output Regulation with Input Delay Compensation \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: This paper investigates the cooperative output regulation (COR) of nonlinear multi-agent systems (MASs) with long input delay based on periodic event-triggered mechanism. Compared with other mechanisms, periodic event-triggered control can automatically guarantee a Zeno-free behavior and avoid the continuous monitoring of triggered conditions. First, a new periodic event-triggered distributed observer, which is based on the fully asynchronous communication data, is proposed to estimate the leader information. Second, a new distributed predictor feedback control method is proposed for the considered nonlinear MASs with input delay. By coordinate transformation, the MASs are mapped into new coupled ODE-PDE target systems with some disturbance-like terms. Then, we show that the COR problem is solvable. At last, to further save the communication resource, a periodic event-triggered mechanism is considered in the sensor-to-controller transmission in every agent. A new periodic event-triggered filter is proposed to deal with the periodic event-triggered feedback data. The MASs with input delay are mapped into coupled ODE-PDE target systems with sampled data information. Then, Lyapunov-Krasovskii functions are constructed to demonstrate the exponential stability of the MASs. Simulations verify the validity of the proposed results.\n",
            "Score: 2\n",
            "\n",
            "Document: 350|||| \n",
            "'arxiv_id': arXiv:2409.05293, \n",
            "'paper_link': https://arxiv.org/abs/2409.05293, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05293, \n",
            "Title: Distributed Robust Continuous-Time Optimization Algorithms for Time-Varying Constrained Cost \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: This paper presents a distributed continuous-time optimization framework aimed at overcoming the challenges posed by time-varying cost functions and constraints in multi-agent systems, particularly those subject to disturbances. By incorporating tools such as log-barrier penalty functions to address inequality constraints, an integral sliding mode control for disturbance mitigation is proposed. The algorithm ensures asymptotic tracking of the optimal solution, achieving a tracking error of zero. The convergence of the introduced algorithms is demonstrated through Lyapunov analysis and nonsmooth techniques. Furthermore, the framework's effectiveness is validated through numerical simulations considering two scenarios for the communication networks.\n",
            "Score: 2\n",
            "\n",
            "Document: 467|||| \n",
            "'arxiv_id': arXiv:2409.05556, \n",
            "'paper_link': https://arxiv.org/abs/2409.05556, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05556, \n",
            "Title: SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations. Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a `swarm of intelligence' similar to biological systems. This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature's design principles.\n",
            "Score: 2\n",
            "\n",
            "Document: 619|||| \n",
            "'arxiv_id': arXiv:2409.05155, \n",
            "'paper_link': https://arxiv.org/abs/2409.05155, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05155, \n",
            "Title: Difference Between Cyclic and Distributed Approach in Stochastic Optimization for Multi-agent System \n",
            "Subjects: Optimization and Control (math.OC) \n",
            "Abstract: Many stochastic optimization problems in multi-agent systems can be decomposed into smaller subproblems or reduced decision subspaces. The cyclic and distributed approaches are two widely used strategies for solving such problems. In this manuscript, we review four existing methods for addressing these problems and compare them based on their suitable problem frameworks and update rules.\n",
            "Score: 2\n",
            "\n",
            "Document: 174|||| \n",
            "'arxiv_id': arXiv:2409.04880, \n",
            "'paper_link': https://arxiv.org/abs/2409.04880, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04880, \n",
            "Title: Towards identifying Source credibility on Information Leakage in Digital Gadget Market \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: The use of Social media to share content is on a constant rise. One of the capsize effect of information sharing on Social media includes the spread of sensitive information on the public domain. With the digital gadget market becoming highly competitive and ever-evolving, the trend of an increasing number of sensitive posts leaking information on devices in social media is observed. Many web-blogs on digital gadget market have mushroomed recently, making the problem of information leak all pervasive. Credible leaks on specifics of an upcoming device can cause a lot of financial damage to the respective organization. Hence, it is crucial to assess the credibility of the platforms that continuously post about a smartphone or digital gadget leaks. In this work, we analyze the headlines of leak web-blog posts and their corresponding official press-release. We first collect 54, 495 leak and press-release headlines for different smartphones. We train our custom NER model to capture the evolving smartphone names with an accuracy of 82.14% on manually annotated results. We further propose a credibility score metric for the web-blog, based on the number of falsified and authentic smartphone leak posts.\n",
            "Score: 1\n",
            "\n",
            "Document: 244|||| \n",
            "'arxiv_id': arXiv:2409.05025, \n",
            "'paper_link': https://arxiv.org/abs/2409.05025, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05025, \n",
            "Title: Cooperative Learning-Based Framework for VNF Caching and Placement Optimization over Low Earth Orbit Satellite Networks \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: Low Earth Orbit Satellite Networks (LSNs) are integral to supporting a broad range of modern applications, which are typically modeled as Service Function Chains (SFCs). Each SFC is composed of Virtual Network Functions (VNFs), where each VNF performs a specific task. In this work, we tackle two key challenges in deploying SFCs across an LSN. Firstly, we aim to optimize the long-term system performance by minimizing the average end-to-end SFC execution delay, given that each satellite comes with a pre-installed/cached subset of VNFs. To achieve optimal SFC placement, we formulate an offline Dynamic Programming (DP) equation. To overcome the challenges associated with DP, such as its complexity, the need for probability knowledge, and centralized decision-making, we put forth an online Multi-Agent Q-Learning (MAQL) solution. Our MAQL approach addresses convergence issues in the non-stationary LSN environment by enabling satellites to share learning parameters and update their Q-tables based on distinct rules for their selected actions. Secondly, to determine the optimal VNF subsets for satellite caching, we develop a Bayesian Optimization (BO)-based learning mechanism that operates both offline and continuously in the background during runtime. Extensive experiments demonstrate that our MAQL approach achieves near-optimal performance comparable to the DP model and significantly outperforms existing baselines. Moreover, the BO-based approach effectively enhances the request serving rate over time.\n",
            "Score: 1\n",
            "\n",
            "Document: 435|||| \n",
            "'arxiv_id': arXiv:2409.05480, \n",
            "'paper_link': https://arxiv.org/abs/2409.05480, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05480, \n",
            "Title: Adaptive Multi-Layer Deployment for A Digital Twin Empowered Satellite-Terrestrial Integrated Network \n",
            "Subjects: Networking and Internet Architecture (cs.NI) \n",
            "Abstract: With the development of satellite communication technology, satellite-terrestrial integrated networks (STIN), which integrate satellite networks and ground networks, can realize seamless global coverage of communication services. Confronting the intricacies of network dynamics, the diversity of resource heterogeneity, and the unpredictability of user mobility, dynamic resource allocation within networks faces formidable challenges. Digital twin (DT), as a new technique, can reflect a physical network to a virtual network to monitor, analyze, and optimize the physical network. Nevertheless, in the process of constructing the DT model, the deployment location and resource allocation of DTs may adversely affect its performance. Therefore, we propose a STIN model, which alleviates the problem of insufficient single-layer deployment flexibility of the traditional edge network by deploying DTs in multi-layer nodes in a STIN. To address the challenge of deploying DTs in the network, we propose multi-layer DT deployment in a STIN to reduce system delay. Then we adopt a multi-agent reinforcement learning (MARL) scheme to explore the optimal strategy of the DT multi-layer deployment problem. The implemented scheme demonstrates a notable reduction in system delay, as evidenced by simulation outcomes.\n",
            "Score: 1\n",
            "\n",
            "Document: 524|||| \n",
            "'arxiv_id': arXiv:2409.05712, \n",
            "'paper_link': https://arxiv.org/abs/2409.05712, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05712, \n",
            "Title: Cooperative Decision-Making for CAVs at Unsignalized Intersections: A MARL Approach with Attention and Hierarchical Game Priors \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems. However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles. While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors. In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations. Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents. The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety. Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort.\n",
            "Score: 1\n",
            "\n",
            "Document: 598|||| \n",
            "'arxiv_id': arXiv:2409.04821, \n",
            "'paper_link': https://arxiv.org/abs/2409.04821, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04821, \n",
            "Title: Adjacency Labeling Schemes for Small Classes \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: A graph class admits an implicit representation if, for every positive integer $n$, its $n$-vertex graphs have a $O(\\log n)$-bit (adjacency) labeling scheme, i.e., their vertices can be labeled by binary strings of length $O(\\log n)$ such that the presence of an edge between any pair of vertices can be deduced solely from their labels. The famous Implicit Graph Conjecture posited that every hereditary (i.e., closed under taking induced subgraphs) factorial (i.e., containing $2^{O(n \\log n)}$ $n$-vertex graphs) class admits an implicit representation. The conjecture was recently refuted [Hatami and Hatami, FOCS '22], and does not even hold among monotone (i.e., closed under taking subgraphs) factorial classes [Bonnet et al., ICALP '24]. However, monotone small (i.e., containing at most $n! c^n$ many $n$-vertex graphs for some constant $c$) classes do admit implicit representations.\n",
            "This motivates the Small Implicit Graph Conjecture: Every hereditary small class admits an $O(\\log n)$-bit labeling scheme. We provide evidence supporting the Small Implicit Graph Conjecture. First, we show that every small weakly sparse (i.e., excluding some fixed bipartite complete graph as a subgraph) class has an implicit representation. This is a consequence of the following fact of independent interest proved in the paper: Every weakly sparse small class has bounded expansion (hence, in particular, bounded degeneracy). Second, we show that every hereditary small class admits an $O(\\log^3 n)$-bit labeling scheme, which provides a substantial improvement of the best-known polynomial upper bound of $n^{1-\\varepsilon}$ on the size of adjacency labeling schemes for such classes. This is a consequence of another fact of independent interest proved in the paper: Every small class has neighborhood complexity $O(n \\log n)$.\n",
            "Score: 1\n",
            "\n",
            "Document: 645|||| \n",
            "'arxiv_id': arXiv:2409.05678, \n",
            "'paper_link': https://arxiv.org/abs/2409.05678, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05678, \n",
            "Title: A step towards finding the analog of the Four-Color Theorem for $(n,m)$-graphs \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: An \\textit{$(n,m)$-graph} $G$ is a graph having both arcs and edges, and its arcs (resp., edges) are labeled using one of the $n$ (resp., $m$) different symbols. An \\textit{$(n,m)$-complete graph} $G$ is an $(n,m)$-graph without loops or multiple edges in its underlying graph such that identifying any pair of vertices results in a loop or parallel adjacencies with distinct labels. We show that a planar $(n,m)$-complete graph cannot have more than $3(2n+m)^2+(2n+m)+1$ vertices, for all $(n,m) \\neq (0,1)$ and the bound is tight. This answers a naturally fundamental extremal question in the domain of homomorphisms of $(n,m)$-graphs and positively settles a recent conjecture by Bensmail \\textit{et al.}~[Graphs and Combinatorics 2017]. Essentially, our result finds the clique number for planar $(n,m)$-graphs, which is a difficult problem except when $(n,m)=(0,1)$, answering a sub-question to finding the chromatic number for the family of planar $(n,m)$-graphs.\n",
            "Score: 1\n",
            "\n",
            "Document: 672|||| \n",
            "'arxiv_id': arXiv:2302.09620, \n",
            "'paper_link': https://arxiv.org/abs/2302.09620, \n",
            "'pdf_link': https://arxiv.org/pdf/2302.09620, \n",
            "Title: Jointly Complementary&Competitive Influence Maximization with Concurrent Ally-Boosting and Rival-Preventing \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: In this paper, we propose a new influence spread model, namely, Complementary\\&Competitive Independent Cascade (C$^2$IC) model. C$^2$IC model generalizes three well known influence model, i.e., influence boosting (IB) model, campaign oblivious (CO)IC model and the IC-N (IC model with negative opinions) model. This is the first model that considers both complementary and competitive influence spread comprehensively under multi-agent environment. Correspondingly, we propose the Complementary\\&Competitive influence maximization (C$^2$IM) problem. Given an ally seed set and a rival seed set, the C$^2$IM problem aims to select a set of assistant nodes that can boost the ally spread and prevent the rival spread concurrently. We show the problem is NP-hard and can generalize the influence boosting problem and the influence blocking problem. With classifying the different cascade priorities into 4 cases by the monotonicity and submodularity (M\\&S) holding conditions, we design 4 algorithms respectively, with theoretical approximation bounds provided. We conduct extensive experiments on real social networks and the experimental results demonstrate the effectiveness of the proposed algorithms. We hope this work can inspire abundant future exploration for constructing more generalized influence models that help streamline the works of this area.\n",
            "Score: 1\n",
            "\n",
            "Document: 683|||| \n",
            "'arxiv_id': arXiv:2304.12653, \n",
            "'paper_link': https://arxiv.org/abs/2304.12653, \n",
            "'pdf_link': https://arxiv.org/pdf/2304.12653, \n",
            "Title: Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Traditional multi-agent reinforcement learning algorithms are difficultly applied in a large-scale multi-agent environment. The introduction of mean field theory has enhanced the scalability of multi-agent reinforcement learning in recent years. This paper considers partially observable multi-agent reinforcement learning (MARL), where each agent can only observe other agents within a fixed range. This partial observability affects the agent's ability to assess the quality of the actions of surrounding agents. This paper focuses on developing a method to capture more effective information from local observations in order to select more effective actions. Previous work in this field employs probability distributions or weighted mean field to update the average actions of neighborhood agents, but it does not fully consider the feature information of surrounding neighbors and leads to a local optimum. In this paper, we propose a novel multi-agent reinforcement learning algorithm, Partially Observable Mean Field Multi-Agent Reinforcement Learning based on Graph-Attention (GAMFQ) to remedy this flaw. GAMFQ uses a graph attention module and a mean field module to describe how an agent is influenced by the actions of other agents at each time step. This graph attention module consists of a graph attention encoder and a differentiable attention mechanism, and this mechanism outputs a dynamic graph to represent the effectiveness of neighborhood agents against central agents. The mean-field module approximates the effect of a neighborhood agent on a central agent as the average effect of effective neighborhood agents. Experiments show that GAMFQ outperforms baselines including the state-of-the-art partially observable mean-field reinforcement learning algorithms. The code for this paper is here \\url{this https URL}.\n",
            "Score: 1\n",
            "\n",
            "Document: 755|||| \n",
            "'arxiv_id': arXiv:2401.00747, \n",
            "'paper_link': https://arxiv.org/abs/2401.00747, \n",
            "'pdf_link': https://arxiv.org/pdf/2401.00747, \n",
            "Title: Geometric Structure and Polynomial-time Algorithm of Game Equilibriums \n",
            "Subjects: Computer Science and Game Theory (cs.GT) \n",
            "Abstract: Whether a PTAS (polynomial-time approximation scheme) exists for game equilibriums has been an open question, and the absence of this polynomial-time algorithm has indications and consequences in three fields, such as the practicality of methods in algorithmic game theory, non-stationarity and curse of multiagency in MARL (multi-agent reinforcement learning), and the tractability of PPAD in computational complexity theory. In this paper, we introduce a geometric object called equilibrium bundle, which leads to a fundamental leap in the understanding of game equilibriums. Regarding the equilibrium bundle, first, we formalize perfect equilibriums of dynamic games as the zero points of its canonical section, second, we formalize a hybrid iteration of dynamic programming and interior point method as a line search on it, such that the method is an FPTAS (fully PTAS) for any perfect equilibrium of any dynamic game, implying PPAD=FP, third, we give the existence and oddness theorems of it as an extension of those of Nash equilibriums. As intermediate results, we introduce a concept called policy cone to give the sufficient and necessary condition for dynamic programming to converge to perfect equilibriums, and introduce two concepts called unbiased barrier problem and unbiased KKT conditions to make the interior point method to approximate Nash equilibriums. In experiment, the line search process is animated, and the method is tested on 2000 randomly generated dynamic games where it converges to a perfect equilibrium in every single case.\n",
            "Score: 1\n",
            "\n",
            "Document: 900|||| \n",
            "'arxiv_id': arXiv:2407.02263, \n",
            "'paper_link': https://arxiv.org/abs/2407.02263, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.02263, \n",
            "Title: FreeCG: Free the Design Space of Clebsch-Gordan Transform for Machine Learning Force Fields \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Machine Learning Force Fields (MLFFs) are of great importance for chemistry, physics, materials science, and many other related fields. The Clebsch-Gordan Transform (CG transform) effectively encodes many-body interactions and is thus an important building block for many models of MLFFs. However, the permutation-equivariance requirement of MLFFs limits the design space of CG transform, that is, intensive CG transform has to be conducted for each neighboring edge and the operations should be performed in the same manner for all edges. This constraint results in reduced expressiveness of the model while simultaneously increasing computational demands. To overcome this challenge, we first implement the CG transform layer on the permutation-invariant abstract edges generated from real edge information. We show that this approach allows complete freedom in the design of the layer without compromising the crucial symmetry. Developing on this free design space, we further propose group CG transform with sparse path, abstract edges shuffling, and attention enhancer to form a powerful and efficient CG transform layer. Our method, known as FreeCG, achieves state-of-the-art (SOTA) results in force prediction for MD17, rMD17, MD22, and is well extended to property prediction in QM9 datasets with several improvements greater than 15% and the maximum beyond 20%. The extensive real-world applications showcase high practicality. FreeCG introduces a novel paradigm for carrying out efficient and expressive CG transform in future geometric neural network designs. To demonstrate this, the recent SOTA, QuinNet, is also enhanced under our paradigm. Code will be publicly available.\n",
            "Score: 1\n",
            "\n",
            "Document: 940|||| \n",
            "'arxiv_id': arXiv:2408.00523, \n",
            "'paper_link': https://arxiv.org/abs/2408.00523, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.00523, \n",
            "Title: Jailbreaking Text-to-Image Models with LLM-Based Agents \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: Recent advancements have significantly improved automated task-solving capabilities using autonomous agents powered by large language models (LLMs). However, most LLM-based agents focus on dialogue, programming, or specialized domains, leaving their potential for addressing generative AI safety tasks largely unexplored. In this paper, we propose Atlas, an advanced LLM-based multi-agent framework targeting generative AI models, specifically focusing on jailbreak attacks against text-to-image (T2I) models with built-in safety filters. Atlas consists of two agents, namely the mutation agent and the selection agent, each comprising four key modules: a vision-language model (VLM) or LLM brain, planning, memory, and tool usage. The mutation agent uses its VLM brain to determine whether a prompt triggers the T2I model's safety filter. It then collaborates iteratively with the LLM brain of the selection agent to generate new candidate jailbreak prompts with the highest potential to bypass the filter. In addition to multi-agent communication, we leverage in-context learning (ICL) memory mechanisms and the chain-of-thought (COT) approach to learn from past successes and failures, thereby enhancing Atlas's performance. Our evaluation demonstrates that Atlas successfully jailbreaks several state-of-the-art T2I models equipped with multi-modal safety filters in a black-box setting. Additionally, Atlas outperforms existing methods in both query efficiency and the quality of generated images. This work convincingly demonstrates the successful application of LLM-based agents in studying the safety vulnerabilities of popular text-to-image generation models. We urge the community to consider advanced techniques like ours in response to the rapidly evolving text-to-image generation field.\n",
            "Score: 1\n",
            "\n",
            "Document: 957|||| \n",
            "'arxiv_id': arXiv:2408.08688, \n",
            "'paper_link': https://arxiv.org/abs/2408.08688, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.08688, \n",
            "Title: The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: This paper presents synthetic Preference Optimization (PO) datasets generated using multi-agent workflows and evaluates the effectiveness and potential of these workflows in the dataset generation process. PO dataset generation requires two modules: (1) response evaluation, and (2) response generation. In the response evaluation module, the responses from Large Language Models (LLMs) are evaluated and ranked - a task typically carried out by human annotators that we automate using LLMs. We assess the response evaluation module in a 2 step process. In step 1, we assess LLMs as evaluators using three distinct prompting strategies. In step 2, we apply the winning prompting strategy to compare the performance of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. In each step, we use inter-rater agreement using Cohen's Kappa between human annotators and LLMs. For the response generation module, we compare different configurations for the LLM Feedback Loop using the identified LLM evaluator configuration. We use the win rate (the fraction of times a generation framework is selected as the best by an LLM evaluator) to determine the best multi-agent configuration for generation. After identifying the best configurations for both modules, we use models from the GPT, Gemma, and Llama families to generate our PO datasets using the above pipeline. We generate two types of PO datasets, one to improve the generation capabilities of individual LLM and the other to improve the multi-agent workflow. Our evaluation shows that GPT-4o-as-a-Judge is more consistent across datasets when the candidate responses do not include responses from the GPT family. Additionally, we find that the LLM Feedback Loop, with Llama as the generator and Gemma as the reviewer, achieves a notable 71.8% and 73.8% win rate over single-agent Llama and Gemma, respectively.\n",
            "Score: 1\n",
            "\n",
            "Document: 1043|||| \n",
            "'arxiv_id': arXiv:2302.07170, \n",
            "'paper_link': https://arxiv.org/abs/2302.07170, \n",
            "'pdf_link': https://arxiv.org/pdf/2302.07170, \n",
            "Title: Characterizing the Degree-Kirchhoff, Gutman, and Schultz Indices in Pentagonal Cylinders and M\\\"{o}bius Chains \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: The degree-Kirchhoff index of a connected graph is defined as the sum of the reciprocals of the non-zero eigenvalues of the normalized Laplacian matrix, each multiplied by the graph's total degree. Several studies have recently obtained explicit formulations for the degree-Kirchhoff index of various kinds of class graphs. This paper presents closed-form formulas for the degree-Kirchhoff index of pentagonal cylinders and Möbius chains. Additionally, we calculate the Gutman index and Schultz index for these graphs.\n",
            "Score: 1\n",
            "\n",
            "Document: 1054|||| \n",
            "'arxiv_id': arXiv:2311.07995, \n",
            "'paper_link': https://arxiv.org/abs/2311.07995, \n",
            "'pdf_link': https://arxiv.org/pdf/2311.07995, \n",
            "Title: EPPA numbers of graphs \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: If $G$ is a graph, $A$ and $B$ its induced subgraphs, and $f\\colon A\\to B$ an isomorphism, we say that $f$ is a \\emph{partial automorphism} of $G$. In 1992, Hrushovski proved that graphs have the \\emph{extension property for partial automorphisms} (\\emph{EPPA}, also called the \\emph{Hrushovski property}), that is, for every finite graph $G$ there is a finite graph $H$, an \\emph{EPPA-witness} for $G$, such that $G$ is an induced subgraph of $H$ and every partial automorphism of $G$ extends to an automorphism of $H$.\n",
            "The EPPA number of a graph $G$, denoted by $\\mathop{\\mathrm{eppa}}\\nolimits(G)$, is the smallest number of vertices of an EPPA-witness for $G$, and we put $\\mathop{\\mathrm{eppa}}\\nolimits(n) = \\max\\{\\mathop{\\mathrm{eppa}}\\nolimits(G) : \\lvert G\\rvert = n\\}$. In this note we review the state of the area, prove several lower bounds (in particular, we show that $\\mathop{\\mathrm{eppa}}\\nolimits(n)\\geq \\frac{2^n}{\\sqrt{n}}$, thereby identifying the correct base of the exponential) and pose many open questions. We also briefly discuss EPPA numbers of hypergraphs, directed graphs, and $K_k$-free graphs.\n",
            "Score: 1\n",
            "\n",
            "Document: 1058|||| \n",
            "'arxiv_id': arXiv:2401.06618, \n",
            "'paper_link': https://arxiv.org/abs/2401.06618, \n",
            "'pdf_link': https://arxiv.org/pdf/2401.06618, \n",
            "Title: Stabiliser codes over fields of even order \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: We prove that the natural isomorphism between GF(2^h) and GF(2)^h induces a bijection between stabiliser codes on n quqits with local dimension q=2^h and binary stabiliser codes on hn qubits. This allows us to describe these codes geometrically: a stabiliser code over a field of even order corresponds to a so-called quantum set of symplectic polar spaces. Moreover, equivalent stabiliser codes have a similar geometry, which can be used to prove the uniqueness of a [[4,0,3]]_4 stabiliser code and the nonexistence of both a [[7,1,4]]_4 and an [[8,0,5]]_4 stabiliser code.\n",
            "Score: 1\n",
            "\n",
            "Document: 1087|||| \n",
            "'arxiv_id': arXiv:2408.02548, \n",
            "'paper_link': https://arxiv.org/abs/2408.02548, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.02548, \n",
            "Title: Higher weight spectra and Betti numbers of Reed-Muller codes $RM_q(2,2)$ \n",
            "Subjects: Combinatorics (math.CO) \n",
            "Abstract: We determine the higher weight spectra of $q$-ary Reed-Muller codes $C_q=RM_q(2,2)$ for all prime powers $q$. This is equivalent to finding the usual weight distributions of all extension codes of $C_q$ over every field extension of $F_q$ of finite degree. To obtain our results we will utilize well-known connections between these weights and properties of the Stanley-Reisner rings of a series of matroids associated to each code $C_q$. In the process, we are able to explicitly determine all the graded Betti numbers of matroids associated to $C_q$ and its elongations.\n",
            "Score: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = .5\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"Agents for Software Engineering\", .5),\n",
        "        (\"ai writing code\", .5),\n",
        "        (\"coding done by ai\", .5),\n",
        "        (\"AI-Generated Code\", .5),\n",
        "        (\"Generated Code\", .5),\n",
        "        (\"code generation\", .5),\n",
        "        (\"ai code writing\", .5),\n",
        "        (\"solutions to produce computer code\", .5),\n",
        "        (\"Generated Code\", .5),\n",
        "\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w24GXHdtcVgr",
        "outputId": "6b915618-9649-440d-9639-2b220e0f717c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: Agents for Software Engineering\n",
            "Total Matches in Set: 6\n",
            "Matches Above Score-Floor in Set: 6\n",
            "2024-09-10__122810365840\n",
            "\n",
            "Showing 6 in top-6 out of 6 total results.     -> 6 of 6/6\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 0.5) -> 0.5\n",
            "\n",
            "\n",
            "Document: 834|||| \n",
            "'arxiv_id': arXiv:2404.15639, \n",
            "'paper_link': https://arxiv.org/abs/2404.15639, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.15639, \n",
            "Title: CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Large Language Models (LLMs) have achieved remarkable progress in code generation. It now becomes crucial to identify whether the code is AI-generated and to determine the specific model used, particularly for purposes such as protecting Intellectual Property (IP) in industry and preventing cheating in programming exercises. To this end, several attempts have been made to insert watermarks into machine-generated code. However, existing approaches are limited to inserting only a single bit of information or overly depending on particular code patterns. In this paper, we introduce CodeIP, a novel multi-bit watermarking technique that embeds additional information to preserve crucial provenance details, such as the vendor ID of an LLM, thereby safeguarding the IPs of LLMs in code generation. Furthermore, to ensure the syntactical correctness of the generated code, we propose constraining the sampling process for predicting the next token by training a type predictor. Experiments conducted on a real-world dataset across five programming languages demonstrate the effectiveness of CodeIP in watermarking LLMs for code generation while maintaining the syntactical correctness of code.\n",
            "Score: 1.5\n",
            "\n",
            "Document: 230|||| \n",
            "'arxiv_id': arXiv:2409.05001, \n",
            "'paper_link': https://arxiv.org/abs/2409.05001, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05001, \n",
            "Title: A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement \n",
            "Subjects: Software Engineering (cs.SE) \n",
            "Abstract: Large language models (LLMs) have achieved impressive performance on code generation. Although prior studies enhanced LLMs with prompting techniques and code refinement, they still struggle with complex programming problems due to rigid solution plans. In this paper, we draw on pair programming practices to propose PairCoder, a novel LLM-based framework for code generation. PairCoder incorporates two collaborative LLM agents, namely a Navigator agent for high-level planning and a Driver agent for specific implementation. The Navigator is responsible for proposing promising solution plans, selecting the current optimal plan, and directing the next iteration round based on execution feedback. The Driver follows the guidance of Navigator to undertake initial code generation, code testing, and refinement. This interleaved and iterative workflow involves multi-plan exploration and feedback-based refinement, which mimics the collaboration of pair programmers. We evaluate PairCoder with both open-source and closed-source LLMs on various code generation benchmarks. Extensive experimental results demonstrate the superior accuracy of PairCoder, achieving relative pass@1 improvements of 12.00%-162.43% compared to prompting LLMs directly.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 304|||| \n",
            "'arxiv_id': arXiv:2409.05177, \n",
            "'paper_link': https://arxiv.org/abs/2409.05177, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05177, \n",
            "Title: Insights from Benchmarking Frontier Language Models on Web App Code Generation \n",
            "Subjects: Software Engineering (cs.SE) \n",
            "Abstract: This paper presents insights from evaluating 16 frontier large language models (LLMs) on the WebApp1K benchmark, a test suite designed to assess the ability of LLMs to generate web application code. The results reveal that while all models possess similar underlying knowledge, their performance is differentiated by the frequency of mistakes they make. By analyzing lines of code (LOC) and failure distributions, we find that writing correct code is more complex than generating incorrect code. Furthermore, prompt engineering shows limited efficacy in reducing errors beyond specific cases. These findings suggest that further advancements in coding LLM should emphasize on model reliability and mistake minimization.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 917|||| \n",
            "'arxiv_id': arXiv:2407.10106, \n",
            "'paper_link': https://arxiv.org/abs/2407.10106, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.10106, \n",
            "Title: DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation \n",
            "Subjects: Software Engineering (cs.SE) \n",
            "Abstract: Large Language Models (LLMs) have showcased their remarkable capabilities in diverse domains, encompassing natural language understanding, translation, and even code generation. The potential for LLMs to generate harmful content is a significant concern. This risk necessitates rigorous testing and comprehensive evaluation of LLMs to ensure safe and responsible use. However, extensive testing of LLMs requires substantial computational resources, making it an expensive endeavor. Therefore, exploring cost-saving strategies during the testing phase is crucial to balance the need for thorough evaluation with the constraints of resource availability. To address this, our approach begins by transferring the moderation knowledge from an LLM to a small model. Subsequently, we deploy two distinct strategies for generating malicious queries: one based on a syntax tree approach, and the other leveraging an LLM-based method. Finally, our approach incorporates a sequential filter-test process designed to identify test cases that are prone to eliciting toxic responses. Our research evaluated the efficacy of DistillSeq across four LLMs: GPT-3.5, GPT-4.0, Vicuna-13B, and Llama-13B. In the absence of DistillSeq, the observed attack success rates on these LLMs stood at 31.5% for GPT-3.5, 21.4% for GPT-4.0, 28.3% for Vicuna-13B, and 30.9% for Llama-13B. However, upon the application of DistillSeq, these success rates notably increased to 58.5%, 50.7%, 52.5%, and 54.4%, respectively. This translated to an average escalation in attack success rate by a factor of 93.0% when compared to scenarios without the use of DistillSeq. Such findings highlight the significant enhancement DistillSeq offers in terms of reducing the time and resource investment required for effectively testing LLMs.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 975|||| \n",
            "'arxiv_id': arXiv:2408.13745, \n",
            "'paper_link': https://arxiv.org/abs/2408.13745, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.13745, \n",
            "Title: DOCE: Finding the Sweet Spot for Execution-Based Code Generation \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Recently, a diverse set of decoding and reranking procedures have been shown effective for LLM-based code generation. However, a comprehensive framework that links and experimentally compares these methods is missing. We address this by proposing Decoding Objectives for Code Execution, a comprehensive framework that includes candidate generation, $n$-best reranking, minimum Bayes risk (MBR) decoding, and self-debugging as the core components. We then study the contributions of these components through execution-based evaluation metrics. Our findings highlight the importance of execution-based methods and the difference gap between execution-based and execution-free methods. Furthermore, we assess the impact of filtering based on trial unit tests, a simple and effective strategy that has been often overlooked in prior works. We also propose self-debugging on multiple candidates, obtaining state-of-the-art performance on reranking for code generation. We expect our framework to provide a solid guideline for future research on code generation.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 1074|||| \n",
            "'arxiv_id': arXiv:2405.05974, \n",
            "'paper_link': https://arxiv.org/abs/2405.05974, \n",
            "'pdf_link': https://arxiv.org/pdf/2405.05974, \n",
            "Title: Symbolic construction of the chemical Jacobian of quasi-steady state (QSS) chemistries for Exascale computing platforms \n",
            "Subjects: Fluid Dynamics (physics.flu-dyn) \n",
            "Abstract: The Quasi-Steady State Approximation (QSSA) can be an effective tool for reducing the size and stiffness of chemical mechanisms for implementation in computational reacting flow solvers. However, for many applications, stiffness remains, and the resulting model requires implicit methods for efficient time integration. In this paper, we outline an approach to formulating the QSSA reduction that is coupled with a strategy to generate C++ source code to evaluate the net species production rate, and the chemical Jacobian. The code-generation component employs a symbolic approach enabling a simple and effective strategy to analytically compute the chemical Jacobian. For computational tractability, the symbolic approach needs to be paired with common subexpression elimination which can negatively affect memory usage. Several solutions are outlined and successfully tested on a 3D multipulse ignition problem, thus allowing portable application across a chemical model sizes and GPU capabilities. The implementation of the proposed method is available at this https URL under an open-source license.\n",
            "Score: 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = .5\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"e-Learners\", 1),\n",
        "        (\"educational content\", 1),\n",
        "        (\"learning styles\", 1),\n",
        "        (\"educational process\", 1),\n",
        "        (\"human learning\", 1),\n",
        "\n",
        "        (\"education\", .5),\n",
        "        (\"learner\", .5),\n",
        "        (\"individual needs\", .5),\n",
        "\n",
        "        (\"learning sciences\", .5),\n",
        "        (\"educational technology\", .5),\n",
        "        (\"human-computer interaction\", .5),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ1iMqUJt8l9",
        "outputId": "d78f2eb6-a77c-4e77-dae0-db50463986b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: e-Learners\n",
            "Total Matches in Set: 37\n",
            "Matches Above Score-Floor in Set: 37\n",
            "2024-09-10__122810543330\n",
            "\n",
            "Showing 37 in top-37 out of 37 total results.     -> 37 of 37/37\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 0.5) -> 0.5\n",
            "\n",
            "\n",
            "Document: 64|||| \n",
            "'arxiv_id': arXiv:2409.04645, \n",
            "'paper_link': https://arxiv.org/abs/2409.04645, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04645, \n",
            "Title: PAIGE: Examining Learning Outcomes and Experiences with Personalized AI-Generated Educational Podcasts \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students' majors, interests, and learning styles. Our findings show that students found the AI-generated podcast format to be more enjoyable than textbooks and that personalized podcasts led to significantly improved learning outcomes, although this was subject-specific. These results highlight that AI-generated podcasts can offer an engaging and effective modality transformation of textbook material, with personalization enhancing content relevance. We conclude with design recommendations for leveraging AI in education, informed by student feedback.\n",
            "Score: 2.5\n",
            "\n",
            "Document: 442|||| \n",
            "'arxiv_id': arXiv:2409.05496, \n",
            "'paper_link': https://arxiv.org/abs/2409.05496, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05496, \n",
            "Title: Educational Virtual Field Trips based on Social VR and 360{\\deg} Spaces \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Virtual field trips (VFTs) have proven to be valuable learning tools. Such applications are mostly based on 360° technology and are to be characterized as single-user applications in technological terms. In contrast, Social VR applications are characterized by multi-user capability and user-specific avatars. From a learning perspective, the concepts of collaborative learning and embodiment have long been proposed as conducive to learning. Both concepts might be supported using Social VR. However, little is currently known about the use of Social VR for VFTs. Accordingly, the research questions are to what extent VFTs can be implemented in Social VR environments and how these Social VR-based VFTs are perceived by learners. This article presents an evaluation study on the development and evaluation of a VFT environment using the Social VR platform Mozilla Hubs. It describes the design decisions to create the environment and evaluation results from a mixed-method study (N=16) using a questionnaire and focus group discussions. The study highlighted the opportunities offered by Social VR-based VFTs but also revealed several challenges that need to be addressed to embrace the potential of Social VR-based VFTs to be utilized regularly in education.\n",
            "Score: 1.5\n",
            "\n",
            "Document: 81|||| \n",
            "'arxiv_id': arXiv:2409.04683, \n",
            "'paper_link': https://arxiv.org/abs/2409.04683, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04683, \n",
            "Title: C2F-CHART: A Curriculum Learning Approach to Chart Classification \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: In scientific research, charts are usually the primary method for visually representing data. However, the accessibility of charts remains a significant concern. In an effort to improve chart understanding pipelines, we focus on optimizing the chart classification component. We leverage curriculum learning, which is inspired by the human learning process. In this paper, we introduce a novel training approach for chart classification that utilizes coarse-to-fine curriculum learning. Our approach, which we name C2F-CHART (for coarse-to-fine) exploits inter-class similarities to create learning tasks of varying difficulty levels. We benchmark our method on the ICPR 2022 CHART-Infographics UB UNITEC PMC dataset, outperforming the state-of-the-art results.\n",
            "Score: 1\n",
            "\n",
            "Document: 226|||| \n",
            "'arxiv_id': arXiv:2409.04987, \n",
            "'paper_link': https://arxiv.org/abs/2409.04987, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04987, \n",
            "Title: How to Align Large Language Models for Teaching English? Designing and Developing LLM based-Chatbot for Teaching English Conversation in EFL, Findings and Limitations \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: This study investigates the design, development, and evaluation of a Large Language Model (LLM)-based chatbot for teaching English conversations in an English as a Foreign Language (EFL) context. Employing the Design and Development Research (DDR), we analyzed needs, established design principles, and iteratively refined a chatbot through experimenting various LLMs and alignment methods. Through both quantitative and qualitative evaluations, we identified the most effective LLM and its prompt combination to generate high-quality, contextually appropriate responses. Interviews with teachers provided insights into desirable system features, potential educational applications, and ethical considerations in the development and deployment of the chatbots. The design iterations yielded the importance of feedback mechanisms and customizable AI personas. Future research should explore adaptive feedback strategies, collaborative approaches with various stakeholders, and the integration of insights from human-computer interaction (HCI) and user experience (UX) design. This study contributes to the growing body of research on applying LLMs in language education, providing insights and recommendations for the design, development, and evaluation of LLM-based chatbots for EFL conversation practice. As the field evolves, ongoing research and collaboration among educators, AI engineers, and other stakeholders will be essential to harness the potential of these technologies to enhance language learning experiences.\n",
            "Score: 1.0\n",
            "\n",
            "Document: 303|||| \n",
            "'arxiv_id': arXiv:2409.05176, \n",
            "'paper_link': https://arxiv.org/abs/2409.05176, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05176, \n",
            "Title: Using Generative Artificial Intelligence Creatively in the Classroom: Examples and Lessons Learned \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Although generative artificial intelligence (AI) is not new, recent technological breakthroughs have transformed its capabilities across many domains. These changes necessitate new attention from educators and specialized training within the atmospheric sciences and related fields. Enabling students to use generative AI effectively, responsibly, and ethically is critically important for their academic and professional preparation. Educators can also use generative AI to create engaging classroom activities, such as active learning modules and games, but must be aware of potential pitfalls and biases. There are also ethical implications in using tools that lack transparency, as well as equity concerns for students who lack access to more sophisticated paid versions of generative AI tools. This article is written for students and educators alike, particularly those who want to learn more about generative AI in education, including use cases, ethical concerns, and a brief history of its emergence. Sample user prompts are also provided across numerous applications in education and the atmospheric and related sciences. While we don't have solutions for some broader ethical concerns surrounding the use of generative AI in education, our goal is to start a conversation that could galvanize the education community around shared goals and values.\n",
            "Score: 1.0\n",
            "\n",
            "Document: 311|||| \n",
            "'arxiv_id': arXiv:2409.05203, \n",
            "'paper_link': https://arxiv.org/abs/2409.05203, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05203, \n",
            "Title: CARDinality: Interactive Card-shaped Robots with Locomotion and Haptics using Vibration \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: This paper introduces a novel approach to interactive robots by leveraging the form-factor of cards to create thin robots equipped with vibrational capabilities for locomotion and haptic feedback. The system is composed of flat-shaped robots with on-device sensing and wireless control, which offer lightweight portability and scalability. This research introduces a hardware prototype. Applications include augmented card playing, educational tools, and assistive technology, which showcase CARDinality's versatility in tangible interaction.\n",
            "Score: 1.0\n",
            "\n",
            "Document: 448|||| \n",
            "'arxiv_id': arXiv:2409.05511, \n",
            "'paper_link': https://arxiv.org/abs/2409.05511, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05511, \n",
            "Title: Enhancing Critical Thinking in Education by means of a Socratic Chatbot \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: While large language models (LLMs) are increasingly playing a pivotal role in education by providing instantaneous, adaptive responses, their potential to promote critical thinking remains understudied. In this paper, we fill such a gap and present an innovative educational chatbot designed to foster critical thinking through Socratic questioning. Unlike traditional intelligent tutoring systems, including educational chatbots, that tend to offer direct answers, the proposed Socratic tutor encourages students to explore various perspectives and engage in self-reflection by posing structured, thought-provoking questions. Our Socratic questioning is implemented by fine and prompt-tuning the open-source pretrained LLM with a specialized dataset that stimulates critical thinking and offers multiple viewpoints. In an effort to democratize access and to protect the students' privacy, the proposed tutor is based on small LLMs (Llama2 7B and 13B-parameter models) that are able to run locally on off-the-shelf hardware. We validate our approach in a battery of experiments consisting of interactions between a simulated student and the chatbot to evaluate its effectiveness in enhancing critical thinking skills. Results indicate that the Socratic tutor supports the development of reflection and critical thinking significantly better than standard chatbots. Our approach opens the door for improving educational outcomes by cultivating active learning and encouraging intellectual autonomy.\n",
            "Score: 1.0\n",
            "\n",
            "Document: 18|||| \n",
            "'arxiv_id': arXiv:2409.04493, \n",
            "'paper_link': https://arxiv.org/abs/2409.04493, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04493, \n",
            "Title: The Perception of Stress in Graph Drawings \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Most of the common graph layout principles (a.k.a. \"aesthetics\") on which many graph drawing algorithms are based are easy to define and to perceive. For example, the number of pairs of edges that cross each other, how symmetric a drawing looks, the aspect ratio of the bounding box, or the angular resolution at the nodes. The extent to which a graph drawing conforms to these principles can be determined by looking at how it is drawn -- that is, by looking at the marks on the page -- without consideration for the underlying structure of the graph. A key layout principle is that of optimising `stress', the basis for many algorithms such as the popular Kamada \\& Kawai algorithm and several force-directed algorithms. The stress of a graph drawing is, loosely speaking, the extent to which the geometric distance between each pair of nodes is proportional to the shortest path between them -- over the whole graph drawing. The definition of stress therefore relies on the underlying structure of the graph (the `paths') in a way that other layout principles do not, making stress difficult to describe to novices unfamiliar with graph drawing principles, and, we believe, difficult to perceive. We conducted an experiment to see whether people (novices as well as experts) can see stress in graph drawings, and found that it is possible to train novices to `see' stress -- even if their perception strategies are not based on the definitional concepts.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 24|||| \n",
            "'arxiv_id': arXiv:2409.04508, \n",
            "'paper_link': https://arxiv.org/abs/2409.04508, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04508, \n",
            "Title: Toward LLM-Powered Social Robots for Supporting Sensitive Disclosures of Stigmatized Health Conditions \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Disclosing sensitive health conditions offers significant benefits at both individual and societal levels. However, patients often face challenges due to concerns about stigma. The use of social robots and chatbots to support sensitive disclosures is gaining traction, especially with the emergence of LLM models. Yet, numerous technical, ethical, privacy, safety, efficacy, and reporting concerns must be carefully addressed in this context. In this position paper, we focus on the example of HIV status disclosure, examining key opportunities, technical considerations, and risks associated with LLM-backed social robotics.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 25|||| \n",
            "'arxiv_id': arXiv:2409.04511, \n",
            "'paper_link': https://arxiv.org/abs/2409.04511, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04511, \n",
            "Title: Paradoxes of Openness and Trans Experiences in Open Source Software \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: In recent years, concerns have increased over the lack of contributor diversity in open source software (OSS), despite its status as a paragon of open collaboration. OSS is an important form of digital infrastructure and part of a career path for many developers. While there exists a growing body of literature on cisgender women's under-representation in OSS, the experiences of contributors from other marginalized groups are comparatively absent from the literature. Such is the case for trans contributors, a historically influential group in OSS. In this study, we interviewed 21 trans participants to understand and represent their experiences in the OSS literature. From their experiences, we theorize two related paradoxes of openness in OSS: the paradox of openness and display and the paradox of openness and governance. In an increasingly violent world for trans people, we draw on our theorizing to build recommendations for more inclusive and safer OSS projects for contributors.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 40|||| \n",
            "'arxiv_id': arXiv:2409.04579, \n",
            "'paper_link': https://arxiv.org/abs/2409.04579, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04579, \n",
            "Title: Developing a Modular Toolkit for Rapid Prototyping of Wearable Vibrotactile Haptic Harness \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: This paper presents a toolkit for rapid harness prototyping. These wearable structures attach vibrotactile actuators to the body using modular elements like 3D printed joints, laser cut or vinyl cutter-based sheets and magnetic clasps. This facilitates easy customization and assembly. The toolkit's primary objective is to simplify the design of haptic wearables, making research in this field easier and more approachable.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 56|||| \n",
            "'arxiv_id': arXiv:2409.04616, \n",
            "'paper_link': https://arxiv.org/abs/2409.04616, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04616, \n",
            "Title: From Data Dump to Digestible Chunks: Automated Segmentation and Summarization of Provenance Logs for Communication \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Communicating one's sensemaking during a complex analysis session to explain thought processes is hard, yet most intelligence occurs in collaborative settings. Team members require a deeper understanding of the work being completed by their peers and subordinates, but little research has fully articulated best practices for analytic provenance consumers. This work proposes an automatic summarization technique that separates an analysis session and summarizes interaction provenance as textual blurbs to allow for meta-analysis of work done. Focusing on the domain of intelligence analysis, we demonstrate our segmentation technique using five datasets, including both publicly available and classified interaction logs. We shared our demonstration with a notoriously inaccessible population of expert reviewers with experience as United States Department of Defense analysts. Our findings indicate that the proposed pipeline effectively generates cards that display key events from interaction logs, facilitating the sharing of analysis progress. Yet, we also hear that there is a need for more prominent justifications and pattern elicitation controls to communicate analysis summaries more effectively. The expert review highlights the potential of automated approaches in addressing the challenges of provenance information in complex domains. We'd like to emphasize the need for further research into provenance communication in other domains.\n",
            "A free copy of this paper and all supplemental materials are available at this https URL\n",
            "Score: 0.5\n",
            "\n",
            "Document: 71|||| \n",
            "'arxiv_id': arXiv:2409.04658, \n",
            "'paper_link': https://arxiv.org/abs/2409.04658, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04658, \n",
            "Title: Unveiling the Inter-Related Preferences of Crowdworkers: Implications for Personalized and Flexible Platform Design \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Crowdsourcing platforms have traditionally been designed with a focus on workstation interfaces, restricting the flexibility that crowdworkers need. Recognizing this limitation and the need for more adaptable platforms, prior research has highlighted the diverse work processes of crowdworkers, influenced by factors such as device type and work stage. However, these variables have largely been studied in isolation. Our study is the first to explore the interconnected variabilities among these factors within the crowdwork community. Through a survey involving 150 Amazon Mechanical Turk crowdworkers, we uncovered three distinct groups characterized by their interrelated variabilities in key work aspects. The largest group exhibits a reliance on traditional devices, showing limited interest in integrating smartphones and tablets into their work routines. The second-largest group also primarily uses traditional devices but expresses a desire for supportive tools and scripts that enhance productivity across all devices, particularly smartphones and tablets. The smallest group actively uses and strongly prefers non-workstation devices, especially smartphones and tablets, for their crowdworking activities. We translate our findings into design insights for platform developers, discussing the implications for creating more personalized, flexible, and efficient crowdsourcing environments. Additionally, we highlight the unique work practices of these crowdworker clusters, offering a contrast to those of more traditional and established worker groups.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 78|||| \n",
            "'arxiv_id': arXiv:2409.04676, \n",
            "'paper_link': https://arxiv.org/abs/2409.04676, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04676, \n",
            "Title: Exploring Crowdworkers' Perceptions, Current Practices, and Desired Practices Regarding Using Non-Workstation Devices for Crowdwork \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Despite a plethora of research dedicated to designing HITs for non-workstations, there is a lack of research looking specifically into workers' perceptions of the suitability of these devices for managing and completing work. In this work, we fill this research gap by conducting an online survey of 148 workers on Amazon Mechanical Turk to explore 1. how crowdworkers currently use their non-workstation devices to complete and manage crowdwork, 2. what challenges they face using those devices, and 3. to what extent they wish they could use those devices if their concerns were addressed. Our results show that workers unanimously favor using a desktop to complete and manage crowdwork. While workers occasionally use smartphones or tablets, they find their suitability marginal at best and have little interest in smart speakers and smartwatches, viewing them as unsuitable for crowdwork. When investigating the reason for these views, we find that the key issue is that non workstation devices lack the tooling necessary to automatically find and accept HITs, tooling that workers view as essential in their efforts to compete with bots in accepting high paying work. To address this problem, we propose a new paradigm for finding, accepting, and completing crowdwork that puts crowdworkers on equal footing with bots in these tasks. We also describe future research directions for tailoring HITs to non workstation devices and definitely answering whether smart speakers and smartwatches have a place in crowdwork.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 134|||| \n",
            "'arxiv_id': arXiv:2409.04795, \n",
            "'paper_link': https://arxiv.org/abs/2409.04795, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04795, \n",
            "Title: Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Automatic Essay Scoring (AES) is widely used to evaluate candidates for educational purposes. However, due to the lack of representative data, most existing AES systems are not robust, and their scoring predictions are biased towards the most represented data samples. In this study, we propose a model-agnostic phrase-level method to generate an adversarial essay set to address the biases and robustness of AES models. Specifically, we construct an attack test set comprising samples from the original test set and adversarially generated samples using our proposed method. To evaluate the effectiveness of the attack strategy and data augmentation, we conducted a comprehensive analysis utilizing various neural network scoring models. Experimental results show that the proposed approach significantly improves AES model performance in the presence of adversarial examples and scenarios without such attacks.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 139|||| \n",
            "'arxiv_id': arXiv:2409.04808, \n",
            "'paper_link': https://arxiv.org/abs/2409.04808, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04808, \n",
            "Title: HULLMI: Human vs LLM identification with explainability \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: As LLMs become increasingly proficient at producing human-like responses, there has been a rise of academic and industrial pursuits dedicated to flagging a given piece of text as \"human\" or \"AI\". Most of these pursuits involve modern NLP detectors like T5-Sentinel and RoBERTa-Sentinel, without paying too much attention to issues of interpretability and explainability of these models. In our study, we provide a comprehensive analysis that shows that traditional ML models (Naive-Bayes,MLP, Random Forests, XGBoost) perform as well as modern NLP detectors, in human vs AI text detection. We achieve this by implementing a robust testing procedure on diverse datasets, including curated corpora and real-world samples. Subsequently, by employing the explainable AI technique LIME, we uncover parts of the input that contribute most to the prediction of each model, providing insights into the detection process. Our study contributes to the growing need for developing production-level LLM detection tools, which can leverage a wide range of traditional as well as modern NLP detectors we propose. Finally, the LIME techniques we demonstrate also have the potential to equip these detection tools with interpretability analysis features, making them more reliable and trustworthy in various domains like education, healthcare, and media.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 167|||| \n",
            "'arxiv_id': arXiv:2409.04857, \n",
            "'paper_link': https://arxiv.org/abs/2409.04857, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04857, \n",
            "Title: IPN-V: The Interplanetary Network Visualizer \n",
            "Subjects: Networking and Internet Architecture (cs.NI) \n",
            "Abstract: The Interplanetary Network (IPN) emerges as the backbone for communication between various spacecraft and satellites orbiting distant celestial bodies. This paper introduces the Interplanetary Network Visualizer (IPN-V), a software platform that integrates interplanetary communications planning support, education, and outreach. IPN-V bridges the gap between the complexities of astrodynamics and network engineering by enabling the generation and assessment of dynamic, realistic network topologies that encapsulate the inherent challenges of space communication, such as time-evolving latencies and planetary occlusions. Leveraging the power of Unity 3D and C#, IPN-V provides a user-friendly 3D interface for the interactive visualization of interplanetary networks, incorporating contact tracing models to represent line-of-sight communication constraints accurately. IPN-V supports importing and exporting contact plans compatible with established space communication standards, including NASA's ION and HDTN formats. This paper delineates the conception, architecture, and operational framework of IPN-V while evaluating its performance metrics.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 183|||| \n",
            "'arxiv_id': arXiv:2409.04900, \n",
            "'paper_link': https://arxiv.org/abs/2409.04900, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04900, \n",
            "Title: XR Prototyping of Mixed Reality Visualizations: Compensating Interaction Latency for a Medical Imaging Robot \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Researching novel user experiences in medicine is challenging due to limited access to equipment and strict ethical protocols. Extended Reality (XR) simulation technologies offer a cost- and time-efficient solution for developing interactive systems. Recent work has shown Extended Reality Prototyping (XRP)'s potential, but its applicability to specific domains like controlling complex machinery needs further exploration. This paper explores the benefits and limitations of XRP in controlling a mobile medical imaging robot. We compare two XR visualization techniques to reduce perceived latency between user input and robot activation. Our XRP validation study demonstrates its potential for comparative studies, but identifies a gap in modeling human behavior in the analytic XRP validation framework.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 211|||| \n",
            "'arxiv_id': arXiv:2409.04964, \n",
            "'paper_link': https://arxiv.org/abs/2409.04964, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04964, \n",
            "Title: Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Machine translation using large language models (LLMs) is having a significant global impact, making communication easier. Mandarin Chinese is the official language used for communication by the government, education institutes, and media in China. In this study, we provide an automated assessment of machine translation models with human experts using sentiment and semantic analysis. In order to demonstrate our framework, we select classic early twentieth-century novel 'The True Story of Ah Q' with selected Mandarin Chinese to English translations. We also us Google Translate to generate the given text into English and then conduct a chapter-wise sentiment analysis and semantic analysis to compare the extracted sentiments across the different translations. We utilise LLMs for semantic and sentiment analysis. Our results indicate that the precision of Google Translate differs both in terms of semantic and sentiment analysis when compared to human expert translations. We find that Google Translate is unable to translate some of the specific words or phrases in Chinese, such as Chinese traditional allusions. The mistranslations have to its lack of contextual significance and historical knowledge of China. Thus, this framework brought us some new insights about machine translation for Chinese Mandarin. The future work can explore other languages or types of texts with this framework.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 237|||| \n",
            "'arxiv_id': arXiv:2409.05015, \n",
            "'paper_link': https://arxiv.org/abs/2409.05015, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05015, \n",
            "Title: Improving Multimodal Emotion Recognition by Leveraging Acoustic Adaptation and Visual Alignment \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Multimodal Emotion Recognition (MER) aims to automatically identify and understand human emotional states by integrating information from various modalities. However, the scarcity of annotated multimodal data significantly hinders the advancement of this research field. This paper presents our solution for the MER-SEMI sub-challenge of MER 2024. First, to better adapt acoustic modality features for the MER task, we experimentally evaluate the contributions of different layers of the pre-trained speech model HuBERT in emotion recognition. Based on these observations, we perform Parameter-Efficient Fine-Tuning (PEFT) on the layers identified as most effective for emotion recognition tasks, thereby achieving optimal adaptation for emotion recognition with a minimal number of learnable parameters. Second, leveraging the strengths of the acoustic modality, we propose a feature alignment pre-training method. This approach uses large-scale unlabeled data to train a visual encoder, thereby promoting the semantic alignment of visual features within the acoustic feature space. Finally, using the adapted acoustic features, aligned visual features, and lexical features, we employ an attention mechanism for feature fusion. On the MER2024-SEMI test set, the proposed method achieves a weighted F1 score of 88.90%, ranking fourth among all participating teams, validating the effectiveness of our approach.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 360|||| \n",
            "'arxiv_id': arXiv:2409.05312, \n",
            "'paper_link': https://arxiv.org/abs/2409.05312, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05312, \n",
            "Title: Open-World Dynamic Prompt and Continual Visual Representation Learning \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The open world is inherently dynamic, characterized by ever-evolving concepts and distributions. Continual learning (CL) in this dynamic open-world environment presents a significant challenge in effectively generalizing to unseen test-time classes. To address this challenge, we introduce a new practical CL setting tailored for open-world visual representation learning. In this setting, subsequent data streams systematically introduce novel classes that are disjoint from those seen in previous training phases, while also remaining distinct from the unseen test classes. In response, we present Dynamic Prompt and Representation Learner (DPaRL), a simple yet effective Prompt-based CL (PCL) method. Our DPaRL learns to generate dynamic prompts for inference, as opposed to relying on a static prompt pool in previous PCL methods. In addition, DPaRL jointly learns dynamic prompt generation and discriminative representation at each training stage whereas prior PCL methods only refine the prompt learning throughout the process. Our experimental results demonstrate the superiority of our approach, surpassing state-of-the-art methods on well-established open-world image retrieval benchmarks by an average of 4.7\\% improvement in Recall@1 performance.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 366|||| \n",
            "'arxiv_id': arXiv:2409.05330, \n",
            "'paper_link': https://arxiv.org/abs/2409.05330, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05330, \n",
            "Title: KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks Generation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Audio-driven talking face generation is a widely researched topic due to its high applicability. Reconstructing a talking face using audio significantly contributes to fields such as education, healthcare, online conversations, virtual assistants, and virtual reality. Early studies often focused solely on changing the mouth movements, which resulted in outcomes with limited practical applications. Recently, researchers have proposed a new approach of constructing the entire face, including face pose, neck, and shoulders. To achieve this, they need to generate through landmarks. However, creating stable landmarks that align well with the audio is a challenge. In this paper, we propose the KFusion of Dual-Domain model, a robust model that generates landmarks from audio. We separate the audio into two distinct domains to learn emotional information and facial context, then use a fusion mechanism based on the KAN model. Our model demonstrates high efficiency compared to recent models. This will lay the groundwork for the development of the audio-driven talking face generation problem in the future.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 380|||| \n",
            "'arxiv_id': arXiv:2409.05358, \n",
            "'paper_link': https://arxiv.org/abs/2409.05358, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05358, \n",
            "Title: BAMDP Shaping: a Unified Theoretical Framework for Intrinsic Motivation and Reward Shaping \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Intrinsic motivation (IM) and reward shaping are common methods for guiding the exploration of reinforcement learning (RL) agents by adding pseudo-rewards. Designing these rewards is challenging, however, and they can counter-intuitively harm performance. To address this, we characterize them as reward shaping in Bayes-Adaptive Markov Decision Processes (BAMDPs), which formalizes the value of exploration by formulating the RL process as updating a prior over possible MDPs through experience. RL algorithms can be viewed as BAMDP policies; instead of attempting to find optimal algorithms by solving BAMDPs directly, we use it at a theoretical framework for understanding how pseudo-rewards guide suboptimal algorithms. By decomposing BAMDP state value into the value of the information collected plus the prior value of the physical state, we show how psuedo-rewards can help by compensating for RL algorithms' misestimation of these two terms, yielding a new typology of IM and reward shaping approaches. We carefully extend the potential-based shaping theorem to BAMDPs to prove that when pseudo-rewards are BAMDP Potential-based shaping Functions (BAMPFs), they preserve optimal, or approximately optimal, behavior of RL algorithms; otherwise, they can corrupt even optimal learners. We finally give guidance on how to design or convert existing pseudo-rewards to BAMPFs by expressing assumptions about the environment as potential functions on BAMDP states.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 386|||| \n",
            "'arxiv_id': arXiv:2409.05374, \n",
            "'paper_link': https://arxiv.org/abs/2409.05374, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05374, \n",
            "Title: Don't Leave Me Out: Designing for Device Inclusivity in Mixed Reality Collaboration \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Modern collaborative Mixed Reality (MR) systems continue to break the boundaries of conventional co-located and remote collaboration and communication. They merge physical and virtual worlds and enable natural interaction, opening up a spectrum of novel opportunities for interpersonal connection. For these connections to be perceived as engaging and positive, collaborators should feel comfortable and experience a sense of belonging. Not having the dedicated devices to smoothly participate in these spaces can hinder this and give users the impression of being left out. To counteract this, we propose to prioritize designing for device inclusivity in MR collaboration, focusing on compensating disadvantages of common non-immersive device classes in cross-device systems.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 422|||| \n",
            "'arxiv_id': arXiv:2409.05457, \n",
            "'paper_link': https://arxiv.org/abs/2409.05457, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05457, \n",
            "Title: Visualizing Extensions of Argumentation Frameworks as Layered Graphs \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: The visualization of argumentation frameworks (AFs) is crucial for enabling a wide applicability of argumentative tools. However, their visualization is often considered only as an accompanying part of tools for computing semantics and standard graphical representations are used. We introduce a new visualization technique that draws an AF, together with an extension (as part of the input), as a 3-layer graph layout. Our technique supports the user to more easily explore the visualized AF, better understand extensions, and verify algorithms for computing semantics. To optimize the visual clarity and aesthetics of this layout, we propose to minimize edge crossings in our 3-layer drawing. We do so by an exact ILP-based approach, but also propose a fast heuristic pipeline. Via a quantitative evaluation, we show that the heuristic is feasible even for large instances, while producing at most twice as many crossings as an optimal drawing in most cases.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 517|||| \n",
            "'arxiv_id': arXiv:2409.05696, \n",
            "'paper_link': https://arxiv.org/abs/2409.05696, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05696, \n",
            "Title: Citizen-Led Personalization of User Interfaces: Investigating How People Customize Interfaces for Themselves and Others \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: User interface (UI) personalization can improve usability and user experience. However, current systems offer limited opportunities for customization, and third-party solutions often require significant effort and technical skills beyond the reach of most users, impeding the future adoption of interface personalization. In our research, we explore the concept of UI customization for the self and others. We performed a two-week study where nine participants used a custom-designed tool that allows websites' UI customization for oneself and to create and reply to customization assistance requests from others. Results suggest that people enjoy customizing for others more than for themselves. They see requests as challenges to solve and are motivated by the positive feeling of helping others. To customize for themselves, people need help with the creative process. We discuss challenges and opportunities for future research seeking to democratize access to personalized UIs, particularly through community-based approaches.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 523|||| \n",
            "'arxiv_id': arXiv:2409.05703, \n",
            "'paper_link': https://arxiv.org/abs/2409.05703, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05703, \n",
            "Title: The Influence of Task and Group Disparities over Users' Attitudes Toward Using Large Language Models for Psychotherapy \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: The population suffering from mental health disorders has kept increasing in recent years. With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention. However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored. As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools. Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China. The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools. Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention. These findings can guide the design of future LLM-based psychotherapy services.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 528|||| \n",
            "'arxiv_id': arXiv:2409.05731, \n",
            "'paper_link': https://arxiv.org/abs/2409.05731, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05731, \n",
            "Title: What Did My Car Say? Autonomous Vehicle Explanation Errors, Context, and Personal Traits Impact Comfort, Reliance, Satisfaction, and Driving Confidence \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger's comfort in relying on an AV, preference for control, confidence in the AV's ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV's driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 534|||| \n",
            "'arxiv_id': arXiv:2409.05747, \n",
            "'paper_link': https://arxiv.org/abs/2409.05747, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05747, \n",
            "Title: A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: This paper presents a novel conversational AI-enabled active ideation interface as a creative idea-generation tool to assist novice designers in mitigating the initial latency and ideation bottlenecks that are commonly observed. It is a dynamic, interactive, and contextually responsive approach, actively involving a large language model (LLM) from the domain of natural language processing (NLP) in artificial intelligence (AI) to produce multiple statements of potential ideas for different design problems. Integrating such AI models with ideation creates what we refer to as an Active Ideation scenario, which helps foster continuous dialogue-based interaction, context-sensitive conversation, and prolific idea generation. A pilot study was conducted with thirty novice designers to generate ideas for given problems using traditional methods and the new CAI-based interface. The key parameters of fluency, novelty, and variety were used to compare the outcomes qualitatively by a panel of experts. The findings demonstrated the effectiveness of the proposed tool for generating prolific, diverse and novel ideas. The interface was enhanced by incorporating a prompt-engineered structured dialogue style for each ideation stage to make it uniform and more convenient for the designers. The resulting responses of such a structured CAI interface were found to be more succinct and aligned towards the subsequent design stage, namely conceptualization. The paper thus established the rich potential of using Generative AI (Gen-AI) for the early ill-structured phase of the creative product design process.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 541|||| \n",
            "'arxiv_id': arXiv:2409.05773, \n",
            "'paper_link': https://arxiv.org/abs/2409.05773, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05773, \n",
            "Title: Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: This paper explores the integration of visual communication and musical interaction by implementing a robotic camera within a \"Guided Harmony\" musical game. We aim to examine co-creative behaviors between human musicians and robotic systems. Our research explores existing methodologies like improvisational game pieces and extends these concepts to include robotic participation using a PTZ camera. The robotic system interprets and responds to nonverbal cues from musicians, creating a collaborative and adaptive musical experience. This initial case study underscores the importance of intuitive visual communication channels. We also propose future research directions, including parameters for refining the visual cue toolkit and data collection methods to understand human-machine co-creativity further. Our findings contribute to the broader understanding of machine intelligence in augmenting human creativity, particularly in musical settings.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 703|||| \n",
            "'arxiv_id': arXiv:2307.11880, \n",
            "'paper_link': https://arxiv.org/abs/2307.11880, \n",
            "'pdf_link': https://arxiv.org/pdf/2307.11880, \n",
            "Title: Bans vs. Warning Labels: Examining Bystanders' Support for Community-wide Moderation Interventions \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Social media platforms like Facebook and Reddit host thousands of user-governed online communities. These platforms sanction communities that frequently violate platform policies; however, public perceptions of such sanctions remain unclear. In a pre-registered survey conducted in the US, I explore bystander perceptions of content moderation for communities that frequently feature hate speech, violent content, and sexually explicit content. Two community-wide moderation interventions are tested: (1) community bans, where all community posts are removed, and (2) community warning labels, where an interstitial warning label precedes access. I examine how third-person effects and support for free speech influence user approval of these interventions on any platform. My regression analyses show that presumed effects on others are a significant predictor of backing for both interventions, while free speech beliefs significantly influence participants' inclination for using warning labels. Analyzing the open-ended responses, I find that community-wide bans are often perceived as too coarse, and users instead value sanctions in proportion to the severity and type of infractions. I report on concerns that norm-violating communities could reinforce inappropriate behaviors and show how users' choice of sanctions is influenced by their perceived effectiveness. I discuss the implications of these results for HCI research on online harms and content moderation.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 818|||| \n",
            "'arxiv_id': arXiv:2404.09296, \n",
            "'paper_link': https://arxiv.org/abs/2404.09296, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.09296, \n",
            "Title: Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.\n",
            "Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 985|||| \n",
            "'arxiv_id': arXiv:2408.17244, \n",
            "'paper_link': https://arxiv.org/abs/2408.17244, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.17244, \n",
            "Title: Categorical data clustering: 25 years beyond K-modes \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: The clustering of categorical data is a common and important task in computer science, offering profound implications across a spectrum of applications. Unlike purely numerical data, categorical data often lack inherent ordering as in nominal data, or have varying levels of order as in ordinal data, thus requiring specialized methodologies for efficient organization and analysis. This review provides a comprehensive synthesis of categorical data clustering in the past twenty-five years, starting from the introduction of K-modes. It elucidates the pivotal role of categorical data clustering in diverse fields such as health sciences, natural sciences, social sciences, education, engineering and economics. Practical comparisons are conducted for algorithms having public implementations, highlighting distinguishing clustering methodologies and revealing the performance of recent algorithms on several benchmark categorical datasets. Finally, challenges and opportunities in the field are discussed.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 994|||| \n",
            "'arxiv_id': arXiv:2409.00629, \n",
            "'paper_link': https://arxiv.org/abs/2409.00629, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.00629, \n",
            "Title: Assessing the Impact of Upselling in Online Fantasy Sports \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: This study explores the impact of upselling on user engagement. We model users' deposit behaviour on the fantasy sports platform Dream11. Subsequently, we develop an experimental framework to evaluate the effect of upselling using an intensity parameter. Our live experiments on user deposit behaviour reveal decreased user recall with heightened upselling intensity. Our findings indicate that increased upselling intensity improves user deposit metrics and concurrently diminishes user satisfaction and conversion rates. We conduct robust counterfactual analysis and train causal meta-learners to personalise users' upselling intensity levels to reach an optimal trade-off point.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 1008|||| \n",
            "'arxiv_id': arXiv:2409.02219, \n",
            "'paper_link': https://arxiv.org/abs/2409.02219, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.02219, \n",
            "Title: A+AI: Threats to Society, Remedies, and Governance \n",
            "Subjects: Computers and Society (cs.CY) \n",
            "Abstract: This document focuses on the threats, especially near-term threats, that Artificial Intelligence (AI) brings to society. Most of the threats discussed here can result from any algorithmic process, not just AI; in addition, defining AI is notoriously difficult. For both reasons, it is important to think of \"A+AI\": Algorithms and Artificial Intelligence.\n",
            "In addition to the threats, this paper discusses countermeasures to them, and it includes a table showing which countermeasures are likely to mitigate which threats. Thoughtful governance could manage the risks without seriously impeding progress; in fact, chances are it would accelerate progress by reducing the social chaos that would otherwise be likely. The paper lists specific actions government should take as soon as possible, namely:\n",
            "* Require all social media platforms accessible in the U.S. to offer users verification that their accounts are owned by citizens, and to display every account's verification status\n",
            "* Establish regulations to require that all products created or significantly modified with A+AI be clearly labeled as such; to restrict use of generative AI to create likenesses of persons; and to require creators of generative AI software to disclose materials used to train their software and to compensate the creators of any copyrighted material used\n",
            "* Fund a crash project of research on mitigating the threats\n",
            "* Fund educational campaigns to raise awareness of the threats\n",
            "Score: 0.5\n",
            "\n",
            "Document: 1029|||| \n",
            "'arxiv_id': arXiv:2409.03893, \n",
            "'paper_link': https://arxiv.org/abs/2409.03893, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.03893, \n",
            "Title: Understanding Fairness in Recommender Systems: A Healthcare Perspective \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Fairness in AI-driven decision-making systems has become a critical concern, especially when these systems directly affect human lives. This paper explores the public's comprehension of fairness in healthcare recommendations. We conducted a survey where participants selected from four fairness metrics -- Demographic Parity, Equal Accuracy, Equalized Odds, and Positive Predictive Value -- across different healthcare scenarios to assess their understanding of these concepts. Our findings reveal that fairness is a complex and often misunderstood concept, with a generally low level of public understanding regarding fairness metrics in recommender systems. This study highlights the need for enhanced information and education on algorithmic fairness to support informed decision-making in using these systems. Furthermore, the results suggest that a one-size-fits-all approach to fairness may be insufficient, pointing to the importance of context-sensitive designs in developing equitable AI systems.\n",
            "Score: 0.5\n",
            "\n",
            "Document: 1032|||| \n",
            "'arxiv_id': arXiv:2409.04102, \n",
            "'paper_link': https://arxiv.org/abs/2409.04102, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04102, \n",
            "Title: Intelligent tutoring systems by Bayesian nets with noisy gates \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Directed graphical models such as Bayesian nets are often used to implement intelligent tutoring systems able to interact in real-time with learners in a purely automatic way. When coping with such models, keeping a bound on the number of parameters might be important for multiple reasons. First, as these models are typically based on expert knowledge, a huge number of parameters to elicit might discourage practitioners from adopting them. Moreover, the number of model parameters affects the complexity of the inferences, while a fast computation of the queries is needed for real-time feedback. We advocate logical gates with uncertainty for a compact parametrization of the conditional probability tables in the underlying Bayesian net used by tutoring systems. We discuss the semantics of the model parameters to elicit and the assumptions required to apply such approach in this domain. We also derive a dedicated inference scheme to speed up computations.\n",
            "Score: 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"collective behavior\", 1),\n",
        "        (\"collective\", 1),\n",
        "        (\"coordination\", 1),\n",
        "        (\"oganization\", 1),\n",
        "        (\"behavior\", 1),\n",
        "        (\"ants\", 1),\n",
        "        (\"insects\", 1),\n",
        "        (\"worms\", 1),\n",
        "        (\"swarm\", 1),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "id": "9zPAIaz5xzmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15f74fc-9f16-45de-8219-945ba8ee604d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: collective behavior\n",
            "Total Matches in Set: 147\n",
            "Matches Above Score-Floor in Set: 16\n",
            "2024-09-10__122810736940\n",
            "\n",
            "Showing 16 in top-45 out of 147 total results.     -> 16 of 45/147\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 104|||| \n",
            "'arxiv_id': arXiv:2409.04736, \n",
            "'paper_link': https://arxiv.org/abs/2409.04736, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04736, \n",
            "Title: LiTelFuzz : Swarms Fuzzing Based on Linear Temporal Logic Constraints \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: Multi-robot swarms utilize swarm intelligence to collaborate on tasks and play an increasingly significant role in a variety of practical scenarios. However, due to the complex design, multi-robot swarm systems often have vulnerabilities caused by logical errors, which can severely disrupt the normal operations of multi-robot swarms. Despite the significant security threats that logical vulnerabilities pose to multi-robot swarms, there are still considerable challenges in testing and identifying these vulnerabilities, and related research still faces two major challenges: 1) the explosion of input space for testing, 2) the lack of effective test-guidance strategies. Therefore, in this paper, we overcome the two major challenges mentioned above, and propose a formal verification method to discover logical flaws in multi-robot swarms. Specifically, we abstract linear temporal logic constraints of the swarm and compute swarm robustness based on these constraints thus guiding fuzzing, we call this approach LiTelFuzz (Fuzzing based on Linear Temporal Logic Constraints). The core idea of LiTelFuzz is to design a metric based on behavioral constraints to assess the state of the multi-robot swarm at different moments, and guide fuzz testing based on the assessment results. Based on this idea, we overcome the two challenges of excessive test case input space and the lack of fuzzing guidance. Consequently, we implement a single attack drone fuzzing scheme and a multiple attack drones scheme based on LiTelFuzz. These are named SA-Fuzzing and MA-Fuzzing, respectively. Finally, we tested three popular swarm algorithms using LiTelFuzz with an average success rate of 87.35% for SA-Fuzzing and 91.73% for MA-Fuzzing to find vulnerabilities. The success rate and efficiency are better than the existing state-of-the-art fuzzer SWARMFLAWFINDER.\n",
            "Score: 3\n",
            "\n",
            "Document: 188|||| \n",
            "'arxiv_id': arXiv:2409.04916, \n",
            "'paper_link': https://arxiv.org/abs/2409.04916, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04916, \n",
            "Title: Chemical Power Variability among Microscopic Robots in Blood Vessels \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Fuel cells using oxygen and glucose could power microscopic robots operating in blood vessels. Swarms of such robots can significantly reduce oxygen concentration, depending on the time between successive transits of the lung, hematocrit variation in vessels and tissue oxygen consumption. These factors differ among circulation paths through the body. This paper evaluates how these variations affect the minimum oxygen concentration due to robot consumption and where it occurs: mainly in moderate-sized veins toward the end of long paths prior to their merging with veins from shorter paths. This shows that tens of billions of robots can obtain hundreds of picowatts throughout the body with minor reduction in total oxygen. However, a trillion robots significantly deplete oxygen in some parts of the body. By storing oxygen or limiting their consumption in long circulation paths, robots can actively mitigate this depletion. The variation in behavior is illustrated in three cases: the portal system which involves passage through two capillary networks, the spleen whose slits significantly slow some of the flow, and large tissue consumption in coronary circulation.\n",
            "Score: 2\n",
            "\n",
            "Document: 199|||| \n",
            "'arxiv_id': arXiv:2409.04937, \n",
            "'paper_link': https://arxiv.org/abs/2409.04937, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04937, \n",
            "Title: CONNECTOR: Enhancing the Traceability of Decentralized Bridge Applications via Automatic Cross-chain Transaction Association \n",
            "Subjects: Software Engineering (cs.SE) \n",
            "Abstract: Decentralized bridge applications are important software that connects various blockchains and facilitates cross-chain asset transfer in the decentralized finance (DeFi) ecosystem which currently operates in a multi-chain environment. Cross-chain transaction association identifies and matches unique transactions executed by bridge DApps, which is important research to enhance the traceability of cross-chain bridge DApps. However, existing methods rely entirely on unobservable internal ledgers or APIs, violating the open and decentralized properties of blockchain. In this paper, we analyze the challenges of this issue and then present CONNECTOR, an automated cross-chain transaction association analysis method based on bridge smart contracts. Specifically, CONNECTOR first identifies deposit transactions by extracting distinctive and generic features from the transaction traces of bridge contracts. With the accurate deposit transactions, CONNECTOR mines the execution logs of bridge contracts to achieve withdrawal transaction matching. We conduct real-world experiments on different types of bridges to demonstrate the effectiveness of CONNECTOR. The experiment demonstrates that CONNECTOR successfully identifies 100% deposit transactions, associates 95.81% withdrawal transactions, and surpasses methods for CeFi bridges. Based on the association results, we obtain interesting findings about cross-chain transaction behaviors in DeFi bridges and analyze the tracing abilities of CONNECTOR to assist the DeFi bridge apps.\n",
            "Score: 2\n",
            "\n",
            "Document: 233|||| \n",
            "'arxiv_id': arXiv:2409.05006, \n",
            "'paper_link': https://arxiv.org/abs/2409.05006, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05006, \n",
            "Title: HelmetPoser: A Helmet-Mounted IMU Dataset for Data-Driven Estimation of Human Head Motion in Diverse Conditions \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Helmet-mounted wearable positioning systems are crucial for enhancing safety and facilitating coordination in industrial, construction, and emergency rescue environments. These systems, including LiDAR-Inertial Odometry (LIO) and Visual-Inertial Odometry (VIO), often face challenges in localization due to adverse environmental conditions such as dust, smoke, and limited visual features. To address these limitations, we propose a novel head-mounted Inertial Measurement Unit (IMU) dataset with ground truth, aimed at advancing data-driven IMU pose estimation. Our dataset captures human head motion patterns using a helmet-mounted system, with data from ten participants performing various activities. We explore the application of neural networks, specifically Long Short-Term Memory (LSTM) and Transformer networks, to correct IMU biases and improve localization accuracy. Additionally, we evaluate the performance of these methods across different IMU data window dimensions, motion patterns, and sensor types. We release a publicly available dataset, demonstrate the feasibility of advanced neural network approaches for helmet-based localization, and provide evaluation metrics to establish a baseline for future studies in this field. Data and code can be found at \\url{this https URL}.\n",
            "Score: 2\n",
            "\n",
            "Document: 254|||| \n",
            "'arxiv_id': arXiv:2409.05044, \n",
            "'paper_link': https://arxiv.org/abs/2409.05044, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05044, \n",
            "Title: An Analysis of Logit Learning with the r-Lambert Function \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: The well-known replicator equation in evolutionary game theory describes how population-level behaviors change over time when individuals make decisions using simple imitation learning rules. In this paper, we study evolutionary dynamics based on a fundamentally different class of learning rules known as logit learning. Numerous previous studies on logit dynamics provide numerical evidence of bifurcations of multiple fixed points for several types of games. Our results here provide a more explicit analysis of the logit fixed points and their stability properties for the entire class of two-strategy population games -- by way of the $r$-Lambert function. We find that for Prisoner's Dilemma and anti-coordination games, there is only a single fixed point for all rationality levels. However, coordination games exhibit a pitchfork bifurcation: there is a single fixed point in a low-rationality regime, and three fixed points in a high-rationality regime. We provide an implicit characterization for the level of rationality where this bifurcation occurs. In all cases, the set of logit fixed points converges to the full set of Nash equilibria in the high rationality limit.\n",
            "Score: 2\n",
            "\n",
            "Document: 258|||| \n",
            "'arxiv_id': arXiv:2409.05049, \n",
            "'paper_link': https://arxiv.org/abs/2409.05049, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05049, \n",
            "Title: The Influence of Demographic Variation on the Perception of Industrial Robot Movements \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: The influence of individual differences on the perception and evaluation of interactions with robots has been researched for decades. Some human demographic characteristics have been shown to affect how individuals perceive interactions with robots. Still, it is to-date not clear whether, which and to what extent individual differences influence how we perceive robots, and even less is known about human factors and their effect on the perception of robot movements. In addition, most results on the relevance of individual differences investigate human-robot interactions with humanoid or social robots whereas interactions with industrial robots are underrepresented. We present a literature review on the relationship of robot movements and the influence of demographic variation. Our review reveals a limited comparability of existing findings due to a lack of standardized robot manipulations, various dependent variables used and differing experimental setups including different robot types. In addition, most studies have insufficient sample sizes to derive generalizable results. To overcome these shortcomings, we report the results from a Web-based experiment with 930 participants that studies the effect of demographic characteristics on the evaluation of movement behaviors of an articulated robot arm. Our findings demonstrate that most participants prefer an approach from the side, a large movement range, conventional numbers of rotations, smooth movements and neither fast nor slow movement speeds. Regarding individual differences, most of these preferences are robust to demographic variation, and only gender and age was found to cause slight preference differences between slow and fast movements.\n",
            "Score: 2\n",
            "\n",
            "Document: 305|||| \n",
            "'arxiv_id': arXiv:2409.05189, \n",
            "'paper_link': https://arxiv.org/abs/2409.05189, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05189, \n",
            "Title: Energy Internet: A Standardization-Based Blueprint Design \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: The decarbonization of power and energy systems faces a bottleneck: The enormous number of user-side resources cannot be properly managed and operated by centralized system operators, who used to send dispatch instructions only to a few large power plants. To break through, we need not only new devices and algorithms, but structural reforms of our energy systems. Taking the Internet as a paradigm, a practicable design of the Energy Internet is presented based on the principle of standardization. A combination of stylized data and energy delivery, referred to as a Block of Energy Exchange (BEE), is designed as the media to be communicated, which is parsed by the Energy Internet Card. Each Energy Internet Card is assigned a unique MAC address, defining a participant of the Energy Internet, whose standardized profile will be automatically updated according to BEE transfers without the intervention of any centralized operator. The structure of Energy Internet and protocols thereof to support the transfer of BEE are presented. System operators will become Energy Internet Service Providers, who operate the energy system by flow control and dispatching centralized resources, which is decoupled from users' behaviors in the Energy Internet. Example shows that the Energy Internet can not only reduce carbon emissions via interactions between peers, but also promotes energy democracy and dwindles the gap in energy equity.\n",
            "Score: 2\n",
            "\n",
            "Document: 361|||| \n",
            "'arxiv_id': arXiv:2409.05314, \n",
            "'paper_link': https://arxiv.org/abs/2409.05314, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05314, \n",
            "Title: Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: The emergence of large language models (LLMs) has significantly impacted various fields, from natural language processing to sectors like medicine and finance. However, despite their rapid proliferation, the applications of LLMs in telecommunications remain limited, often relying on general-purpose models that lack domain-specific specialization. This lack of specialization results in underperformance, particularly when dealing with telecommunications-specific technical terminology and their associated mathematical representations. This paper addresses this gap by first creating and disseminating Tele-Data, a comprehensive dataset of telecommunications material curated from relevant sources, and Tele-Eval, a large-scale question-and-answer dataset tailored to the domain. Through extensive experiments, we explore the most effective training techniques for adapting LLMs to the telecommunications domain, ranging from examining the division of expertise across various telecommunications aspects to employing parameter-efficient techniques. We also investigate how models of different sizes behave during adaptation and analyze the impact of their training data on this behavior. Leveraging these findings, we develop and open-source Tele-LLMs, the first series of language models ranging from 1B to 8B parameters, specifically tailored for telecommunications. Our evaluations demonstrate that these models outperform their general-purpose counterparts on Tele-Eval while retaining their previously acquired capabilities, thus avoiding the catastrophic forgetting phenomenon.\n",
            "Score: 2\n",
            "\n",
            "Document: 392|||| \n",
            "'arxiv_id': arXiv:2409.05384, \n",
            "'paper_link': https://arxiv.org/abs/2409.05384, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05384, \n",
            "Title: Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: In spite of great success in many image recognition tasks achieved by recent deep models, directly applying them to recognize low-resolution images may suffer from low accuracy due to the missing of informative details during resolution degradation. However, these images are still recognizable for subjects who are familiar with the corresponding high-resolution ones. Inspired by that, we propose a teacher-student learning approach to facilitate low-resolution image recognition via hybrid order relational knowledge distillation. The approach refers to three streams: the teacher stream is pretrained to recognize high-resolution images in high accuracy, the student stream is learned to identify low-resolution images by mimicking the teacher's behaviors, and the extra assistant stream is introduced as bridge to help knowledge transfer across the teacher to the student. To extract sufficient knowledge for reducing the loss in accuracy, the learning of student is supervised with multiple losses, which preserves the similarities in various order relational structures. In this way, the capability of recovering missing details of familiar low-resolution images can be effectively enhanced, leading to a better knowledge transfer. Extensive experiments on metric learning, low-resolution image classification and low-resolution face recognition tasks show the effectiveness of our approach, while taking reduced models.\n",
            "Score: 2\n",
            "\n",
            "Document: 572|||| \n",
            "'arxiv_id': arXiv:2409.05862, \n",
            "'paper_link': https://arxiv.org/abs/2409.05862, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05862, \n",
            "Title: Evaluating Multiview Object Consistency in Humans and Image Models \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: We introduce a benchmark to directly evaluate the alignment between human observers and vision models on a 3D shape inference task. We leverage an experimental design from the cognitive sciences which requires zero-shot visual inferences about object shape: given a set of images, participants identify which contain the same/different objects, despite considerable viewpoint variation. We draw from a diverse range of images that include common objects (e.g., chairs) as well as abstract shapes (i.e., procedurally generated `nonsense' objects). After constructing over 2000 unique image sets, we administer these tasks to human participants, collecting 35K trials of behavioral data from over 500 participants. This includes explicit choice behaviors as well as intermediate measures, such as reaction time and gaze data. We then evaluate the performance of common vision models (e.g., DINOv2, MAE, CLIP). We find that humans outperform all models by a wide margin. Using a multi-scale evaluation approach, we identify underlying similarities and differences between models and humans: while human-model performance is correlated, humans allocate more time/processing on challenging trials. All images, data, and code can be accessed via our project page.\n",
            "Score: 2\n",
            "\n",
            "Document: 573|||| \n",
            "'arxiv_id': arXiv:2409.05863, \n",
            "'paper_link': https://arxiv.org/abs/2409.05863, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05863, \n",
            "Title: Promptable Closed-loop Traffic Simulation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Simulation stands as a cornerstone for safe and efficient autonomous driving development. At its core a simulation system ought to produce realistic, reactive, and controllable traffic patterns. In this paper, we propose ProSim, a multimodal promptable closed-loop traffic simulation framework. ProSim allows the user to give a complex set of numerical, categorical or textual prompts to instruct each agent's behavior and intention. ProSim then rolls out a traffic scenario in a closed-loop manner, modeling each agent's interaction with other traffic participants. Our experiments show that ProSim achieves high prompt controllability given different user prompts, while reaching competitive performance on the Waymo Sim Agents Challenge when no prompt is given. To support research on promptable traffic simulation, we create ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with over 10M text prompts for over 520k real-world driving scenarios. We will release code of ProSim as well as data and labeling tools of ProSim-Instruct-520k at this https URL.\n",
            "Score: 2\n",
            "\n",
            "Document: 614|||| \n",
            "'arxiv_id': arXiv:2409.05086, \n",
            "'paper_link': https://arxiv.org/abs/2409.05086, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05086, \n",
            "Title: Exploring the Optimal Size of Grid-forming Energy Storage in an Off-grid Renewable P2H System under Multi-timescale Energy Management \n",
            "Subjects: Optimization and Control (math.OC) \n",
            "Abstract: Utility-scale off-grid renewable power-to-hydrogen systems (OReP2HSs) typically include photovoltaic plants, wind turbines, electrolyzers (ELs), and energy storage systems. As an island system, OReP2HS requires at least one component, generally the battery energy storage system (BESS), that operates for grid-forming control to provide frequency and voltage references and regulate them through transient power support and short-term energy balance regulation. While larger BESS capacity increases this ability, it also raises investment costs. This paper proposes a framework of layered multi-timescale energy management system (EMS) and evaluates the most cost-effective size of the grid-forming BESS in the OReP2HS. The proposed EMS covers the timescales ranging from those for power system transient behaviors to intra-day scheduling, coordinating renewable power, BESS, and ELs. Then, an iterative search procedure based on high-fidelity simulation is employed to determine the size of the BESS with minimal levelized cost of hydrogen (LCOH). Simulations over a reference year, based on the data from a planned OReP2HS project in Inner Mongolia, China, show that with the proposed EMS, the base-case optimal LCOH is 33.212 CNY/kg (4.581 USD/kg). The capital expenditure of the BESS accounts for 17.83% of the total, and the optimal BESS size accounts for 13.6% of the rated hourly energy output of power sources. Sensitivity analysis reveals that by reducing the electrolytic load adjustment time step from 90 to 5 s and increasing its ramping limit from 1% to 10% rated power per second, the BESS size decreases by 53.57%, and the LCOH decreases to 25.458 CNY/kg (3.511 USD/kg). Considering the cost of designing and manufacturing utility-scale ELs with fast load regulation capability, a load adjustment time step of 5-10 s and a ramping limit of 4-6% rated power per second are recommended.\n",
            "Score: 2\n",
            "\n",
            "Document: 703|||| \n",
            "'arxiv_id': arXiv:2307.11880, \n",
            "'paper_link': https://arxiv.org/abs/2307.11880, \n",
            "'pdf_link': https://arxiv.org/pdf/2307.11880, \n",
            "Title: Bans vs. Warning Labels: Examining Bystanders' Support for Community-wide Moderation Interventions \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Social media platforms like Facebook and Reddit host thousands of user-governed online communities. These platforms sanction communities that frequently violate platform policies; however, public perceptions of such sanctions remain unclear. In a pre-registered survey conducted in the US, I explore bystander perceptions of content moderation for communities that frequently feature hate speech, violent content, and sexually explicit content. Two community-wide moderation interventions are tested: (1) community bans, where all community posts are removed, and (2) community warning labels, where an interstitial warning label precedes access. I examine how third-person effects and support for free speech influence user approval of these interventions on any platform. My regression analyses show that presumed effects on others are a significant predictor of backing for both interventions, while free speech beliefs significantly influence participants' inclination for using warning labels. Analyzing the open-ended responses, I find that community-wide bans are often perceived as too coarse, and users instead value sanctions in proportion to the severity and type of infractions. I report on concerns that norm-violating communities could reinforce inappropriate behaviors and show how users' choice of sanctions is influenced by their perceived effectiveness. I discuss the implications of these results for HCI research on online harms and content moderation.\n",
            "Score: 2\n",
            "\n",
            "Document: 725|||| \n",
            "'arxiv_id': arXiv:2310.08896, \n",
            "'paper_link': https://arxiv.org/abs/2310.08896, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.08896, \n",
            "Title: Migrant Resettlement by Evolutionary Multi-objective Optimization \n",
            "Subjects: Neural and Evolutionary Computing (cs.NE) \n",
            "Abstract: Migration has been a universal phenomenon, which brings opportunities as well as challenges for global development. As the number of migrants (e.g., refugees) increases rapidly in recent years, a key challenge faced by each country is the problem of migrant resettlement. This problem has attracted scientific research attention, from the perspective of maximizing the employment rate. Previous works mainly formulated migrant resettlement as an approximately submodular optimization problem subject to multiple matroid constraints and employed the greedy algorithm, whose performance, however, may be limited due to its greedy nature. In this paper, we propose a new framework MR-EMO based on Evolutionary Multi-objective Optimization, which reformulates Migrant Resettlement as a bi-objective optimization problem that maximizes the expected number of employed migrants and minimizes the number of dispatched migrants simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve the bi-objective problem. We implement MR-EMO using three MOEAs, the popular NSGA-II, MOEA/D as well as the theoretically grounded GSEMO. To further improve the performance of MR-EMO, we propose a specific MOEA, called GSEMO-SR, using matrix-swap mutation and repair mechanism, which has a better ability to search for feasible solutions. We prove that MR-EMO using either GSEMO or GSEMO-SR can achieve better theoretical guarantees than the previous greedy algorithm. Experimental results under the interview and coordination migration models clearly show the superiority of MR-EMO (with either NSGA-II, MOEA/D, GSEMO or GSEMO-SR) over previous algorithms, and that using GSEMO-SR leads to the best performance of MR-EMO.\n",
            "Score: 2\n",
            "\n",
            "Document: 792|||| \n",
            "'arxiv_id': arXiv:2403.05771, \n",
            "'paper_link': https://arxiv.org/abs/2403.05771, \n",
            "'pdf_link': https://arxiv.org/pdf/2403.05771, \n",
            "Title: Providing Safety Assurances for Systems with Unknown Dynamics \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: As autonomous systems become more complex and integral in our society, the need to accurately model and safely control these systems has increased significantly. In the past decade, there has been tremendous success in using deep learning techniques to model and control systems that are difficult to model using first principles. However, providing safety assurances for such systems remains difficult, partially due to the uncertainty in the learned model. In this work, we aim to provide safety assurances for systems whose dynamics are not readily derived from first principles and, hence, are more advantageous to be learned using deep learning techniques. Given the system of interest and safety constraints, we learn an ensemble model of the system dynamics from data. Leveraging ensemble uncertainty as a measure of uncertainty in the learned dynamics model, we compute a maximal robust control invariant set, starting from which the system is guaranteed to satisfy the safety constraints under the condition that realized model uncertainties are contained in the predefined set of admissible model uncertainty. We demonstrate the effectiveness of our method using a simulated case study with an inverted pendulum and a hardware experiment with a TurtleBot. The experiments show that our method robustifies the control actions of the system against model uncertainty and generates safe behaviors without being overly restrictive. The codes and accompanying videos can be found on the project website.\n",
            "Score: 2\n",
            "\n",
            "Document: 815|||| \n",
            "'arxiv_id': arXiv:2404.06841, \n",
            "'paper_link': https://arxiv.org/abs/2404.06841, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.06841, \n",
            "Title: Projection method for quasiperiodic elliptic equations and application to quasiperiodic homogenization \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: In this study, our main objective is to address the challenge of solving elliptic equations with quasiperiodic coefficients. To achieve accurate and efficient computation, we introduce the projection method, which enables the embedding of quasiperiodic systems into higher-dimensional periodic systems. To enhance the computational efficiency, we propose a compressed storage strategy for the stiffness matrix by its multi-level block circulant structure, significantly reducing memory requirements. Furthermore, we design a diagonal preconditioner to efficiently solve the resulting high-dimensional linear system by reducing the condition number of the stiffness matrix. These techniques collectively contribute to the computational effectiveness of our proposed approach. Convergence analysis shows the spectral accuracy of our proposed method. We demonstrate the effectiveness and accuracy of our approach through a series of numerical examples. Moreover, we apply our method to achieve a highly accurate computation of the homogenized coefficients for a quasiperiodic multiscale elliptic equation.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"Retrieval-Augmented Systems\", 1),\n",
        "        (\"RAG systems\", 1),\n",
        "        (\"Retrieval-Augmented Generation\", 1),\n",
        "        (\"RAG evaluation metric \", 3),\n",
        "        # (\"\", 1),\n",
        "        # (\"\", 1),\n",
        "        # (\"\", 1),\n",
        "        # (\"\", 1),\n",
        "        # (\"\", 1),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oZ9kzdx6xhG",
        "outputId": "0de10adc-c9f8-4de1-c99c-c00dc534f2c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: Retrieval-Augmented Systems\n",
            "Total Matches in Set: 9\n",
            "Matches Above Score-Floor in Set: 2\n",
            "2024-09-10__122810924051\n",
            "\n",
            "Showing 2 in top-9 out of 9 total results.     -> 2 of 9/9\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 482|||| \n",
            "'arxiv_id': arXiv:2409.05591, \n",
            "'paper_link': https://arxiv.org/abs/2409.05591, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05591, \n",
            "Title: MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Retrieval-Augmented Generation (RAG) leverages retrieval tools to access external databases, thereby enhancing the generation quality of large language models (LLMs) through optimized context. However, the existing retrieval methods are constrained inherently, as they can only perform relevance matching between explicitly stated queries and well-formed knowledge, but unable to handle tasks involving ambiguous information needs or unstructured knowledge. Consequently, existing RAG systems are primarily effective for straightforward question-answering tasks. In this work, we propose \\textbf{MemoRAG}, a novel retrieval-augmented generation paradigm empowered by long-term memory. MemoRAG adopts a dual-system architecture. On the one hand, it employs a \\textit{light but long-range} LLM to form the global memory of database. Once a task is presented, it generates draft answers, cluing the retrieval tools to locate useful information within the database. On the other hand, it leverages an \\textit{expensive but expressive} LLM, which generates the ultimate answer based on the retrieved information. Building on this general framework, we further optimize MemoRAG's performance by enhancing its cluing mechanism and memorization capacity. In our experiment, MemoRAG achieves superior performance across a variety of evaluation tasks, including both complex ones where conventional RAG fails and straightforward ones where RAG is commonly applied.\n",
            "Score: 2\n",
            "\n",
            "Document: 902|||| \n",
            "'arxiv_id': arXiv:2407.03627, \n",
            "'paper_link': https://arxiv.org/abs/2407.03627, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.03627, \n",
            "Title: DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks. However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module. Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information. Therefore, in this work, we propose DSLR (Document Refinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages. We experimentally validate DSLR on multiple open-domain QA datasets and the results demonstrate that DSLR significantly enhances the RAG performance over conventional fixed-size passage. Furthermore, our DSLR enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"mental health\", 5),\n",
        "        (\"psychological health\", 5),\n",
        "        (\"psycholog\", 2),  # stem vs. lemma\n",
        "        (\"mental health care\", 3),\n",
        "        (\"neuroscience\", 2),\n",
        "        (\"psychological assessment\", 2),\n",
        "        (\"personality assessment\", 2),\n",
        "        (\"personality inference\", 2),\n",
        "        (\"personality traits\", 2),\n",
        "        (\"personality dimensions\", 2),\n",
        "        (\"emotion\", 15),\n",
        "        (\"sports psychology\", 15),\n",
        "        (\"sentiment recognition\", 10),\n",
        "        (\"Emotion Recognition\", 5),\n",
        "        # (\"\", 5),\n",
        "        # (\"\", 5),\n",
        "\n",
        "        # disease terms\n",
        "        (\"depression\", 5),\n",
        "        (\"anxiety\", 5),\n",
        "        (\"mental disorders\", 2),\n",
        "        (\"social anxiety disorder\", 4),\n",
        "        (\"mental illness\", 2),\n",
        "        (\"Major Depressive Disorder\", 2),\n",
        "        (\"MDD\", 2),\n",
        "        (\"psychological stressors\", 2),\n",
        "        (\"cognitive impairment\", 2),\n",
        "        (\"mci\", 2),\n",
        "        (\"personality\", 1)\n",
        "        # (\"\", 2),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "id": "CixuXw-Fl3-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9b4924-2e9b-4d17-e651-091dc1eccd51"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: mental health\n",
            "Total Matches in Set: 49\n",
            "Matches Above Score-Floor in Set: 49\n",
            "2024-09-10__122811079733\n",
            "\n",
            "Showing 49 in top-45 out of 49 total results.     -> 49 of 45/49\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 1|||| \n",
            "'arxiv_id': arXiv:2409.04447, \n",
            "'paper_link': https://arxiv.org/abs/2409.04447, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04447, \n",
            "Title: Leveraging Contrastive Learning and Self-Training for Multimodal Emotion Recognition with Limited Labeled Samples \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: The Multimodal Emotion Recognition challenge MER2024 focuses on recognizing emotions using audio, language, and visual signals. In this paper, we present our submission solutions for the Semi-Supervised Learning Sub-Challenge (MER2024-SEMI), which tackles the issue of limited annotated data in emotion recognition. Firstly, to address the class imbalance, we adopt an oversampling strategy. Secondly, we propose a modality representation combinatorial contrastive learning (MR-CCL) framework on the trimodal input data to establish robust initial models. Thirdly, we explore a self-training approach to expand the training set. Finally, we enhance prediction robustness through a multi-classifier weighted soft voting strategy. Our proposed method is validated to be effective on the MER2024-SEMI Challenge, achieving a weighted average F-score of 88.25% and ranking 6th on the leaderboard. Our project is available at this https URL.\n",
            "Score: 20\n",
            "\n",
            "Document: 231|||| \n",
            "'arxiv_id': arXiv:2409.05004, \n",
            "'paper_link': https://arxiv.org/abs/2409.05004, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05004, \n",
            "Title: Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Voice conversion (VC) aims to modify the speaker's timbre while retaining speech content. Previous approaches have tokenized the outputs from self-supervised into semantic tokens, facilitating disentanglement of speech content information. Recently, in-context learning (ICL) has emerged in text-to-speech (TTS) systems for effectively modeling specific characteristics such as timbre through context conditioning. This paper proposes an ICL capability enhanced VC system (ICL-VC) employing a mask and reconstruction training strategy based on flow-matching generative models. Augmented with semantic tokens, our experiments on the LibriTTS dataset demonstrate that ICL-VC improves speaker similarity. Additionally, we find that k-means is a versatile tokenization method applicable to various pre-trained models. However, the ICL-VC system faces challenges in preserving the prosody of the source speech. To mitigate this issue, we propose incorporating prosody embeddings extracted from a pre-trained emotion recognition model into our system. Integration of prosody embeddings notably enhances the system's capability to preserve source speech prosody, as validated on the Emotional Speech Database.\n",
            "Score: 20\n",
            "\n",
            "Document: 237|||| \n",
            "'arxiv_id': arXiv:2409.05015, \n",
            "'paper_link': https://arxiv.org/abs/2409.05015, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05015, \n",
            "Title: Improving Multimodal Emotion Recognition by Leveraging Acoustic Adaptation and Visual Alignment \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: Multimodal Emotion Recognition (MER) aims to automatically identify and understand human emotional states by integrating information from various modalities. However, the scarcity of annotated multimodal data significantly hinders the advancement of this research field. This paper presents our solution for the MER-SEMI sub-challenge of MER 2024. First, to better adapt acoustic modality features for the MER task, we experimentally evaluate the contributions of different layers of the pre-trained speech model HuBERT in emotion recognition. Based on these observations, we perform Parameter-Efficient Fine-Tuning (PEFT) on the layers identified as most effective for emotion recognition tasks, thereby achieving optimal adaptation for emotion recognition with a minimal number of learnable parameters. Second, leveraging the strengths of the acoustic modality, we propose a feature alignment pre-training method. This approach uses large-scale unlabeled data to train a visual encoder, thereby promoting the semantic alignment of visual features within the acoustic feature space. Finally, using the adapted acoustic features, aligned visual features, and lexical features, we employ an attention mechanism for feature fusion. On the MER2024-SEMI test set, the proposed method achieves a weighted F1 score of 88.90%, ranking fourth among all participating teams, validating the effectiveness of our approach.\n",
            "Score: 20\n",
            "\n",
            "Document: 294|||| \n",
            "'arxiv_id': arXiv:2409.05148, \n",
            "'paper_link': https://arxiv.org/abs/2409.05148, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05148, \n",
            "Title: Better Spanish Emotion Recognition In-the-wild: Bringing Attention to Deep Spectrum Voice Analysis \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: Within the context of creating new Socially Assistive Robots, emotion recognition has become a key development factor, as it allows the robot to adapt to the user's emotional state in the wild. In this work, we focused on the analysis of two voice recording Spanish datasets: ELRA-S0329 and EmoMatchSpanishDB. Specifically, we centered our work in the paralanguage, e.~g. the vocal characteristics that go along with the message and clarifies the meaning. We proposed the use of the DeepSpectrum method, which consists of extracting a visual representation of the audio tracks and feeding them to a pretrained CNN model. For the classification task, DeepSpectrum is often paired with a Support Vector Classifier --DS-SVC--, or a Fully-Connected deep-learning classifier --DS-FC--. We compared the results of the DS-SVC and DS-FC architectures with the state-of-the-art (SOTA) for ELRA-S0329 and EmoMatchSpanishDB. Moreover, we proposed our own classifier based upon Attention Mechanisms, namely DS-AM. We trained all models against both datasets, and we found that our DS-AM model outperforms the SOTA models for the datasets and the SOTA DeepSpectrum architectures. Finally, we trained our DS-AM model in one dataset and tested it in the other, to simulate real-world conditions on how biased is the model to the dataset.\n",
            "Score: 20\n",
            "\n",
            "Document: 328|||| \n",
            "'arxiv_id': arXiv:2409.05243, \n",
            "'paper_link': https://arxiv.org/abs/2409.05243, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05243, \n",
            "Title: Mamba-Enhanced Text-Audio-Video Alignment Network for Emotion Recognition in Conversations \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Emotion Recognition in Conversations (ERCs) is a vital area within multimodal interaction research, dedicated to accurately identifying and classifying the emotions expressed by speakers throughout a conversation. Traditional ERC approaches predominantly rely on unimodal cues\\-such as text, audio, or visual data\\-leading to limitations in their effectiveness. These methods encounter two significant challenges: 1) Consistency in multimodal information. Before integrating various modalities, it is crucial to ensure that the data from different sources is aligned and coherent. 2) Contextual information capture. Successfully fusing multimodal features requires a keen understanding of the evolving emotional tone, especially in lengthy dialogues where emotions may shift and develop over time. To address these limitations, we propose a novel Mamba-enhanced Text-Audio-Video alignment network (MaTAV) for the ERC task. MaTAV is with the advantages of aligning unimodal features to ensure consistency across different modalities and handling long input sequences to better capture contextual multimodal information. The extensive experiments on the MELD and IEMOCAP datasets demonstrate that MaTAV significantly outperforms existing state-of-the-art methods on the ERC task with a big margin.\n",
            "Score: 20\n",
            "\n",
            "Document: 594|||| \n",
            "'arxiv_id': arXiv:2409.04723, \n",
            "'paper_link': https://arxiv.org/abs/2409.04723, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04723, \n",
            "Title: NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series \n",
            "Subjects: Signal Processing (eess.SP) \n",
            "Abstract: Sleep is known to be a key factor in emotional regulation and overall mental health. In this study, we explore the integration of sleep measures from the previous night into wearable-based mood recognition. To this end, we propose NapTune, a novel prompt-tuning framework that utilizes sleep-related measures as additional inputs to a frozen pre-trained wearable time-series encoder by adding and training lightweight prompt parameters to each Transformer layer. Through rigorous empirical evaluation, we demonstrate that the inclusion of sleep data using NapTune not only improves mood recognition performance across different wearable time-series namely ECG, PPG, and EDA, but also makes it more sample-efficient. Our method demonstrates significant improvements over the best baselines and unimodal variants. Furthermore, we analyze the impact of adding sleep-related measures on recognizing different moods as well as the influence of individual sleep-related measures.\n",
            "Score: 20\n",
            "\n",
            "Document: 654|||| \n",
            "'arxiv_id': arXiv:2409.05770, \n",
            "'paper_link': https://arxiv.org/abs/2409.05770, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05770, \n",
            "Title: Consensus-based Distributed Quantum Kernel Learning for Speech Recognition \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: This paper presents a Consensus-based Distributed Quantum Kernel Learning (CDQKL) framework aimed at improving speech recognition through distributed quantum computing.CDQKL addresses the challenges of scalability and data privacy in centralized quantum kernel learning. It does this by distributing computational tasks across quantum terminals, which are connected through classical channels. This approach enables the exchange of model parameters without sharing local training data, thereby maintaining data privacy and enhancing computational efficiency. Experimental evaluations on benchmark speech emotion recognition datasets demonstrate that CDQKL achieves competitive classification accuracy and scalability compared to centralized and local quantum kernel learning models. The distributed nature of CDQKL offers advantages in privacy preservation and computational efficiency, making it suitable for data-sensitive fields such as telecommunications, automotive, and finance. The findings suggest that CDQKL can effectively leverage distributed quantum computing for large-scale machine-learning tasks.\n",
            "Score: 20\n",
            "\n",
            "Document: 62|||| \n",
            "'arxiv_id': arXiv:2409.04639, \n",
            "'paper_link': https://arxiv.org/abs/2409.04639, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04639, \n",
            "Title: High-Speed and Impact Resilient Teleoperation of Humanoid Robots \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Teleoperation of humanoid robots has long been a challenging domain, necessitating advances in both hardware and software to achieve seamless and intuitive control. This paper presents an integrated solution based on several elements: calibration-free motion capture and retargeting, low-latency fast whole-body kinematics streaming toolbox and high-bandwidth cycloidal actuators. Our motion retargeting approach stands out for its simplicity, requiring only 7 IMUs to generate full-body references for the robot. The kinematics streaming toolbox, ensures real-time, responsive control of the robot's movements, significantly reducing latency and enhancing operational efficiency. Additionally, the use of cycloidal actuators makes it possible to withstand high speeds and impacts with the environment. Together, these approaches contribute to a teleoperation framework that offers unprecedented performance. Experimental results on the humanoid robot Nadia demonstrate the effectiveness of the integrated system.\n",
            "Score: 15\n",
            "\n",
            "Document: 209|||| \n",
            "'arxiv_id': arXiv:2409.04961, \n",
            "'paper_link': https://arxiv.org/abs/2409.04961, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04961, \n",
            "Title: Heterogeneous LiDAR Dataset for Benchmarking Robust Localization in Diverse Degenerate Scenarios \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: The ability to estimate pose and generate maps using 3D LiDAR significantly enhances robotic system autonomy. However, existing open-source datasets lack representation of geometrically degenerate environments, limiting the development and benchmarking of robust LiDAR SLAM algorithms. To address this gap, we introduce GEODE, a comprehensive multi-LiDAR, multi-scenario dataset specifically designed to include real-world geometrically degenerate environments. GEODE comprises 64 trajectories spanning over 64 kilometers across seven diverse settings with varying degrees of degeneracy. The data was meticulously collected to promote the development of versatile algorithms by incorporating various LiDAR sensors, stereo cameras, IMUs, and diverse motion conditions. We evaluate state-of-the-art SLAM approaches using the GEODE dataset to highlight current limitations in LiDAR SLAM techniques. This extensive dataset will be publicly available at this https URL, supporting further advancements in LiDAR-based SLAM.\n",
            "Score: 15\n",
            "\n",
            "Document: 234|||| \n",
            "'arxiv_id': arXiv:2409.05007, \n",
            "'paper_link': https://arxiv.org/abs/2409.05007, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05007, \n",
            "Title: Audio-Guided Fusion Techniques for Multimodal Emotion Analysis \n",
            "Subjects: Sound (cs.SD) \n",
            "Abstract: In this paper, we propose a solution for the semi-supervised learning track (MER-SEMI) in MER2024. First, in order to enhance the performance of the feature extractor on sentiment classification tasks,we fine-tuned video and text feature extractors, specifically CLIP-vit-large and Baichuan-13B, using labeled data. This approach effectively preserves the original emotional information conveyed in the videos. Second, we propose an Audio-Guided Transformer (AGT) fusion mechanism, which leverages the robustness of Hubert-large, showing superior effectiveness in fusing both inter-channel and intra-channel information. Third, To enhance the accuracy of the model, we iteratively apply self-supervised learning by using high-confidence unlabeled data as pseudo-labels. Finally, through black-box probing, we discovered an imbalanced data distribution between the training and test sets. Therefore, We adopt a prior-knowledge-based voting mechanism. The results demonstrate the effectiveness of our strategy, ultimately earning us third place in the MER-SEMI track.\n",
            "Score: 15\n",
            "\n",
            "Document: 366|||| \n",
            "'arxiv_id': arXiv:2409.05330, \n",
            "'paper_link': https://arxiv.org/abs/2409.05330, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05330, \n",
            "Title: KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks Generation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Audio-driven talking face generation is a widely researched topic due to its high applicability. Reconstructing a talking face using audio significantly contributes to fields such as education, healthcare, online conversations, virtual assistants, and virtual reality. Early studies often focused solely on changing the mouth movements, which resulted in outcomes with limited practical applications. Recently, researchers have proposed a new approach of constructing the entire face, including face pose, neck, and shoulders. To achieve this, they need to generate through landmarks. However, creating stable landmarks that align well with the audio is a challenge. In this paper, we propose the KFusion of Dual-Domain model, a robust model that generates landmarks from audio. We separate the audio into two distinct domains to learn emotional information and facial context, then use a fusion mechanism based on the KAN model. Our model demonstrates high efficiency compared to recent models. This will lay the groundwork for the development of the audio-driven talking face generation problem in the future.\n",
            "Score: 15\n",
            "\n",
            "Document: 394|||| \n",
            "'arxiv_id': arXiv:2409.05387, \n",
            "'paper_link': https://arxiv.org/abs/2409.05387, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05387, \n",
            "Title: Decoupling Contact for Fine-Grained Motion Style Transfer \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Motion style transfer changes the style of a motion while retaining its content and is useful in computer animations and games. Contact is an essential component of motion style transfer that should be controlled explicitly in order to express the style vividly while enhancing motion naturalness and quality. However, it is unknown how to decouple and control contact to achieve fine-grained control in motion style transfer. In this paper, we present a novel style transfer method for fine-grained control over contacts while achieving both motion naturalness and spatial-temporal variations of style. Based on our empirical evidence, we propose controlling contact indirectly through the hip velocity, which can be further decomposed into the trajectory and contact timing, respectively. To this end, we propose a new model that explicitly models the correlations between motions and trajectory/contact timing/style, allowing us to decouple and control each separately. Our approach is built around a motion manifold, where hip controls can be easily integrated into a Transformer-based decoder. It is versatile in that it can generate motions directly as well as be used as post-processing for existing methods to improve quality and contact controllability. In addition, we propose a new metric that measures a correlation pattern of motions based on our empirical evidence, aligning well with human perception in terms of motion naturalness. Based on extensive evaluation, our method outperforms existing methods in terms of style expressivity and motion quality.\n",
            "Score: 15\n",
            "\n",
            "Document: 400|||| \n",
            "'arxiv_id': arXiv:2409.05399, \n",
            "'paper_link': https://arxiv.org/abs/2409.05399, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05399, \n",
            "Title: Sequential Posterior Sampling with Diffusion Models \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Diffusion models have quickly risen in popularity for their ability to model complex distributions and perform effective posterior sampling. Unfortunately, the iterative nature of these generative models makes them computationally expensive and unsuitable for real-time sequential inverse problems such as ultrasound imaging. Considering the strong temporal structure across sequences of frames, we propose a novel approach that models the transition dynamics to improve the efficiency of sequential diffusion posterior sampling in conditional image synthesis. Through modeling sequence data using a video vision transformer (ViViT) transition model based on previous diffusion outputs, we can initialize the reverse diffusion trajectory at a lower noise scale, greatly reducing the number of iterations required for convergence. We demonstrate the effectiveness of our approach on a real-world dataset of high frame rate cardiac ultrasound images and show that it achieves the same performance as a full diffusion trajectory while accelerating inference 25$\\times$, enabling real-time posterior sampling. Furthermore, we show that the addition of a transition model improves the PSNR up to 8\\% in cases with severe motion. Our method opens up new possibilities for real-time applications of diffusion models in imaging and other domains requiring real-time inference.\n",
            "Score: 15\n",
            "\n",
            "Document: 540|||| \n",
            "'arxiv_id': arXiv:2409.05772, \n",
            "'paper_link': https://arxiv.org/abs/2409.05772, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05772, \n",
            "Title: A CLIP-based siamese approach for meme classification \n",
            "Subjects: Multimedia (cs.MM) \n",
            "Abstract: Memes are an increasingly prevalent element of online discourse in social networks, especially among young audiences. They carry ideas and messages that range from humorous to hateful, and are widely consumed. Their potentially high impact requires adequate means of control to moderate their use in large scale. In this work, we propose SimCLIP a deep learning-based architecture for cross-modal understanding of memes, leveraging a pre-trained CLIP encoder to produce context-aware embeddings and a Siamese fusion technique to capture the interactions between text and image. We perform an extensive experimentation on seven meme classification tasks across six datasets. We establish a new state of the art in Memotion7k with a 7.25% relative F1-score improvement, and achieve super-human performance on Harm-P with 13.73% F1-Score improvement. Our approach demonstrates the potential for compact meme classification models, enabling accurate and efficient meme monitoring. We share our code at this https URL\n",
            "Score: 15\n",
            "\n",
            "Document: 579|||| \n",
            "'arxiv_id': arXiv:2409.04468, \n",
            "'paper_link': https://arxiv.org/abs/2409.04468, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04468, \n",
            "Title: Controlled fluid transport by the collective motion of microrotors \n",
            "Subjects: Optimization and Control (math.OC) \n",
            "Abstract: Torque-driven microscale swimming robots, or microrotors, hold significant potential in biomedical applications such as targeted drug delivery, minimally invasive surgery, and micromanipulation. This paper addresses the challenge of controlling the transport of fluid volumes using the flow fields generated by interacting groups of microrotors. Our approach uses polynomial chaos expansions to model the time evolution of fluid particle distributions and formulate an optimal control problem, which we solve numerically. We implement this framework in simulation to achieve the controlled transport of an initial fluid particle distribution to a target destination while minimizing undesirable effects such as stretching and mixing. We consider the case where translational velocities of the rotors are directly controlled, as well as the case where only torques are controlled and the rotors move in response to the collective flow fields they generate. We analyze the solution of this optimal control problem by computing the Lagrangian coherent structures of the associated flow field, which reveal the formation of transport barriers that efficiently guide particles toward their target. This analysis provides insights into the underlying mechanisms of controlled transport.\n",
            "Score: 15\n",
            "\n",
            "Document: 714|||| \n",
            "'arxiv_id': arXiv:2309.12784, \n",
            "'paper_link': https://arxiv.org/abs/2309.12784, \n",
            "'pdf_link': https://arxiv.org/pdf/2309.12784, \n",
            "Title: Learning to Walk and Fly with Adversarial Motion Priors \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Robot multimodal locomotion encompasses the ability to transition between walking and flying, representing a significant challenge in robotics. This work presents an approach that enables automatic smooth transitions between legged and aerial locomotion. Leveraging the concept of Adversarial Motion Priors, our method allows the robot to imitate motion datasets and accomplish the desired task without the need for complex reward functions. The robot learns walking patterns from human-like gaits and aerial locomotion patterns from motions obtained using trajectory optimization. Through this process, the robot adapts the locomotion scheme based on environmental feedback using reinforcement learning, with the spontaneous emergence of mode-switching behavior. The results highlight the potential for achieving multimodal locomotion in aerial humanoid robotics through automatic control of walking and flying modes, paving the way for applications in diverse domains such as search and rescue, surveillance, and exploration missions. This research contributes to advancing the capabilities of aerial humanoid robots in terms of versatile locomotion in various environments.\n",
            "Score: 15\n",
            "\n",
            "Document: 719|||| \n",
            "'arxiv_id': arXiv:2310.02523, \n",
            "'paper_link': https://arxiv.org/abs/2310.02523, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.02523, \n",
            "Title: A Spatio-Temporal Attention-Based Method for Detecting Student Classroom Behaviors \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Accurately detecting student behavior from classroom videos is beneficial for analyzing their classroom status and improving teaching efficiency. However, low accuracy in student classroom behavior detection is a prevalent issue. To address this issue, we propose a Spatio-Temporal Attention-Based Method for Detecting Student Classroom Behaviors (BDSTA). Firstly, the SlowFast network is used to generate motion and environmental information feature maps from the video. Then, the spatio-temporal attention module is applied to the feature maps, including information aggregation, compression and stimulation processes. Subsequently, attention maps in the time, channel and space dimensions are obtained, and multi-label behavior classification is performed based on these attention maps. To solve the long-tail data problem that exists in student classroom behavior datasets, we use an improved focal loss function to assign more weight to the tail class data during training. Experimental results are conducted on a self-made student classroom behavior dataset named STSCB. Compared with the SlowFast model, the average accuracy of student behavior classification detection improves by 8.94\\% using BDSTA.\n",
            "Score: 15\n",
            "\n",
            "Document: 733|||| \n",
            "'arxiv_id': arXiv:2310.18917, \n",
            "'paper_link': https://arxiv.org/abs/2310.18917, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.18917, \n",
            "Title: TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural Radiance Fields \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Previous attempts to integrate Neural Radiance Fields (NeRF) into the Simultaneous Localization and Mapping (SLAM) framework either rely on the assumption of static scenes or require the ground truth camera poses, which impedes their application in real-world scenarios. This paper proposes a time-varying representation to track and reconstruct the dynamic scenes. Firstly, two processes, a tracking process and a mapping process, are maintained simultaneously in our framework. In the tracking process, all input images are uniformly sampled and then progressively trained in a self-supervised paradigm. In the mapping process, we leverage motion masks to distinguish dynamic objects from the static background, and sample more pixels from dynamic areas. Secondly, the parameter optimization for both processes is comprised of two stages: the first stage associates time with 3D positions to convert the deformation field to the canonical field. The second stage associates time with the embeddings of the canonical field to obtain colors and a Signed Distance Function (SDF). Lastly, we propose a novel keyframe selection strategy based on the overlapping rate. Our approach is evaluated on two synthetic datasets and one real-world dataset, and the experiments validate that our method achieves competitive results in both tracking and mapping when compared to existing state-of-the-art NeRF-based dynamic SLAM systems.\n",
            "Score: 15\n",
            "\n",
            "Document: 744|||| \n",
            "'arxiv_id': arXiv:2312.05447, \n",
            "'paper_link': https://arxiv.org/abs/2312.05447, \n",
            "'pdf_link': https://arxiv.org/pdf/2312.05447, \n",
            "Title: From Static to Dynamic: Adapting Landmark-Aware Image Models for Facial Expression Recognition in Videos \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Dynamic facial expression recognition (DFER) in the wild is still hindered by data limitations, e.g., insufficient quantity and diversity of pose, occlusion and illumination, as well as the inherent ambiguity of facial expressions. In contrast, static facial expression recognition (SFER) currently shows much higher performance and can benefit from more abundant high-quality training data. Moreover, the appearance features and dynamic dependencies of DFER remain largely unexplored. To tackle these challenges, we introduce a novel Static-to-Dynamic model (S2D) that leverages existing SFER knowledge and dynamic information implicitly encoded in extracted facial landmark-aware features, thereby significantly improving DFER performance. Firstly, we build and train an image model for SFER, which incorporates a standard Vision Transformer (ViT) and Multi-View Complementary Prompters (MCPs) only. Then, we obtain our video model (i.e., S2D), for DFER, by inserting Temporal-Modeling Adapters (TMAs) into the image model. MCPs enhance facial expression features with landmark-aware features inferred by an off-the-shelf facial landmark detector. And the TMAs capture and model the relationships of dynamic changes in facial expressions, effectively extending the pre-trained image model for videos. Notably, MCPs and TMAs only increase a fraction of trainable parameters (less than +10\\%) to the original image model. Moreover, we present a novel Emotion-Anchors (i.e., reference samples for each emotion category) based Self-Distillation Loss to reduce the detrimental influence of ambiguous emotion labels, further enhancing our S2D. Experiments conducted on popular SFER and DFER datasets show that we achieve the state of the art.\n",
            "Score: 15\n",
            "\n",
            "Document: 770|||| \n",
            "'arxiv_id': arXiv:2402.01086, \n",
            "'paper_link': https://arxiv.org/abs/2402.01086, \n",
            "'pdf_link': https://arxiv.org/pdf/2402.01086, \n",
            "Title: Sim-to-Real of Soft Robots with Learned Residual Physics \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Accurately modeling soft robots in simulation is computationally expensive and commonly falls short of representing the real world. This well-known discrepancy, known as the sim-to-real gap, can have several causes, such as coarsely approximated geometry and material models, manufacturing defects, viscoelasticity and plasticity, and hysteresis effects. Residual physics networks learn from real-world data to augment a discrepant model and bring it closer to reality. Here, we present a residual physics method for modeling soft robots with large degrees of freedom. We train neural networks to learn a residual term -- the modeling error between simulated and physical systems. Concretely, the residual term is a force applied on the whole simulated mesh, while real position data is collected with only sparse motion markers. The physical prior of the analytical simulation provides a starting point for the residual network, and the combined model is more informed than if physics were learned tabula rasa. We demonstrate our method on 1) a silicone elastomeric beam and 2) a soft pneumatic arm with hard-to-model, anisotropic fiber reinforcements. Our method outperforms traditional system identification up to 60%. We show that residual physics need not be limited to low degrees of freedom but can effectively bridge the sim-to-real gap for high dimensional systems.\n",
            "Score: 15\n",
            "\n",
            "Document: 796|||| \n",
            "'arxiv_id': arXiv:2403.09915, \n",
            "'paper_link': https://arxiv.org/abs/2403.09915, \n",
            "'pdf_link': https://arxiv.org/pdf/2403.09915, \n",
            "Title: Robust Light-Weight Facial Affective Behavior Recognition with CLIP \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Human affective behavior analysis aims to delve into human expressions and behaviors to deepen our understanding of human emotions. Basic expression categories (EXPR) and Action Units (AUs) are two essential components in this analysis, which categorize emotions and break down facial movements into elemental units, respectively. Despite advancements, existing approaches in expression classification and AU detection often necessitate complex models and substantial computational resources, limiting their applicability in everyday settings. In this work, we introduce the first lightweight framework adept at efficiently tackling both expression classification and AU detection. This framework employs a frozen CLIP image encoder alongside a trainable multilayer perceptron (MLP), enhanced with Conditional Value at Risk (CVaR) for robustness and a loss landscape flattening strategy for improved generalization. Experimental results on the Aff-wild2 dataset demonstrate superior performance in comparison to the baseline while maintaining minimal computational demands, offering a practical solution for affective behavior analysis. The code is available at this https URL\n",
            "Score: 15\n",
            "\n",
            "Document: 921|||| \n",
            "'arxiv_id': arXiv:2407.11398, \n",
            "'paper_link': https://arxiv.org/abs/2407.11398, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.11398, \n",
            "Title: Animate3D: Animating Any 3D Model with Multi-view Video Diffusion \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Recent advances in 4D generation mainly focus on generating 4D content by distilling pre-trained text or single-view image-conditioned models. It is inconvenient for them to take advantage of various off-the-shelf 3D assets with multi-view attributes, and their results suffer from spatiotemporal inconsistency owing to the inherent ambiguity in the supervision signals. In this work, we present Animate3D, a novel framework for animating any static 3D model. The core idea is two-fold: 1) We propose a novel multi-view video diffusion model (MV-VDM) conditioned on multi-view renderings of the static 3D object, which is trained on our presented large-scale multi-view video dataset (MV-Video). 2) Based on MV-VDM, we introduce a framework combining reconstruction and 4D Score Distillation Sampling (4D-SDS) to leverage the multi-view video diffusion priors for animating 3D objects. Specifically, for MV-VDM, we design a new spatiotemporal attention module to enhance spatial and temporal consistency by integrating 3D and video diffusion models. Additionally, we leverage the static 3D model's multi-view renderings as conditions to preserve its identity. For animating 3D models, an effective two-stage pipeline is proposed: we first reconstruct motions directly from generated multi-view videos, followed by the introduced 4D-SDS to refine both appearance and motion. Benefiting from accurate motion learning, we could achieve straightforward mesh animation. Qualitative and quantitative experiments demonstrate that Animate3D significantly outperforms previous approaches. Data, code, and models will be open-released.\n",
            "Score: 15\n",
            "\n",
            "Document: 945|||| \n",
            "'arxiv_id': arXiv:2408.01688, \n",
            "'paper_link': https://arxiv.org/abs/2408.01688, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.01688, \n",
            "Title: SiamMo: Siamese Motion-Centric 3D Object Tracking \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Current 3D single object tracking methods primarily rely on the Siamese matching-based paradigm, which struggles with textureless and incomplete LiDAR point clouds. Conversely, the motion-centric paradigm avoids appearance matching, thus overcoming these issues. However, its complex multi-stage pipeline and the limited temporal modeling capability of a single-stream architecture constrain its potential. In this paper, we introduce SiamMo, a novel and simple Siamese motion-centric tracking approach. Unlike the traditional single-stream architecture, we employ Siamese feature extraction for motion-centric tracking. This decouples feature extraction from temporal fusion, significantly enhancing tracking performance. Additionally, we design a Spatio-Temporal Feature Aggregation module to integrate Siamese features at multiple scales, capturing motion information effectively. We also introduce a Box-aware Feature Encoding module to encode object size priors into motion estimation. SiamMo is a purely motion-centric tracker that eliminates the need for additional processes like segmentation and box refinement. Without whistles and bells, SiamMo not only surpasses state-of-the-art methods across multiple benchmarks but also demonstrates exceptional robustness in challenging scenarios. SiamMo sets a new record on the KITTI tracking benchmark with 90.1\\% precision while maintaining a high inference speed of 108 FPS. The code will be released at this https URL.\n",
            "Score: 15\n",
            "\n",
            "Document: 970|||| \n",
            "'arxiv_id': arXiv:2408.12548, \n",
            "'paper_link': https://arxiv.org/abs/2408.12548, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.12548, \n",
            "Title: Human-In-The-Loop Machine Learning for Safe and Ethical Autonomous Vehicles: Principles, Challenges, and Opportunities \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Rapid advances in Machine Learning (ML) have triggered new trends in Autonomous Vehicles (AVs). ML algorithms play a crucial role in interpreting sensor data, predicting potential hazards, and optimizing navigation strategies. However, achieving full autonomy in cluttered and complex situations, such as intricate intersections, diverse sceneries, varied trajectories, and complex missions, is still challenging, and the cost of data labeling remains a significant bottleneck. The adaptability and robustness of humans in complex scenarios motivate the inclusion of humans in the ML process, leveraging their creativity, ethical power, and emotional intelligence to improve ML effectiveness. The scientific community knows this approach as Human-In-The-Loop Machine Learning (HITL-ML). Towards safe and ethical autonomy, we present a review of HITL-ML for AVs, focusing on Curriculum Learning (CL), Human-In-The-Loop Reinforcement Learning (HITL-RL), Active Learning (AL), and ethical principles. In CL, human experts systematically train ML models by starting with simple tasks and gradually progressing to more difficult ones. HITL-RL significantly enhances the RL process by incorporating human input through techniques like reward shaping, action injection, and interactive learning. AL streamlines the annotation process by targeting specific instances that need to be labeled with human oversight, reducing the overall time and cost associated with training. Ethical principles must be embedded in AVs to align their behavior with societal values and norms. In addition, we provide insights and specify future research directions.\n",
            "Score: 15\n",
            "\n",
            "Document: 973|||| \n",
            "'arxiv_id': arXiv:2408.13440, \n",
            "'paper_link': https://arxiv.org/abs/2408.13440, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.13440, \n",
            "Title: Knowledge-Aware Conversation Derailment Forecasting Using Graph Convolutional Networks \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Online conversations are particularly susceptible to derailment, which can manifest itself in the form of toxic communication patterns including disrespectful comments and abuse. Forecasting conversation derailment predicts signs of derailment in advance enabling proactive moderation of conversations. State-of-the-art approaches to conversation derailment forecasting sequentially encode conversations and use graph neural networks to model dialogue user dynamics. However, existing graph models are not able to capture complex conversational characteristics such as context propagation and emotional shifts. The use of common sense knowledge enables a model to capture such characteristics, thus improving performance. Following this approach, here we derive commonsense statements from a knowledge base of dialogue contextual information to enrich a graph neural network classification architecture. We fuse the multi-source information on utterance into capsules, which are used by a transformer-based forecaster to predict conversation derailment. Our model captures conversation dynamics and context propagation, outperforming the state-of-the-art models on the CGA and CMV benchmark datasets\n",
            "Score: 15\n",
            "\n",
            "Document: 1009|||| \n",
            "'arxiv_id': arXiv:2409.02371, \n",
            "'paper_link': https://arxiv.org/abs/2409.02371, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.02371, \n",
            "Title: Unfolding Videos Dynamics via Taylor Expansion \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Taking inspiration from physical motion, we present a new self-supervised dynamics learning strategy for videos: Video Time-Differentiation for Instance Discrimination (ViDiDi). ViDiDi is a simple and data-efficient strategy, readily applicable to existing self-supervised video representation learning frameworks based on instance discrimination. At its core, ViDiDi observes different aspects of a video through various orders of temporal derivatives of its frame sequence. These derivatives, along with the original frames, support the Taylor series expansion of the underlying continuous dynamics at discrete times, where higher-order derivatives emphasize higher-order motion features. ViDiDi learns a single neural network that encodes a video and its temporal derivatives into consistent embeddings following a balanced alternating learning algorithm. By learning consistent representations for original frames and derivatives, the encoder is steered to emphasize motion features over static backgrounds and uncover the hidden dynamics in original frames. Hence, video representations are better separated by dynamic features. We integrate ViDiDi into existing instance discrimination frameworks (VICReg, BYOL, and SimCLR) for pretraining on UCF101 or Kinetics and test on standard benchmarks including video retrieval, action recognition, and action detection. The performances are enhanced by a significant margin without the need for large models or extensive datasets.\n",
            "Score: 15\n",
            "\n",
            "Document: 349|||| \n",
            "'arxiv_id': arXiv:2409.05292, \n",
            "'paper_link': https://arxiv.org/abs/2409.05292, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05292, \n",
            "Title: Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: The world is currently experiencing an outbreak of mpox, which has been declared a Public Health Emergency of International Concern by WHO. No prior work related to social media mining has focused on the development of a dataset of Instagram posts about the mpox outbreak. The work presented in this paper aims to address this research gap and makes two scientific contributions to this field. First, it presents a multilingual dataset of 60,127 Instagram posts about mpox, published between July 23, 2022, and September 5, 2024. The dataset, available at this https URL, contains Instagram posts about mpox in 52 languages. For each of these posts, the Post ID, Post Description, Date of publication, language, and translated version of the post (translation to English was performed using the Google Translate API) are presented as separate attributes in the dataset. After developing this dataset, sentiment analysis, hate speech detection, and anxiety or stress detection were performed. This process included classifying each post into (i) one of the sentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or neutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no anxiety/stress detected. These results are presented as separate attributes in the dataset. Second, this paper presents the results of performing sentiment analysis, hate speech analysis, and anxiety or stress analysis. The variation of the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and neutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and 50.64%, respectively. In terms of hate speech detection, 95.75% of the posts did not contain hate and the remaining 4.25% of the posts contained hate. Finally, 72.05% of the posts did not indicate any anxiety/stress, and the remaining 27.95% of the posts represented some form of anxiety/stress.\n",
            "Score: 5\n",
            "\n",
            "Document: 523|||| \n",
            "'arxiv_id': arXiv:2409.05703, \n",
            "'paper_link': https://arxiv.org/abs/2409.05703, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05703, \n",
            "Title: The Influence of Task and Group Disparities over Users' Attitudes Toward Using Large Language Models for Psychotherapy \n",
            "Subjects: Human-Computer Interaction (cs.HC) \n",
            "Abstract: The population suffering from mental health disorders has kept increasing in recent years. With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention. However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored. As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools. Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China. The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools. Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention. These findings can guide the design of future LLM-based psychotherapy services.\n",
            "Score: 5\n",
            "\n",
            "Document: 0|||| \n",
            "'arxiv_id': arXiv:2409.04446, \n",
            "'paper_link': https://arxiv.org/abs/2409.04446, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04446, \n",
            "Title: Hierarchical Optimal Dispatch of Active Distribution Networks Considering Flexibility Auxiliary Service of Multi-community Integrated Energy Systems \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: Active distribution networks (ADNs) are the main platforms for carrying large-scale distributed renewable energy and flexible resources, and multi-community integrated energy systems (MCIESs) may become important flexible resource supplies in ADNs owing to their multi-energy synergistic and complementary advantages. To fully utilize the flexible regulation potential of MCIESs for ADNs, a novel hierarchical stochastic dispatch approach for ADNs that considers flexibility auxiliary services of MCIESs is proposed. In this approach, a flexibility auxiliary service pricing strategy that combines adjustment cost and flexibility margin is established by evaluating the operational flexibility of MCIESs. In addition, considering renewable uncertainty, an MCIES-ADN flexibility interaction mechanism based on insufficient flexibility risk is designed to optimize their operation strategies and reduce the uncertainty risk. In the solution phase, an analytical target cascading theory-based distributed solving method is developed to realize decoupling and parallel solving of multiple stakeholders. The simulation results for a PG&E 69-node system with three CIESs demonstrate that the proposed approach not only improves MCIES revenue but also enhances ADN flexibility to consume renewable energy, which provides a fundamental way for efficient application of regional mutual aid.\n",
            "Score: 2\n",
            "\n",
            "Document: 7|||| \n",
            "'arxiv_id': arXiv:2409.04463, \n",
            "'paper_link': https://arxiv.org/abs/2409.04463, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04463, \n",
            "Title: Discovering Governing equations from Graph-Structured Data by Sparse Identification of Nonlinear Dynamical Systems \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: The combination of machine learning (ML) and sparsity-promoting techniques is enabling direct extraction of governing equations from data, revolutionizing computational modeling in diverse fields of science and engineering. The discovered dynamical models could be used to address challenges in climate science, neuroscience, ecology, finance, epidemiology, and beyond. However, most existing sparse identification methods for discovering dynamical systems treat the whole system as one without considering the interactions between subsystems. As a result, such models are not able to capture small changes in the emergent system behavior. To address this issue, we developed a new method called Sparse Identification of Nonlinear Dynamical Systems from Graph-structured data (SINDyG), which incorporates the network structure into sparse regression to identify model parameters that explain the underlying network dynamics. SINDyG discovers the governing equations of network dynamics while offering improvements in accuracy and model simplicity.\n",
            "Score: 2\n",
            "\n",
            "Document: 77|||| \n",
            "'arxiv_id': arXiv:2409.04670, \n",
            "'paper_link': https://arxiv.org/abs/2409.04670, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04670, \n",
            "Title: Multi-Conditioned Denoising Diffusion Probabilistic Model (mDDPM) for Medical Image Synthesis \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Medical imaging applications are highly specialized in terms of human anatomy, pathology, and imaging domains. Therefore, annotated training datasets for training deep learning applications in medical imaging not only need to be highly accurate but also diverse and large enough to encompass almost all plausible examples with respect to those specifications. We argue that achieving this goal can be facilitated through a controlled generation framework for synthetic images with annotations, requiring multiple conditional specifications as input to provide control. We employ a Denoising Diffusion Probabilistic Model (DDPM) to train a large-scale generative model in the lung CT domain and expand upon a classifier-free sampling strategy to showcase one such generation framework. We show that our approach can produce annotated lung CT images that can faithfully represent anatomy, convincingly fooling experts into perceiving them as real. Our experiments demonstrate that controlled generative frameworks of this nature can surpass nearly every state-of-the-art image generative model in achieving anatomical consistency in generated medical images when trained on comparable large medical datasets.\n",
            "Score: 2\n",
            "\n",
            "Document: 171|||| \n",
            "'arxiv_id': arXiv:2409.04868, \n",
            "'paper_link': https://arxiv.org/abs/2409.04868, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04868, \n",
            "Title: Moment Constraints and Phase Recovery for Multireference Alignment \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: Multireference alignment (MRA) refers to the problem of recovering a signal from noisy samples subject to random circular shifts. Expectation maximization (EM) and variational approaches use statistical modeling to achieve high accuracy at the cost of solving computationally expensive optimization problems. The method of moments, instead, achieves fast reconstructions by utilizing the power spectrum and bispectrum to determine the signal up to shift. Our approach combines the two philosophies by viewing the power spectrum as a manifold on which to constrain the signal. We then maximize the data likelihood function on this manifold with a gradient-based approach to estimate the true signal. Algorithmically, our method involves iterating between template alignment and projections onto the manifold. The method offers increased speed compared to EM and demonstrates improved accuracy over bispectrum-based methods.\n",
            "Score: 2\n",
            "\n",
            "Document: 203|||| \n",
            "'arxiv_id': arXiv:2409.04944, \n",
            "'paper_link': https://arxiv.org/abs/2409.04944, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04944, \n",
            "Title: Delay Balancing with Clock-Follow-Data: Optimizing Area Delay Trade-offs for Robust Rapid Single Flux Quantum Circuits \n",
            "Subjects: Emerging Technologies (cs.ET) \n",
            "Abstract: This paper proposes an algorithm for synthesis of clock-follow-data designs that provides robustness against timing violations for RSFQ circuits while maintaining high performance and minimizing area costs. Since superconducting logic gates must be clocked, managing data flow is a challenging problem that often requires the insertion of many path balancing D Flips (DFFs) to properly sequence data, leading to a substantial increase in area. To address this challenge, we present an algorithm to insert DFFs into clock-follow-data RSFQ circuits that partially balances the delays within the circuit to achieve a target throughput while minimizing area. Our algorithm can account for expected timing variations and, by adjusting the bias of the clock network and clock frequency, we can mitigate unexpected timing violations post-fabrication. Quantifying the benefits of our approach with a benchmark suite with nominal delays, our designs offer an average 1.48x improvement in area delay product (ADP) over high frequency full path balancing (FPB) designs and a 2.07x improvement in ADP over the state of the art robust circuits provided by state-of-the-art (SOTA) multi-phase clocking solutions.\n",
            "Score: 2\n",
            "\n",
            "Document: 407|||| \n",
            "'arxiv_id': arXiv:2409.05414, \n",
            "'paper_link': https://arxiv.org/abs/2409.05414, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05414, \n",
            "Title: CipherDM: Secure Three-Party Inference for Diffusion Model Sampling \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: Diffusion Models (DMs) achieve state-of-the-art synthesis results in image generation and have been applied to various fields. However, DMs sometimes seriously violate user privacy during usage, making the protection of privacy an urgent issue. Using traditional privacy computing schemes like Secure Multi-Party Computation (MPC) directly in DMs faces significant computation and communication challenges. To address these issues, we propose CipherDM, the first novel, versatile and universal framework applying MPC technology to DMs for secure sampling, which can be widely implemented on multiple DM based tasks. We thoroughly analyze sampling latency breakdown, find time-consuming parts and design corresponding secure MPC protocols for computing nonlinear activations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular architectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers. Compared to direct implementation on SPU, our approach improves running time by approximately 1.084\\times \\sim 2.328\\times, and reduces communication costs by approximately 1.212\\times \\sim 1.791\\times.\n",
            "Score: 2\n",
            "\n",
            "Document: 416|||| \n",
            "'arxiv_id': arXiv:2409.05435, \n",
            "'paper_link': https://arxiv.org/abs/2409.05435, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05435, \n",
            "Title: Semifactual Explanations for Reinforcement Learning \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Reinforcement Learning (RL) is a learning paradigm in which the agent learns from its environment through trial and error. Deep reinforcement learning (DRL) algorithms represent the agent's policies using neural networks, making their decisions difficult to interpret. Explaining the behaviour of DRL agents is necessary to advance user trust, increase engagement, and facilitate integration with real-life tasks. Semifactual explanations aim to explain an outcome by providing \"even if\" scenarios, such as \"even if the car were moving twice as slowly, it would still have to swerve to avoid crashing\". Semifactuals help users understand the effects of different factors on the outcome and support the optimisation of resources. While extensively studied in psychology and even utilised in supervised learning, semifactuals have not been used to explain the decisions of RL systems. In this work, we develop a first approach to generating semifactual explanations for RL agents. We start by defining five properties of desirable semifactual explanations in RL and then introducing SGRL-Rewind and SGRL-Advance, the first algorithms for generating semifactual explanations in RL. We evaluate the algorithms in two standard RL environments and find that they generate semifactuals that are easier to reach, represent the agent's policy better, and are more diverse compared to baselines. Lastly, we conduct and analyse a user study to assess the participant's perception of semifactual explanations of the agent's actions.\n",
            "Score: 2\n",
            "\n",
            "Document: 483|||| \n",
            "'arxiv_id': arXiv:2409.05592, \n",
            "'paper_link': https://arxiv.org/abs/2409.05592, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05592, \n",
            "Title: ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Predicting unknown drug-drug interactions (DDIs) is crucial for improving medication safety. Previous efforts in DDI prediction have typically focused on binary classification or predicting DDI categories, with the absence of explanatory insights that could enhance trust in these predictions. In this work, we propose to generate natural language explanations for DDI predictions, enabling the model to reveal the underlying pharmacodynamics and pharmacokinetics mechanisms simultaneously as making the prediction. To do this, we have collected DDI explanations from DDInter and DrugBank and developed various models for extensive experiments and analysis. Our models can provide accurate explanations for unknown DDIs between known drugs. This paper contributes new tools to the field of DDI prediction and lays a solid foundation for further research on generating explanations for DDI predictions.\n",
            "Score: 2\n",
            "\n",
            "Document: 586|||| \n",
            "'arxiv_id': arXiv:2409.04557, \n",
            "'paper_link': https://arxiv.org/abs/2409.04557, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04557, \n",
            "Title: DeepTTV: Deep Learning Prediction of Hidden Exoplanet From Transit Timing Variations \n",
            "Subjects: Earth and Planetary Astrophysics (astro-ph.EP) \n",
            "Abstract: Transit timing variation (TTV) provides rich information about the mass and orbital properties of exoplanets, which are often obtained by solving an inverse problem via Markov Chain Monte Carlo (MCMC). In this paper, we design a new data-driven approach, which potentially can be applied to problems that are hard to traditional MCMC methods, such as the case with only one planet transiting. Specifically, we use a deep learning approach to predict the parameters of non-transit companion for the single transit system with transit information (i.e., TTV, and Transit Duration Variation (TDV)) as input. Thanks to a newly constructed \\textit{Transformer}-based architecture that can extract long-range interactions from TTV sequential data, this previously difficult task can now be accomplished with high accuracy, with an overall fractional error of $\\sim$2\\% on mass and eccentricity.\n",
            "Score: 2\n",
            "\n",
            "Document: 589|||| \n",
            "'arxiv_id': arXiv:2409.04602, \n",
            "'paper_link': https://arxiv.org/abs/2409.04602, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04602, \n",
            "Title: Training quantum machine learning model on cloud without uploading the data \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: Based on the linearity of quantum unitary operations, we propose a method that runs the parameterized quantum circuits before encoding the input data. It enables a dataset owner to train machine learning models on quantum cloud computation platforms, without the risk of leaking the information of the data. It is also capable of encoding a huge number of data effectively at a later time using classical computations, thus saving the runtime on quantum computation devices. The trained quantum machine learning model can be run completely on classical computers, so that the dataset owner does not need to have any quantum hardware, nor even quantum simulators. Moreover, the method can mitigate the encoding bottom neck by reducing the required circuit depth from $O(2^{n})$ to $n/2$. These results manifest yet another advantage of quantum and quantum-inspired machine learning models over existing classical neural networks, and broaden the approaches for data security.\n",
            "Score: 2\n",
            "\n",
            "Document: 605|||| \n",
            "'arxiv_id': arXiv:2409.04935, \n",
            "'paper_link': https://arxiv.org/abs/2409.04935, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.04935, \n",
            "Title: Anomaly Detection for Real-World Cyber-Physical Security using Quantum Hybrid Support Vector Machines \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: Cyber-physical control systems are critical infrastructures designed around highly responsive feedback loops that are measured and manipulated by hundreds of sensors and controllers. Anomalous data, such as from cyber-attacks, greatly risk the safety of the infrastructure and human operators. With recent advances in the quantum computing paradigm, the application of quantum in anomaly detection can greatly improve identification of cyber-attacks in physical sensor data. In this paper, we explore the use of strong pre-processing methods and a quantum-hybrid Support Vector Machine (SVM) that takes advantage of fidelity in parameterized quantum circuits to efficiently and effectively flatten extremely high dimensional data. Our results show an F-1 Score of 0.86 and accuracy of 87% on the HAI CPS dataset using an 8-qubit, 16-feature quantum kernel, performing equally to existing work and 14% better than its classical counterpart.\n",
            "Score: 2\n",
            "\n",
            "Document: 634|||| \n",
            "'arxiv_id': arXiv:2409.05475, \n",
            "'paper_link': https://arxiv.org/abs/2409.05475, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05475, \n",
            "Title: Reinforcement Learning for Variational Quantum Circuits Design \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: Variational Quantum Algorithms have emerged as promising tools for solving optimization problems on quantum computers. These algorithms leverage a parametric quantum circuit called ansatz, where its parameters are adjusted by a classical optimizer with the goal of optimizing a certain cost function. However, a significant challenge lies in designing effective circuits for addressing specific problems. In this study, we leverage the powerful and flexible Reinforcement Learning paradigm to train an agent capable of autonomously generating quantum circuits that can be used as ansatzes in variational algorithms to solve optimization problems. The agent is trained on diverse problem instances, including Maximum Cut, Maximum Clique and Minimum Vertex Cover, built from different graph topologies and sizes. Our analysis of the circuits generated by the agent and the corresponding solutions shows that the proposed method is able to generate effective ansatzes. While our goal is not to propose any new specific ansatz, we observe how the agent has discovered a novel family of ansatzes effective for Maximum Cut problems, which we call $R_{yz}$-connected. We study the characteristics of one of these ansatzes by comparing it against state-of-the-art quantum algorithms across instances of varying graph topologies, sizes, and problem types. Our results indicate that the $R_{yz}$-connected circuit achieves high approximation ratios for Maximum Cut problems, further validating our proposed agent. In conclusion, our study highlights the potential of Reinforcement Learning techniques in assisting researchers to design effective quantum circuits which could have applications in a wide number of tasks.\n",
            "Score: 2\n",
            "\n",
            "Document: 652|||| \n",
            "'arxiv_id': arXiv:2409.05759, \n",
            "'paper_link': https://arxiv.org/abs/2409.05759, \n",
            "'pdf_link': https://arxiv.org/pdf/2409.05759, \n",
            "Title: A Novel Finite Fractional Fourier Transform and its Quantum Circuit Implementation on Qudits \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: We present a new number theoretic definition of discrete fractional Fourier transform (DFrFT) . In this approach the DFrFT is defined as the $N \\times N$ dimensional unitary representation of the generator of the arithmetic rotational group $SO_{2}[\\mathbb{Z}_N]$, which is the finite set of $\\bmod N$ integer, $2\\times 2$ matrices acting on the points of the discrete toroidal phase space lattice $\\mathbb{Z}_N \\times \\mathbb{Z}_N$, preserving the euclidean distance $\\bmod N$.\n",
            "We construct explicitly, using techniques of the Finite Quantum Mechanics (FQM), the $p^n$ dimensional unitary matrix representation of the group $SO_{2}[\\mathbb{Z}_{p^n}]$ and especially we work out in detail the one which corresponds to the generator. This is our definition of the arithmetic fractional Fourier transform (AFrFT).\n",
            "Following this definition, we proceed to the construction of efficient quantum circuits for the AFrFT, on sets of $n$ $p$-dimensional qudits with $p$ a prime integer, by introducing novel quantum subcircuits for diagonal operators with quadratic phases as well as new quantum subcircuits for multipliers by a constant. The quantum subcircuits that we introduce provide a set capable to construct quantum circuits for any element of a more general group, the group of Linear Canonical Transformations (LCT), $SL_{2}[\\mathbb{Z}_N]$ of the toroidal phase space lattice. As a byproduct, extensions of the diagonal and multiplier quantum circuits for both the qudit and qubit case are given, which are useful alone in various applications. Also, we analyze the depth, width and gate complexity of the efficient AFrFT quantum circuit and we estimate its gate complexity which is of the order $O(n^2)$, its depth which is of the order $O(n)$ with depth $n$, while at the same time it has a structure permitting local interactions between the qudits.\n",
            "Score: 2\n",
            "\n",
            "Document: 829|||| \n",
            "'arxiv_id': arXiv:2404.14648, \n",
            "'paper_link': https://arxiv.org/abs/2404.14648, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.14648, \n",
            "Title: Pseudorandom Permutations from Random Reversible Circuits \n",
            "Subjects: Computational Complexity (cs.CC) \n",
            "Abstract: We study pseudorandomness properties of permutations on $\\{0,1\\}^n$ computed by random circuits made from reversible $3$-bit gates (permutations on $\\{0,1\\}^3$). Our main result is that a random circuit of depth $n \\cdot \\tilde{O}(k^2)$, with each layer consisting of $\\approx n/3$ random gates in a fixed nearest-neighbor architecture, yields almost $k$-wise independent permutations. The main technical component is showing that the Markov chain on $k$-tuples of $n$-bit strings induced by a single random $3$-bit nearest-neighbor gate has spectral gap at least $1/n \\cdot \\tilde{O}(k)$. This improves on the original work of Gowers [Gowers96], who showed a gap of $1/\\mathrm{poly}(n,k)$ for one random gate (with non-neighboring inputs); and, on subsequent work [HMMR05,BH08] improving the gap to $\\Omega(1/n^2k)$ in the same setting.\n",
            "From the perspective of cryptography, our result can be seen as a particularly simple/practical block cipher construction that gives provable statistical security against attackers with access to $k$~input-output pairs within few rounds. We also show that the Luby--Rackoff construction of pseudorandom permutations from pseudorandom functions can be implemented with reversible circuits. From this, we make progress on the complexity of the Minimum Reversible Circuit Size Problem (MRCSP), showing that block ciphers of fixed polynomial size are computationally secure against arbitrary polynomial-time adversaries, assuming the existence of one-way functions (OWFs).\n",
            "Score: 2\n",
            "\n",
            "Document: 890|||| \n",
            "'arxiv_id': arXiv:2406.12383, \n",
            "'paper_link': https://arxiv.org/abs/2406.12383, \n",
            "'pdf_link': https://arxiv.org/pdf/2406.12383, \n",
            "Title: Biased Pareto Optimization for Subset Selection with Dynamic Cost Constraints \n",
            "Subjects: Data Structures and Algorithms (cs.DS) \n",
            "Abstract: Subset selection with cost constraints aims to select a subset from a ground set to maximize a monotone objective function without exceeding a given budget, which has various applications such as influence maximization and maximum coverage. In real-world scenarios, the budget, representing available resources, may change over time, which requires that algorithms must adapt quickly to new budgets. However, in this dynamic environment, previous algorithms either lack theoretical guarantees or require a long running time. The state-of-the-art algorithm, POMC, is a Pareto optimization approach designed for static problems, lacking consideration for dynamic problems. In this paper, we propose BPODC, enhancing POMC with biased selection and warm-up strategies tailored for dynamic environments. We focus on the ability of BPODC to leverage existing computational results while adapting to budget changes. We prove that BPODC can maintain the best known $(\\alpha_f/2)(1-e^{-\\alpha_f})$-approximation guarantee when the budget changes. Experiments on influence maximization and maximum coverage show that BPODC adapts more effectively and rapidly to budget changes, with a running time that is less than that of the static greedy algorithm.\n",
            "Score: 2\n",
            "\n",
            "Document: 894|||| \n",
            "'arxiv_id': arXiv:2406.15695, \n",
            "'paper_link': https://arxiv.org/abs/2406.15695, \n",
            "'pdf_link': https://arxiv.org/pdf/2406.15695, \n",
            "Title: SS-GEN: A Social Story Generation Framework with Large Language Models \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Children with Autism Spectrum Disorder (ASD) often misunderstand social situations and struggle to participate in daily routines. Social Stories are traditionally crafted by psychology experts under strict constraints to address these challenges but are costly and limited in diversity. As Large Language Models (LLMs) advance, there's an opportunity to develop more automated, affordable, and accessible methods to generate Social Stories in real-time with broad coverage. However, adapting LLMs to meet the unique and strict constraints of Social Stories is a challenging issue. To this end, we propose \\textbf{SS-GEN}, a \\textbf{S}ocial \\textbf{S}tory \\textbf{GEN}eration framework with LLMs. Firstly, we develop a constraint-driven sophisticated strategy named \\textbf{\\textsc{StarSow}} to hierarchically prompt LLMs to generate Social Stories at scale, followed by rigorous human filtering to build a high-quality dataset. Additionally, we introduce \\textbf{quality assessment criteria} to evaluate the effectiveness of these generated stories. Considering that powerful closed-source large models require very complex instructions and expensive API fees, we finally fine-tune smaller language models with our curated high-quality dataset, achieving comparable results at lower costs and with simpler instruction and deployment. This work marks a significant step in leveraging AI to personalize Social Stories cost-effectively for autistic children at scale, which we hope can encourage future research. The prompt, code and data will release in the \\texttt{Technical Appendix} and \\texttt{Code \\& Data Appendix} at \\url{this https URL}.\n",
            "Score: 2\n",
            "\n",
            "Document: 954|||| \n",
            "'arxiv_id': arXiv:2408.08320, \n",
            "'paper_link': https://arxiv.org/abs/2408.08320, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.08320, \n",
            "Title: Hardware-Algorithm Re-engineering of Retinal Circuit for Intelligent Object Motion Segmentation \n",
            "Subjects: Neural and Evolutionary Computing (cs.NE) \n",
            "Abstract: Recent advances in retinal neuroscience have fueled various hardware and algorithmic efforts to develop retina-inspired solutions for computer vision tasks. In this work, we focus on a fundamental visual feature within the mammalian retina, Object Motion Sensitivity (OMS). Using DVS data from EV-IMO dataset, we analyze the performance of an algorithmic implementation of OMS circuitry for motion segmentation in presence of ego-motion. This holistic analysis considers the underlying constraints arising from the hardware circuit implementation. We present novel CMOS circuits that implement OMS functionality inside image sensors, while providing run-time re-configurability for key algorithmic parameters. In-sensor technologies for dynamical environment adaptation are crucial for ensuring high system performance. Finally, we verify the functionality and re-configurability of the proposed CMOS circuit designs through Cadence simulations in 180nm technology. In summary, the presented work lays foundation for hardware-algorithm re-engineering of known biological circuits to suit application needs.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Timer"
      ],
      "metadata": {
        "id": "BBVy06WenHk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end_time_whole_single_task = datetime.now()\n",
        "duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "print(f\"Duration to run -> {duration_time}\")"
      ],
      "metadata": {
        "id": "cCnRP_8anHbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae0de68-ea5e-4119-cdbf-81098538732e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run -> 0_min__11.4_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See files\n",
        "!ls\n",
        "print(len(all_results_json_list))"
      ],
      "metadata": {
        "id": "B7IHdEI-v2jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51732039-06fa-47c4-fab0-69709bc98209"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Agents for Software Engineering_articles2024-09-10__122810515419.html'\n",
            "'Agents for Software Engineering_articles_2024-09-10__122810515419.json'\n",
            " all_arxiv_article_dicts_2024-09-10__122808986433.json\n",
            " all_arxiv_results_2024-09-10__122809096144.json\n",
            "'collective behavior_articles2024-09-10__122810876538.html'\n",
            "'collective behavior_articles_2024-09-10__122810876538.json'\n",
            " disinformation_articles2024-09-10__122810027229.html\n",
            " disinformation_articles_2024-09-10__122810027229.json\n",
            "'distance measure_articles2024-09-10__122809699531.html'\n",
            "'distance measure_articles_2024-09-10__122809699531.json'\n",
            " e-Learners_articles2024-09-10__122810689394.html\n",
            " e-Learners_articles_2024-09-10__122810689394.json\n",
            "'Manifold Approximation_articles2024-09-10__122809458737.html'\n",
            "'Manifold Approximation_articles_2024-09-10__122809458737.json'\n",
            "'mental health_articles2024-09-10__122811265632.html'\n",
            "'mental health_articles_2024-09-10__122811265632.json'\n",
            "'multiple agents_articles2024-09-10__122810329177.html'\n",
            "'multiple agents_articles_2024-09-10__122810329177.json'\n",
            "'Retrieval-Augmented Systems_articles2024-09-10__122811041260.html'\n",
            "'Retrieval-Augmented Systems_articles_2024-09-10__122811041260.json'\n",
            " sample_data\n",
            " Speech-LLM_articles2024-09-10__122810180636.html\n",
            " Speech-LLM_articles_2024-09-10__122810180636.json\n",
            " survey_articles2024-09-10__122809861244.html\n",
            " survey_articles_2024-09-10__122809861244.json\n",
            "495\n"
          ]
        }
      ]
    }
  ]
}