{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ba77c8fe-bdc2-4e48-91f2-a942055118eb",
        "SOMfhOwlr-zu",
        "YepU-A4Fr_J3",
        "WPnLaV3fpCkv",
        "MaYRyhUgm1ol"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba77c8fe-bdc2-4e48-91f2-a942055118eb"
      },
      "source": [
        "# Arxiv Explorer Tools - minimal weighted match\n",
        "- Fast: ~5-10 sec to run vs. 5-10 min for embedding or TFIDF versions.\n",
        "- multi-topic: use as many pre-set seaches as you want\n",
        "- extracts articles on topics of interest from the too-many-to-look-through daily pages of articles that come out each day.\n",
        "- saves results to json (for automation later) and html (for easy reading and linking)\n",
        "- minimal weighted match uses a list of phrases and an integer weight for each\n",
        "- arxiv reading uses 'beautiful soup'\n",
        "\n",
        "### Setup & Install:\n",
        "- have python installed and use an python env\n",
        "- use a jupyter notebook or script, etc.\n",
        "- for specialty topics you can create extensive weighted search profiles.\n",
        "\n",
        "### See:\n",
        "- https://medium.com/@GeoffreyGordonAshbrook/search-with-non-generative-ai-d0a3cc77164b\n",
        "- https://github.com/lineality/arxiv_explorer_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11e7a29-5a13-4c90-b3a3-f4409a9013b2"
      },
      "source": [
        "\n",
        "- https://pypi.org/project/beautifulsoup4/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdea8fa-7a5d-4d32-a88b-1b1f8619e1b3"
      },
      "source": [
        "requirements.txt ->\n",
        "```\n",
        "scikit-learn\n",
        "scipy\n",
        "numpy\n",
        "beautifulsoup4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4c5c9be-949c-4c72-b2cf-b26df5316aa2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "def duration_min_sec(start_time, end_time):\n",
        "\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    duration_seconds = duration.total_seconds()\n",
        "\n",
        "    minutes = int(duration_seconds // 60)\n",
        "    seconds = duration_seconds % 60\n",
        "    time_message = f\"{minutes}_min__{seconds:.1f}_sec\"\n",
        "\n",
        "    return time_message\n",
        "\n",
        "# # start_time_whole_single_task = datetime.now()\n",
        "# end_time_whole_single_task = datetime.now()\n",
        "# duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "# print(f\"Duration to run -> {duration_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minimal weighted matching code"
      ],
      "metadata": {
        "id": "SOMfhOwlr-zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "# from collections import Counter\n",
        "\n",
        "\n",
        "# And an even more simplistic basic key word search (with optional weights)\n",
        "\n",
        "import re\n",
        "\n",
        "def rank_documents_on_weighted_matches(documents, keyword_weights):\n",
        "    \"\"\"\n",
        "    Ranks documents based on the presence of weighted keywords-phrases.\n",
        "    comparison looks at text without:\n",
        "    - captialization\n",
        "    - spaces\n",
        "    - newlines\n",
        "    - special symbols\n",
        "\n",
        "    Parameters:\n",
        "    documents (list of str): The list of documents to be ranked.\n",
        "    keyword_weights (list of tuple): A list of tuples, where the first element is the keyword and the\n",
        "    second element is the corresponding weight.\n",
        "\n",
        "    Returns:\n",
        "    list of (str, float): A list of tuples, where the first element is the document and the\n",
        "    second element is the ranking score.\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    string cleaning steps:\n",
        "    - lower\n",
        "    - strip extra spaces\n",
        "    - remove symbols\n",
        "    - remove newlines\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ranked_documents = []\n",
        "\n",
        "    for document in documents:\n",
        "        score = 0\n",
        "        # Make the document lowercase and strip all symbols, spaces, and newline characters\n",
        "        match_this_cleaned_document = re.sub(r'[^\\w\\s]', '', document.lower()).replace('\\n', '').replace(' ','')\n",
        "        # print(match_this_cleaned_document)\n",
        "        for keyword, weight in keyword_weights:\n",
        "\n",
        "            # Make the keyword lowercase and strip all symbols, spaces, and newline characters\n",
        "            match_this_cleaned_keyword = re.sub(r'[^\\w\\s]', '', keyword.lower()).replace('\\n', '').replace(' ','')\n",
        "            # print(match_this_cleaned_keyword)\n",
        "            # Check if the keyword-phrase is in the document\n",
        "            if match_this_cleaned_keyword in match_this_cleaned_document:\n",
        "                # If the keyword-phrase is in the document, add its weight to the score\n",
        "                score += weight\n",
        "\n",
        "        ranked_documents.append((document, score))\n",
        "\n",
        "    # Sort the documents by their ranking scores in descending order\n",
        "    ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return ranked_documents\n",
        "\n",
        "\n",
        "# ################\n",
        "# # Example usage\n",
        "# ################\n",
        "# corpus = [\n",
        "#     \"This is the first document about machine learning.\",\n",
        "#     \"The second document discusses data analysis and visualization.\",\n",
        "#     \"The third document focuses on natural language processing.\",\n",
        "#     \"The fourth document talks about deep learning and neural networks.\",\n",
        "#     \"\"\"to test line breaks\n",
        "#     Emotion mining\n",
        "#      data\n",
        "#     analysis\n",
        "#     Keywords: emotion mining, sentiment analysis, natural disasters, psychology, technological disasters\"\"\",\n",
        "# ]\n",
        "\n",
        "# keyword_weights = [(\"machine learning\", 3), (\"data analysis\", 2), (\"natural language processing\", 4), (\"deep learning\", 5), (\"neural networks\", 6)]\n",
        "\n",
        "# ranked_documents = rank_documents_on_weighted_matches(corpus, keyword_weights)\n",
        "\n",
        "# for document, score in ranked_documents:\n",
        "#     print(f\"Document: {document}\\nScore: {score}\\n\")\n"
      ],
      "metadata": {
        "id": "bqy_ZPvpr-6o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arxiv Explorerer\n"
      ],
      "metadata": {
        "id": "YepU-A4Fr_J3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "19bd0781-5480-4ec0-9709-07330763fd06"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Arxiv Explorerer\n",
        "###################\n",
        "\n",
        "# step 1: embed the search-phrase\n",
        "# step 2: embed each text\n",
        "# step 3: get scores\n",
        "# step 4: evaluates if score is succss or fail\n",
        "# step 5: if success: do stuff with text\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "start_time_whole_single_task = datetime.now()\n",
        "\n",
        "\n",
        "# ##########################################\n",
        "# # Make comparison phrase and vectorize it\n",
        "# ##########################################\n",
        "# comparison_phrase = \"computer vision resolution enhancement\"\n",
        "# # comparison_phrase = \"cyber security\"\n",
        "# # comparison_phrase = \"natural language processing\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hght1gb699Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Article Corpus"
      ],
      "metadata": {
        "id": "ItIQ_onG-IXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_segment_time = datetime.now()\n",
        "\n",
        "#####################\n",
        "# Get Article Corpus\n",
        "#####################\n",
        "\n",
        "# List to hold all article data\n",
        "article_data = []\n",
        "\n",
        "# # Make a request to the website\n",
        "r = requests.get('https://arxiv.org/list/cs/new')\n",
        "\n",
        "url = \"https://arxiv.org/list/cs/new\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# # Find all the articles\n",
        "articles = soup.find_all('dt')\n",
        "\n",
        "# # Find all the titles\n",
        "articles_title = soup.find_all('div', {'class': 'list-title mathjax'})\n",
        "\n",
        "# Find all the subject on the page\n",
        "articles_subject = soup.find_all('dd')\n",
        "\n",
        "\n",
        "###############\n",
        "# make corpus\n",
        "###############\n",
        "\n",
        "corpus = []\n",
        "report_list = []\n",
        "article_dicts = []\n",
        "\n",
        "for this_index, article in enumerate(articles):\n",
        "\n",
        "    ################################################\n",
        "    # Extract each field of data about each article\n",
        "    ################################################\n",
        "\n",
        "    # Extract the title\n",
        "    title = articles_title[this_index].text.split('Title:')[1].strip()\n",
        "\n",
        "    # Extract the subjects\n",
        "    subjects = articles_subject[this_index].find('span', {'class': 'primary-subject'}).text\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "\n",
        "    abstract_p = article.find_next_sibling('dd').find('p', {'class': 'mathjax'})\n",
        "\n",
        "    # Extract the abstract\n",
        "    if abstract_p:\n",
        "        abstract = abstract_p.text.strip()\n",
        "    else:\n",
        "        abstract = \"\"\n",
        "\n",
        "    pdf_link_segment = article.find('a', {'title': 'Download PDF'})['href']\n",
        "\n",
        "    arxiv_id = article.find('a', {'title': 'Abstract'}).text.strip()\n",
        "    pdf_link = f\"https://arxiv.org{pdf_link_segment}\"\n",
        "    paper_link = f\"https://arxiv.org/abs/{arxiv_id[6:]}\"\n",
        "\n",
        "    # extracted_article_string = title + \" \" + abstract + \" \" + str(subjects)\n",
        "\n",
        "    # assemble corpus\n",
        "    article_characters = f\"{this_index}|||| \"\n",
        "\n",
        "    article_characters += f\"\\n'arxiv_id': {arxiv_id}, \"\n",
        "    article_characters += f\"\\n'paper_link': {paper_link}, \"\n",
        "    article_characters += f\"\\n'pdf_link': {pdf_link}, \"\n",
        "\n",
        "    article_characters += \"\\nTitle: \" + title + \" \"\n",
        "    article_characters += \"\\nSubjects: \" + subjects + \" \"\n",
        "    article_characters += \"\\nAbstract: \" + abstract\n",
        "\n",
        "    ##################################\n",
        "    # Make Bundles (sharing an index)\n",
        "    ##################################\n",
        "\n",
        "    # # add to corpus: just the meaningful text\n",
        "    # corpus.append(extracted_article_string)\n",
        "\n",
        "    # add to simple report_list: includes link and article ID info\n",
        "    report_list.append(article_characters)\n",
        "\n",
        "    # Append the data to the list\n",
        "    article_dicts.append({\n",
        "        'title': title,\n",
        "        'abstract': abstract,\n",
        "        'paper_link': paper_link,\n",
        "        'pdf_link': pdf_link,\n",
        "        'subjects': subjects,\n",
        "        'arxiv_id': arxiv_id,\n",
        "        'article_sequence_index': this_index,\n",
        "    })\n",
        "\n",
        "    # using this because only basic search works\n",
        "    corpus = report_list\n",
        "\n",
        "\n",
        "# # Segment Timer\n",
        "# start_segment_time = datetime.now()\n",
        "end_segment_time = datetime.now()\n",
        "duration_time = duration_min_sec(start_segment_time, end_segment_time)\n",
        "print(f\"Duration to run segment -> {duration_time}\")"
      ],
      "metadata": {
        "id": "e8FPqO0u-IXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bc61dd-69bd-4a81-b8eb-c024e84bb082"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run segment -> 0_min__5.3_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspection (size of corpus)\n",
        "len(corpus)"
      ],
      "metadata": {
        "id": "bve1wNfDBC-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c91a020-2194-416b-fd12-ce991c488a8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "665"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# print and save: code"
      ],
      "metadata": {
        "id": "WPnLaV3fpCkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "########################################\n",
        "# Filter, Save, & Print the Raw Results\n",
        "########################################\n",
        "\n",
        "\n",
        "def result_counter(ranked_documents):\n",
        "    \"\"\"\n",
        "    count non-zero scored results\n",
        "    \"\"\"\n",
        "\n",
        "    result_count = 0\n",
        "\n",
        "    for this_doc in ranked_documents:\n",
        "        score = this_doc[1]\n",
        "\n",
        "        if score != 0:\n",
        "            result_count += 1\n",
        "\n",
        "    return result_count\n",
        "\n",
        "\n",
        "\n",
        "def score_filtered_result_counter(ranked_documents, score_floor=0):\n",
        "    \"\"\"\n",
        "    count non-zero scored results that are greater than or equal to score_floor\n",
        "    \"\"\"\n",
        "\n",
        "    result_count = 0\n",
        "\n",
        "    for this_doc in ranked_documents:\n",
        "        score = this_doc[1]\n",
        "\n",
        "        if score != 0 and score >= score_floor:\n",
        "            result_count += 1\n",
        "\n",
        "    return result_count\n",
        "\n",
        "\n",
        "def print_and_save(ranked_documents, top_n, name_of_set, score_floor=5):\n",
        "    # Posix UTC Seconds\n",
        "    # make readable time\n",
        "    # from datetime import datetime\n",
        "    date_time = datetime.now()\n",
        "    clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    results_json_list = []\n",
        "\n",
        "    for document, score in ranked_documents:\n",
        "\n",
        "        if score >= score_floor:\n",
        "\n",
        "            blurb = f\"Document: {document}\\nScore: {score}\\n\"\n",
        "\n",
        "            print(blurb)\n",
        "\n",
        "        this_index = int(document.split('||||')[0])\n",
        "\n",
        "        data_dict = article_dicts[this_index]\n",
        "\n",
        "        results_json_list.append(data_dict)\n",
        "\n",
        "        counter += 1\n",
        "        if counter >= top_n:\n",
        "            break\n",
        "\n",
        "\n",
        "    #############\n",
        "    # Write Data\n",
        "    #############\n",
        "\n",
        "    # Save the data to a JSON file\n",
        "    with open(f'{name_of_set}_articles_{clean_timestamp}.json', 'w') as f:\n",
        "        json.dump(results_json_list, f)\n",
        "\n",
        "    # Create an HTML file\n",
        "    html = '<html><body>'\n",
        "    for article in results_json_list:\n",
        "        html += f'<h2><a href=\"{article[\"paper_link\"]}\">{article[\"title\"]}</a></h2>'\n",
        "        html += f'<p>{article[\"abstract\"]}</p>'\n",
        "        html += f'<p>Subjects: {str(article[\"subjects\"])}</p>'\n",
        "\n",
        "        html += f'<a href=\"{article[\"paper_link\"]}\">{article[\"paper_link\"]}</a>'\n",
        "        html += f'<p>paper link: {str(article[\"paper_link\"])}</p>'\n",
        "\n",
        "        html += f'<a href=\"{article[\"pdf_link\"]}\">{article[\"pdf_link\"]}</a>'\n",
        "        html += f'<p>pdf link: {str(article[\"pdf_link\"])}</p>'\n",
        "\n",
        "        html += f'<p>arxiv id: {str(article[\"arxiv_id\"])}</p>'\n",
        "        html += f'<p>article_sequence_index id: {str(article[\"article_sequence_index\"])}</p>'\n",
        "\n",
        "    html += '</body></html>'\n",
        "\n",
        "\n",
        "    # Save the HTML to a file\n",
        "    with open(f'{name_of_set}_articles{clean_timestamp}.html', 'w') as f:\n",
        "        f.write(html)\n",
        "\n",
        "\n",
        "def match_print_save(list_of_lists_of_weights, top_n, score_floor):\n",
        "    date_time = datetime.now()\n",
        "    clean_timestamp = date_time.strftime('%Y-%m-%d__%H%M%S%f')\n",
        "\n",
        "    counter = 0\n",
        "    for keyword_weights in list_of_lists_of_weights:\n",
        "\n",
        "        ranked_documents = rank_documents_on_weighted_matches(corpus, keyword_weights)\n",
        "\n",
        "        # user first list item as name of set\n",
        "        name_of_set = list_of_lists_of_weights[counter][0][0]\n",
        "\n",
        "        result_quantity = result_counter(ranked_documents)\n",
        "\n",
        "        score_floor_filtered_quantity = score_filtered_result_counter(ranked_documents, score_floor)\n",
        "\n",
        "        this_max_number = top_n\n",
        "\n",
        "        if top_n > result_quantity:\n",
        "            this_max_number = result_quantity\n",
        "\n",
        "        print(f\"\\n\\nSet Name: {name_of_set}\")\n",
        "        print(f\"Total Matches in Set: {result_quantity}\")\n",
        "        print(f\"Matches Above Score-Floor in Set: {score_floor_filtered_quantity}\")\n",
        "        print(clean_timestamp)\n",
        "\n",
        "        print(f\"\\nShowing {score_floor_filtered_quantity} in top-{this_max_number} out of {result_quantity} total results.     -> {score_floor_filtered_quantity} of {this_max_number}/{result_quantity}\")\n",
        "        print(f\"(Ceiling set at {top_n} (top_n) filtered results.)    -> {top_n}\")\n",
        "        print(f\"(Minimum-included-score, 'Score-Floor' set at {score_floor}) -> {score_floor}\\n\\n\")\n",
        "\n",
        "        print_and_save(ranked_documents, top_n, name_of_set, score_floor)\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "peVzbe-Di2xH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set of searches\n",
        "(optional)"
      ],
      "metadata": {
        "id": "MaYRyhUgm1ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ########\n",
        "# # Batch\n",
        "# ########\n",
        "\n",
        "# # example multi-list\n",
        "\n",
        "# list_of_lists_of_weights = [\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"computer vision\", 3),\n",
        "#         (\"resolution\", 2),\n",
        "#         # (\"natural language processing\", 4),\n",
        "#         # (\"deep learning\", 5),\n",
        "#         (\"neural networks\", 6),\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"distance measure\", 10),\n",
        "#         (\"similarity measure\", 10),\n",
        "#         (\"vector distance\", 10),\n",
        "#         (\"distance metric\", 10),\n",
        "#         (\"similarity metric\", 10),\n",
        "#         (\"dimension reduction\", 10),\n",
        "\n",
        "\n",
        "#         (\"similarity\", 1),\n",
        "#         (\"distance\", 1),\n",
        "#         (\"metric\", 1),\n",
        "\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     # (\"cognitive science\", 2),  # much too broad...\n",
        "#     [\n",
        "#         (\"mental health\", 5),\n",
        "#         (\"psychological health\", 5),\n",
        "#         (\"psycholog\", 2),  # stem vs. lemma\n",
        "\n",
        "\n",
        "#         (\"mental health care\", 3),\n",
        "#         (\"neuroscience\", 2),\n",
        "#         (\"psychological assessment\", 2),\n",
        "#         (\"personality assessment\", 2),\n",
        "#         (\"personality inference\", 2),\n",
        "#         (\"personality traits\", 2),\n",
        "#         (\"personality dimensions\", 2),\n",
        "#         (\"emotion\", 15),\n",
        "#         (\"sports psychology\", 15),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "\n",
        "\n",
        "\n",
        "#         # disease terms\n",
        "#         (\"depression\", 5),\n",
        "#         (\"anxiety\", 5),\n",
        "#         (\"mental disorders\", 2),\n",
        "#         (\"social anxiety disorder\", 4),\n",
        "#         (\"mental illness\", 2),\n",
        "#         (\"Major Depressive Disorder\", 2),\n",
        "#         (\"MDD\", 2),\n",
        "#         (\"psychological stressors\", 2),\n",
        "#         (\"cognitive impairment\", 2),\n",
        "#         (\"mci\", 2),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "#         # (\"\", 2),\n",
        "\n",
        "#         ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     [\n",
        "#         (\"benchmark\", 5),\n",
        "#         (\"model evaluation\", 5),\n",
        "#         (\"test\", 2),\n",
        "#         (\"measure\", 2),\n",
        "#     ],\n",
        "\n",
        "\n",
        "#     # # keyword_weights =\n",
        "#     [\n",
        "#         (\"training set\", 5),\n",
        "#         (\"synthetic\", 2),\n",
        "#         (\"generate\", 2),\n",
        "#         (\"measure\", 2),\n",
        "#     ],\n",
        "\n",
        "#     # keyword_weights =\n",
        "#     [\n",
        "#         (\"graph\", 5),\n",
        "#         (\"graph generation\", 8),\n",
        "#         (\"subgraph\", 2),\n",
        "#         (\"hierarchical graph\", 2),\n",
        "#         (\"embedding\", 2),\n",
        "#         (\"knowledge graph\", 2),\n",
        "\n",
        "#         (\"graph neural networks\", 2),\n",
        "#         (\"graph representation\", 2),\n",
        "#         (\"node\", 2),\n",
        "#          ## collisions: cryptograph, geograph,\n",
        "#     ],\n",
        "\n",
        "# ]\n",
        "\n",
        "# top_n = 45\n",
        "# score_floor = 3\n",
        "# match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "id": "Sn35USTbt3MM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find top-n articles: use keyword/weights"
      ],
      "metadata": {
        "id": "bt_SeRE_l345"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 3\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"Manifold Approximation\", 10),\n",
        "        (\"UMAP\", 10),\n",
        "        (\"Uniform Manifold Approximation and Projection\", 10),\n",
        "        (\"Manifold hypothesis\", 10),\n",
        "        (\"dimensionality reduction\", 10),\n",
        "        (\"dimension reduction\", 10),\n",
        "        (\"dimension reduction technique\", 10),\n",
        "\n",
        "        (\"stress\", 1),\n",
        "        (\"Manifold\", 1),\n",
        "        (\"lower-dimensional\", 1),\n",
        "        (\"visualiz\", 1),\n",
        "        (\"projection\", 1),\n",
        "        (\"project\", 1),\n",
        "        (\"dimensionality\", 1),\n",
        "        (\"reduction\", 1),\n",
        "    ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLOy8bu3elSO",
        "outputId": "02d93c29-5959-44cc-ab64-5274e157daff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: Manifold Approximation\n",
            "Total Matches in Set: 89\n",
            "Matches Above Score-Floor in Set: 7\n",
            "2024-08-22__131152373406\n",
            "\n",
            "Showing 7 in top-45 out of 89 total results.     -> 7 of 45/89\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 3) -> 3\n",
            "\n",
            "\n",
            "Document: 448|||| \n",
            "'arxiv_id': arXiv:2311.07883, \n",
            "'paper_link': https://arxiv.org/abs/2311.07883, \n",
            "'pdf_link': https://arxiv.org/pdf/2311.07883, \n",
            "Title: A priori analysis of a tensor ROM for parameter dependent parabolic problems \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: A space-time-parameters structure of parametric parabolic PDEs motivates the application of tensor methods to define reduced order models (ROMs). Within a tensor-based ROM framework, the matrix SVD - a traditional dimension reduction technique - yields to a low-rank tensor decomposition (LRTD). Such tensor extension of the Galerkin proper orthogonal decomposition ROMs (POD-ROMs) benefits both the practical efficiency of the ROM and its amenability for rigorous error analysis when applied to parametric PDEs. The paper addresses the error analysis of the Galerkin LRTD-ROM for an abstract linear parabolic problem that depends on multiple physical parameters. An error estimate for the LRTD-ROM solution is proved, which is uniform with respect to problem parameters and extends to parameter values not in a sampling/training set. The estimate is given in terms of discretization and sampling mesh properties, and LRTD accuracy. The estimate depends on the local smoothness rather than on the Kolmogorov n-widths of the parameterized manifold of solutions. Theoretical results are illustrated with several numerical experiments.\n",
            "Score: 22\n",
            "\n",
            "Document: 477|||| \n",
            "'arxiv_id': arXiv:2402.11404, \n",
            "'paper_link': https://arxiv.org/abs/2402.11404, \n",
            "'pdf_link': https://arxiv.org/pdf/2402.11404, \n",
            "Title: Evaluating the Stability of Deep Learning Latent Feature Spaces \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: High-dimensional datasets present substantial challenges in statistical modeling across various disciplines, necessitating effective dimensionality reduction methods. Deep learning approaches, notable for their capacity to distill essential features from complex data, facilitate modeling, visualization, and compression through reduced dimensionality latent feature spaces, have wide applications from bioinformatics to earth sciences. This study introduces a novel workflow to evaluate the stability of these latent spaces, ensuring consistency and reliability in subsequent analyses. Stability, defined as the invariance of latent spaces to minor data, training realizations, and parameter perturbations, is crucial yet often overlooked.\n",
            "Our proposed methodology delineates three stability types, sample, structural, and inferential, within latent spaces, and introduces a suite of metrics for comprehensive evaluation. We implement this workflow across 500 autoencoder realizations and three datasets, encompassing both synthetic and real-world scenarios to explain latent space dynamics. Employing k-means clustering and the modified Jonker-Volgenant algorithm for class alignment, alongside anisotropy metrics and convex hull analysis, we introduce adjusted stress and Jaccard dissimilarity as novel stability indicators.\n",
            "Our findings highlight inherent instabilities in latent feature spaces and demonstrate the workflow's efficacy in quantifying and interpreting these instabilities. This work advances the understanding of latent feature spaces, promoting improved model interpretability and quality control for more informed decision-making for diverse analytical workflows that leverage deep learning.\n",
            "Score: 14\n",
            "\n",
            "Document: 26|||| \n",
            "'arxiv_id': arXiv:2408.11145, \n",
            "'paper_link': https://arxiv.org/abs/2408.11145, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11145, \n",
            "Title: Total Uncertainty Quantification in Inverse PDE Solutions Obtained with Reduced-Order Deep Learning Surrogate Models \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: We propose an approximate Bayesian method for quantifying the total uncertainty in inverse PDE solutions obtained with machine learning surrogate models, including operator learning models. The proposed method accounts for uncertainty in the observations and PDE and surrogate models. First, we use the surrogate model to formulate a minimization problem in the reduced space for the maximum a posteriori (MAP) inverse solution. Then, we randomize the MAP objective function and obtain samples of the posterior distribution by minimizing different realizations of the objective function. We test the proposed framework by comparing it with the iterative ensemble smoother and deep ensembling methods for a non-linear diffusion equation with an unknown space-dependent diffusion coefficient. Among other problems, this equation describes groundwater flow in an unconfined aquifer. Depending on the training dataset and ensemble sizes, the proposed method provides similar or more descriptive posteriors of the parameters and states than the iterative ensemble smoother method. Deep ensembling underestimates uncertainty and provides less informative posteriors than the other two methods.\n",
            "Score: 10\n",
            "\n",
            "Document: 34|||| \n",
            "'arxiv_id': arXiv:2408.11165, \n",
            "'paper_link': https://arxiv.org/abs/2408.11165, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11165, \n",
            "Title: Multi-User SR-LDPC Codes \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: This article introduces a novel non-orthogonal multiple access (NOMA) scheme for coordinated uplink channels. The scheme builds on the recently proposed sparse-regression low-density parity-check (SR-LDPC) code, and extends the underlying notions to scenarios with many concurrent users. The resulting scheme, called Multi-User SR-LDPC (MU-SR-LDPC) coding, consists of each user transmitting its own SR-LDPC codeword using a unique sensing matrix in conjunction with a characteristic outer LDPC code. To recover the sent information, the decoder jointly processes the received signals using a low-complexity and highly-parallelizable AMP-BP algorithm. At finite blocklengths (FBL), MU-SR-LDPC codes are shown to achieve a target BER at a higher spectral efficiency than baseline orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) schemes with similar computational complexity. Furthermore, MU-SR-LDPC codes are shown to match the performance of maximum a posteriori (MAP) decoding in certain regimes. For certain blocklengths and a sufficiently high number of users, MU-SR-LDPC codes may achieve a higher spectral efficiency than the approximate FBL capacity of the effective single-user Gaussian channel seen by each user in a comparable OMA scheme. Results are supported by numerical simulations.\n",
            "Score: 10\n",
            "\n",
            "Document: 350|||| \n",
            "'arxiv_id': arXiv:2408.11792, \n",
            "'paper_link': https://arxiv.org/abs/2408.11792, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11792, \n",
            "Title: Optical ISAC: Fundamental Performance Limits and Transceiver Design \n",
            "Subjects: Information Theory (cs.IT) \n",
            "Abstract: This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point (P2P) system with single-input single-output for communication and single-input multiple-output for sensing (SISO-SIMO-C/S) within an integrated sensing and communication (ISAC) framework. We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors. Our results show these estimators converge to the Bayesian Cramer-Rao bound (BCRB) as sensing antennas increase. We also demonstrate that the achievable rate-CRB (AR-CRB) serves as an outer bound (OB) for the optimal C-D region. To optimize input distribution across the Pareto boundary of the C-D region, we propose two algorithms: an iterative Blahut-Arimoto algorithm (BAA)-type method and a memory-efficient closed-form (CF) approach, including a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions. Additionally, we extend and modify the Deterministic-Random Tradeoff (DRT) to this optical ISAC context.\n",
            "Score: 10\n",
            "\n",
            "Document: 432|||| \n",
            "'arxiv_id': arXiv:2308.03139, \n",
            "'paper_link': https://arxiv.org/abs/2308.03139, \n",
            "'pdf_link': https://arxiv.org/pdf/2308.03139, \n",
            "Title: Unfolded proximal neural networks for robust image Gaussian denoising \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: A common approach to solve inverse imaging problems relies on finding a maximum a posteriori (MAP) estimate of the original unknown image, by solving a minimization problem. In thiscontext, iterative proximal algorithms are widely used, enabling to handle non-smooth functions and linear operators. Recently, these algorithms have been paired with deep learning strategies, to further improve the estimate quality. In particular, proximal neural networks (PNNs) have been introduced, obtained by unrolling a proximal algorithm as for finding a MAP estimate, but over a fixed number of iterations, with learned linear operators and parameters. As PNNs are based on optimization theory, they are very flexible, and can be adapted to any image restoration task, as soon as a proximal algorithm can solve it. They further have much lighter architectures than traditional networks. In this article we propose a unified framework to build PNNs for the Gaussian denoising task, based on both the dual-FB and the primal-dual Chambolle-Pock algorithms. We further show that accelerated inertial versions of these algorithms enable skip connections in the associated NN layers. We propose different learning strategies for our PNN framework, and investigate their robustness (Lipschitz property) and denoising efficiency. Finally, we assess the robustness of our PNNs when plugged in a forward-backward algorithm for an image deblurring problem.\n",
            "Score: 10\n",
            "\n",
            "Document: 279|||| \n",
            "'arxiv_id': arXiv:2408.11612, \n",
            "'paper_link': https://arxiv.org/abs/2408.11612, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11612, \n",
            "Title: Slicing of Radial Functions: a Dimension Walk in the Fourier Space \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: Computations in high-dimensional spaces can often be realized only approximately, using a certain number of projections onto lower dimensional subspaces or sampling from distributions. In this paper, we are interested in pairs of real-valued functions $(F,f)$ on $[0,\\infty)$ that are related by the projection/slicing formula $F (\\| x \\|) = \\mathbb E_{\\xi} \\big[ f \\big(|\\langle x,\\xi \\rangle| \\big) \\big]$ for $x\\in\\mathbb R^d$, where the expectation value is taken over uniformly distributed direction in $\\mathbb R^d$. While it is known that $F$ can be obtained from $f$ by an Abel-like integral formula, we construct conversely $f$ from given $F$ using their Fourier transforms. First, we consider the relation between $F$ and $f$ for radial functions $F(\\| \\cdot\\| )$ that are Fourier transforms of $L^1$ functions. Besides $d$- and one-dimensional Fourier transforms, it relies on a rotation operator, an averaging operator and a multiplication operator to manage the walk from $d$ to one dimension in the Fourier space. Then, we generalize the results to tempered distributions, where we are mainly interested in radial regular tempered distributions. Based on Bochner's theorem, this includes positive definite functions $F(\\| \\cdot\\| )$.\n",
            "Score: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 3\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"distance measure\", 10),\n",
        "        (\"similarity measure\", 10),\n",
        "        (\"vector distance\", 10),\n",
        "        (\"distance metric\", 10),\n",
        "        (\"similarity metric\", 10),\n",
        "        (\"dimension reduction\", 10),\n",
        "\n",
        "        (\"similarity\", 1),\n",
        "        (\"distance\", 1),\n",
        "        (\"metric\", 1),\n",
        "    ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HOGJ_6VhZtO",
        "outputId": "edf7a061-f284-4ff6-b239-39f08c2eab7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: distance measure\n",
            "Total Matches in Set: 114\n",
            "Matches Above Score-Floor in Set: 3\n",
            "2024-08-22__131152745807\n",
            "\n",
            "Showing 3 in top-45 out of 114 total results.     -> 3 of 45/114\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 3) -> 3\n",
            "\n",
            "\n",
            "Document: 448|||| \n",
            "'arxiv_id': arXiv:2311.07883, \n",
            "'paper_link': https://arxiv.org/abs/2311.07883, \n",
            "'pdf_link': https://arxiv.org/pdf/2311.07883, \n",
            "Title: A priori analysis of a tensor ROM for parameter dependent parabolic problems \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: A space-time-parameters structure of parametric parabolic PDEs motivates the application of tensor methods to define reduced order models (ROMs). Within a tensor-based ROM framework, the matrix SVD - a traditional dimension reduction technique - yields to a low-rank tensor decomposition (LRTD). Such tensor extension of the Galerkin proper orthogonal decomposition ROMs (POD-ROMs) benefits both the practical efficiency of the ROM and its amenability for rigorous error analysis when applied to parametric PDEs. The paper addresses the error analysis of the Galerkin LRTD-ROM for an abstract linear parabolic problem that depends on multiple physical parameters. An error estimate for the LRTD-ROM solution is proved, which is uniform with respect to problem parameters and extends to parameter values not in a sampling/training set. The estimate is given in terms of discretization and sampling mesh properties, and LRTD accuracy. The estimate depends on the local smoothness rather than on the Kolmogorov n-widths of the parameterized manifold of solutions. Theoretical results are illustrated with several numerical experiments.\n",
            "Score: 11\n",
            "\n",
            "Document: 249|||| \n",
            "'arxiv_id': arXiv:2408.11558, \n",
            "'paper_link': https://arxiv.org/abs/2408.11558, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11558, \n",
            "Title: GSTran: Joint Geometric and Semantic Coherence for Point Cloud Segmentation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Learning meaningful local and global information remains a challenge in point cloud segmentation tasks. When utilizing local information, prior studies indiscriminately aggregates neighbor information from different classes to update query points, potentially compromising the distinctive feature of query points. In parallel, inaccurate modeling of long-distance contextual dependencies when utilizing global information can also impact model performance. To address these issues, we propose GSTran, a novel transformer network tailored for the segmentation task. The proposed network mainly consists of two principal components: a local geometric transformer and a global semantic transformer. In the local geometric transformer module, we explicitly calculate the geometric disparity within the local region. This enables amplifying the affinity with geometrically similar neighbor points while suppressing the association with other neighbors. In the global semantic transformer module, we design a multi-head voting strategy. This strategy evaluates semantic similarity across the entire spatial range, facilitating the precise capture of contextual dependencies. Experiments on ShapeNetPart and S3DIS benchmarks demonstrate the effectiveness of the proposed method, showing its superiority over other algorithms. The code is available at this https URL.\n",
            "Score: 3\n",
            "\n",
            "Document: 663|||| \n",
            "'arxiv_id': arXiv:2408.09731, \n",
            "'paper_link': https://arxiv.org/abs/2408.09731, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.09731, \n",
            "Title: Reconstruct Spine CT from Biplanar X-Rays via Diffusion Learning \n",
            "Subjects: Image and Video Processing (eess.IV) \n",
            "Abstract: Intraoperative CT imaging serves as a crucial resource for surgical guidance; however, it may not always be readily accessible or practical to implement. In scenarios where CT imaging is not an option, reconstructing CT scans from X-rays can offer a viable alternative. In this paper, we introduce an innovative method for 3D CT reconstruction utilizing biplanar X-rays. Distinct from previous research that relies on conventional image generation techniques, our approach leverages a conditional diffusion process to tackle the task of reconstruction. More precisely, we employ a diffusion-based probabilistic model trained to produce 3D CT images based on orthogonal biplanar X-rays. To improve the structural integrity of the reconstructed images, we incorporate a novel projection loss function. Experimental results validate that our proposed method surpasses existing state-of-the-art benchmarks in both visual image quality and multiple evaluative metrics. Specifically, our technique achieves a higher Structural Similarity Index (SSIM) of 0.83, a relative increase of 10\\%, and a lower FrÃ©chet Inception Distance (FID) of 83.43, which represents a relative decrease of 25\\%.\n",
            "Score: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"survey\", 1),\n",
        "        (\"election\", 1),\n",
        "        (\"voting\", 1),\n",
        "        (\"poll\", 1),\n",
        "        (\"vote\", 1),\n",
        "        (\"candidate\", 1),\n",
        "\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Po_ipgoynfr",
        "outputId": "4232f44f-9d3b-479f-cff1-bad897413a88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: survey\n",
            "Total Matches in Set: 54\n",
            "Matches Above Score-Floor in Set: 6\n",
            "2024-08-22__131153115107\n",
            "\n",
            "Showing 6 in top-45 out of 54 total results.     -> 6 of 45/54\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 332|||| \n",
            "'arxiv_id': arXiv:2408.11755, \n",
            "'paper_link': https://arxiv.org/abs/2408.11755, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11755, \n",
            "Title: On the Distortion of Committee Election with 1-Euclidean Preferences and Few Distance Queries \n",
            "Subjects: Computer Science and Game Theory (cs.GT) \n",
            "Abstract: We consider committee election of $k \\geq 3$ (out of $m \\geq k+1$) candidates, where the voters and the candidates are associated with locations on the real line. Each voter's cardinal preferences over candidates correspond to her distance to the candidate locations, and each voter's cardinal preferences over committees is defined as her distance to the nearest candidate elected in the committee. We consider a setting where the true distances and the locations are unknown. We can nevertheless have access to degraded information which consists of an order of candidates for each voter. We investigate the best possible distortion (a worst-case performance criterion) wrt. the social cost achieved by deterministic committee election rules based on ordinal preferences submitted by $n$ voters and few additional distance queries. We show that for any $k \\geq 3$, the best possible distortion of any deterministic algorithm that uses at most $k-3$ distance queries cannot be bounded by any function of $n$, $m$ and $k$. We present deterministic algorithms for $k$-committee election with distortion of $O(n)$ with $O(k)$ distance queries and $O(1)$ with $O(k \\log n)$ distance queries.\n",
            "Score: 3\n",
            "\n",
            "Document: 47|||| \n",
            "'arxiv_id': arXiv:2408.11195, \n",
            "'paper_link': https://arxiv.org/abs/2408.11195, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11195, \n",
            "Title: Proposal of an Electronic Auditing System Applied to the Brazilian Electronic Voting Machine \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: A new system, called SELA -- Auditing Electronic System, has been developed to be applied to the Brazilian Electronic Voting Machine. The SELA was designed to use open hardware and software, making it widely known by society. The security of the auditing process is guaranteed by the application of a Fingerprint Algorithm, a Hash Function. This system is robust and requires minimal modifications to the Electronic Voting Machine. In this paper, SELA is described, and its use during the election process is analyzed. A comparison between SELA and the use of thermal printers as a secondary voting record system is also presented. The authors recommend a pilot implementation of SELA for the 2002 Brazilian Elections.\n",
            "Score: 2\n",
            "\n",
            "Document: 97|||| \n",
            "'arxiv_id': arXiv:2408.11297, \n",
            "'paper_link': https://arxiv.org/abs/2408.11297, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11297, \n",
            "Title: Making Large Vision Language Models to be Good Few-shot Learners \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Few-shot classification (FSC) is a fundamental yet challenging task in computer vision that involves recognizing novel classes from limited data. While previous methods have focused on enhancing visual features or incorporating additional modalities, Large Vision Language Models (LVLMs) offer a promising alternative due to their rich knowledge and strong visual perception. However, LVLMs risk learning specific response formats rather than effectively extracting useful information from support data in FSC tasks. In this paper, we investigate LVLMs' performance in FSC and identify key issues such as insufficient learning and the presence of severe positional biases. To tackle the above challenges, we adopt the meta-learning strategy to teach models \"learn to learn\". By constructing a rich set of meta-tasks for instruction fine-tuning, LVLMs enhance the ability to extract information from few-shot support data for classification. Additionally, we further boost LVLM's few-shot learning capabilities through label augmentation and candidate selection in the fine-tuning and inference stage, respectively. Label augmentation is implemented via a character perturbation strategy to ensure the model focuses on support information. Candidate selection leverages attribute descriptions to filter out unreliable candidates and simplify the task. Extensive experiments demonstrate that our approach achieves superior performance on both general and fine-grained datasets. Furthermore, our candidate selection strategy has been proven beneficial for training-free LVLMs.\n",
            "Score: 2\n",
            "\n",
            "Document: 524|||| \n",
            "'arxiv_id': arXiv:2405.05688, \n",
            "'paper_link': https://arxiv.org/abs/2405.05688, \n",
            "'pdf_link': https://arxiv.org/pdf/2405.05688, \n",
            "Title: Evaluating Dialect Robustness of Language Models via Conversation Understanding \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: With an evergrowing number of LLMs reporting superlative performance for English, their ability to perform equitably for different dialects of English ($\\textit{i.e.}$, dialect robustness) needs to be ascertained. Specifically, we use English language (US English or Indian English) conversations between humans who play the word-guessing game of 'taboo'. We formulate two evaluative tasks: target word prediction (TWP) ($\\textit{i.e.}$, predict the masked target word in a conversation) and target word selection (TWS) ($\\textit{i.e.}$, select the most likely masked target word in a conversation, from among a set of candidate words). Extending MD3, an existing dialectic dataset of taboo-playing conversations, we introduce M-MD3, a target-word-masked version of MD3 with the en-US and en-IN subsets. We create two subsets: en-MV (where en-US is transformed to include dialectal information) and en-TR (where dialectal information is removed from en-IN). We evaluate one open-source (Llama3) and two closed-source (GPT-4/3.5) LLMs. LLMs perform significantly better for US English than Indian English for both TWP and TWS tasks, for all settings, exhibiting marginalisation against the Indian dialect of English. While GPT-based models perform the best, the comparatively smaller models work more equitably after fine-tuning. Our error analysis shows that the LLMs can understand the dialect better after fine-tuning using dialectal data. Our evaluation methodology exhibits a novel way to examine attributes of language models using pre-existing dialogue datasets.\n",
            "Score: 2\n",
            "\n",
            "Document: 578|||| \n",
            "'arxiv_id': arXiv:2407.16160, \n",
            "'paper_link': https://arxiv.org/abs/2407.16160, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.16160, \n",
            "Title: UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using complex mechanisms and extensive model tuning methods to model the multimodal interaction on specific datasets. However, these methods overcomplicate the MEL task and overlook the visual semantic information, which makes them costly and hard to scale. Moreover, these methods can not solve the issues like textual ambiguity, redundancy, and noisy images, which severely degrade their performance. Fortunately, the advent of Large Language Models (LLMs) with robust capabilities in text understanding and reasoning, particularly Multimodal Large Language Models (MLLMs) that can process multimodal inputs, provides new insights into addressing this challenge. However, how to design a universally applicable LLMs-based MEL approach remains a pressing challenge. To this end, we propose UniMEL, a unified framework which establishes a new paradigm to process multimodal entity linking tasks using LLMs. In this framework, we employ LLMs to augment the representation of mentions and entities individually by integrating textual and visual information and refining textual information. Subsequently, we employ the embedding-based method for retrieving and re-ranking candidate entities. Then, with only ~0.26% of the model parameters fine-tuned, LLMs can make the final selection from the candidate entities. Extensive experiments on three public benchmark datasets demonstrate that our solution achieves state-of-the-art performance, and ablation studies verify the effectiveness of all modules. Our code is available at this https URL.\n",
            "Score: 2\n",
            "\n",
            "Document: 586|||| \n",
            "'arxiv_id': arXiv:2407.20371, \n",
            "'paper_link': https://arxiv.org/abs/2407.20371, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.20371, \n",
            "Title: Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval \n",
            "Subjects: Computers and Society (cs.CY) \n",
            "Abstract: Artificial intelligence (AI) hiring tools have revolutionized resume screening, and large language models (LLMs) have the potential to do the same. However, given the biases which are embedded within LLMs, it is unclear whether they can be used in this scenario without disadvantaging groups based on their protected attributes. In this work, we investigate the possibilities of using LLMs in a resume screening setting via a document retrieval framework that simulates job candidate selection. Using that framework, we then perform a resume audit study to determine whether a selection of Massive Text Embedding (MTE) models are biased in resume screening scenarios. We simulate this for nine occupations, using a collection of over 500 publicly available resumes and 500 job descriptions. We find that the MTEs are biased, significantly favoring White-associated names in 85.1\\% of cases and female-associated names in only 11.1\\% of cases, with a minority of cases showing no statistically significant differences. Further analyses show that Black males are disadvantaged in up to 100\\% of cases, replicating real-world patterns of bias in employment settings, and validate three hypotheses of intersectionality. We also find an impact of document length as well as the corpus frequency of names in the selection of resumes. These findings have implications for widely used AI tools that are automating employment, fairness, and tech policy.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\" collective behavior\", 1),\n",
        "        (\"collective\", 1),\n",
        "        (\"coordination\", 1),\n",
        "        (\"oganization\", 1),\n",
        "        (\"behavior\", 1),\n",
        "        (\"ants\", 1),\n",
        "        (\"insects\", 1),\n",
        "        (\"worms\", 1),\n",
        "        (\"swarm\", 1),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zPAIaz5xzmJ",
        "outputId": "2b79a28b-5e2f-4998-d342-48bcf76e164e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name:  collective behavior\n",
            "Total Matches in Set: 100\n",
            "Matches Above Score-Floor in Set: 9\n",
            "2024-08-22__131153411115\n",
            "\n",
            "Showing 9 in top-45 out of 100 total results.     -> 9 of 45/100\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 58|||| \n",
            "'arxiv_id': arXiv:2408.11212, \n",
            "'paper_link': https://arxiv.org/abs/2408.11212, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11212, \n",
            "Title: How many autonomous vehicles are required to stabilize traffic flow? \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: Collective behavior of human-driven vehicles (HVs) results in the well-known stop-and-go waves potentially leading to higher fuel consumption and emissions. This letter investigates the stabilization of traffic flow via a minimum number of autonomous vehicles (AVs) subject to constraints on the control parameters. The unconstrained scenario has been well-studied in recent studies. The main motivation to investigate the constrained scenario is that, in reality, lower and upper bounds exist on the control parameters. For the constrained scenario, we optimally find the minimum number of required AVs (via computing the optimal lower bound on the AV penetration rate) to stabilize traffic flow for a given number of HVs. As an immediate consequence, we conclude that for a given number of AVs, the number of HVs in the stabilized traffic flow cannot be arbitrarily large in the constrained scenario unlike the unconstrained scenario studied in the literature. Using nonlinear optimization techniques, we systematically propose a procedure to compute the optimal lower bound on the AV penetration rate. Finally, we validate the theoretical results via numerical simulations. Numerical simulations suggest that by enlarging the constraint intervals, a smaller optimal lower bound on the AV penetration rate is attainable. However, it leads to a slower transient response due to a dominant pole closer to the origin.\n",
            "Score: 3\n",
            "\n",
            "Document: 31|||| \n",
            "'arxiv_id': arXiv:2408.11155, \n",
            "'paper_link': https://arxiv.org/abs/2408.11155, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11155, \n",
            "Title: Range-based Multi-Robot Integrity Monitoring Against Cyberattacks and Faults: An Anchor-Free Approach \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: Coordination of multi-robot systems (MRSs) relies on efficient sensing and reliable communication among the robots. However, the sensors and communication channels of these robots are often vulnerable to cyberattacks and faults, which can disrupt their individual behavior and the overall objective of the MRS. In this work, we present a multi-robot integrity monitoring framework that utilizes inter-robot range measurements to (i) detect the presence of cyberattacks or faults affecting the MRS, (ii) identify the affected robot(s), and (iii) reconstruct the resulting localization error of these robot(s). The proposed iterative algorithm leverages sequential convex programming and alternating direction of multipliers method to enable real-time and distributed implementation. Our approach is validated using numerical simulations and demonstrated using PX4-SiTL in Gazebo on an MRS, where certain agents deviate from their desired position due to a GNSS spoofing attack. Furthermore, we demonstrate the scalability and interoperability of our algorithm through mixed-reality experiments by forming a heterogeneous MRS comprising real Crazyflie UAVs and virtual PX4-SiTL UAVs working in tandem.\n",
            "Score: 2\n",
            "\n",
            "Document: 325|||| \n",
            "'arxiv_id': arXiv:2408.11746, \n",
            "'paper_link': https://arxiv.org/abs/2408.11746, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11746, \n",
            "Title: Mixed Sparsity Training: Achieving 4$\\times$ FLOP Reduction for Transformer Pretraining \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75\\%$ of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\\times$ without compromising performance.\n",
            "Score: 2\n",
            "\n",
            "Document: 331|||| \n",
            "'arxiv_id': arXiv:2408.11752, \n",
            "'paper_link': https://arxiv.org/abs/2408.11752, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11752, \n",
            "Title: Consensus over Clustered Networks using Intermittent and Asynchronous Output Feedback \n",
            "Subjects: Systems and Control (eess.SY) \n",
            "Abstract: In recent years, multi-agent teaming has garnered considerable interest since complex objectives, such as intelligence, surveillance, and reconnaissance, can be divided into multiple cluster-level sub-tasks and assigned to a cluster of agents with the appropriate functionality. Yet, coordination and information dissemination between clusters may be necessary to accomplish a desired objective. Distributed consensus protocols provide a mechanism for spreading information within clustered networks, allowing agents and clusters to make decisions without requiring direct access to the state of the ensemble. Hence, we propose a strategy for achieving system-wide consensus in the states of identical linear time-invariant systems coupled by an undirected graph whose directed sub-graphs are available only at sporadic times. Within this work, the agents of the network are organized into pairwise disjoint clusters, which induce sub-graphs of the undirected parent graph. Some cluster sub-graph pairs are linked by an inter-cluster sub-graph, where the union of all cluster and inter-cluster sub-graphs yields the undirected parent graph. Each agent utilizes a distributed consensus protocol with components that are updated intermittently and asynchronously with respect to other agents. The closed-loop ensemble dynamics is modeled as a hybrid system, and a Lyapunov-based stability analysis yields sufficient conditions for rendering the agreement subspace (consensus set) globally exponentially stable. Furthermore, an input-to-state stability argument demonstrates the consensus set is robust to a class of perturbations. A numerical simulation considering both nominal and perturbed scenarios is provided for validation purposes.\n",
            "Score: 2\n",
            "\n",
            "Document: 412|||| \n",
            "'arxiv_id': arXiv:2211.10317, \n",
            "'paper_link': https://arxiv.org/abs/2211.10317, \n",
            "'pdf_link': https://arxiv.org/pdf/2211.10317, \n",
            "Title: $\\alpha$-Rank-Collections: Analyzing Expected Strategic Behavior with Uncertain Utilities \n",
            "Subjects: Computer Science and Game Theory (cs.GT) \n",
            "Abstract: Game theory relies heavily on the availability of cardinal utility functions, but in fields such as matching markets, only ordinal preferences are typically elicited. The literature focuses on mechanisms with simple dominant strategies, but many real-world applications lack dominant strategies, making the intensity of preferences between outcomes important for determining strategies. Even though precise information about cardinal utilities is not available, some data about the likelihood of utility functions is often accessible. We propose to use Bayesian games to formalize uncertainty about the decision-makers' utilities by viewing them as a collection of normal-form games. Instead of searching for the Bayes-Nash equilibrium, we study how uncertainty in utilities is reflected in uncertainty of strategic play. To do this, we introduce a novel solution concept called $\\alpha$-Rank-collections, which extends $\\alpha$-Rank to Bayesian games. This allows us to analyze strategic play in, for example, non-strategyproof matching markets, for which appropriate solution concepts are currently lacking. $\\alpha$-Rank-collections characterize the expected probability of encountering a certain strategy profile under replicator dynamics in the long run, rather than predicting a specific equilibrium strategy profile. We experimentally evaluate $\\alpha$-Rank-collections using instances of the Boston mechanism, finding that our solution concept provides more nuanced predictions compared to Bayes-Nash equilibria. Additionally, we prove that $\\alpha$-Rank-collections are invariant to positive affine transformations, a standard property for a solution concept, and are efficient to approximate.\n",
            "Score: 2\n",
            "\n",
            "Document: 439|||| \n",
            "'arxiv_id': arXiv:2310.00280, \n",
            "'paper_link': https://arxiv.org/abs/2310.00280, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.00280, \n",
            "Title: Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Large Language Models (LLMs) are evolving at an unprecedented pace and have exhibited considerable capability in the realm of natural language processing (NLP) with world knowledge. Benefiting from ultra-large-scale training corpora, a single LLM can manage typical NLP tasks competently. However, its performance in executing reasoning tasks is still confined by the limitations of its internal representations. To push this boundary further, we introduce Corex in this paper, a suite of novel general-purpose strategies that transform LLMs into autonomous agents pioneering multi-model collaborations for complex task-solving. Inspired by human behaviors, Corex is constituted by diverse collaboration paradigms including Debate, Review, and Retrieve modes, which collectively work towards enhancing the factuality, faithfulness, and reliability of the reasoning process. These paradigms foster task-agnostic approaches that enable LLMs to ''think outside the box,'' thereby overcoming hallucinations and providing better solutions. Through extensive experiments across four different types of reasoning tasks, we demonstrate that orchestrating multiple LLMs to work in concert yields substantially better performance compared to existing methods. Further results and in-depth analysis demonstrate the cost-effectiveness of our method, facilitating collaboration among different LLMs and promoting annotation efficiency.\n",
            "Score: 2\n",
            "\n",
            "Document: 513|||| \n",
            "'arxiv_id': arXiv:2404.14649, \n",
            "'paper_link': https://arxiv.org/abs/2404.14649, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.14649, \n",
            "Title: Bi-CL: A Reinforcement Learning Framework for Robots Coordination Through Bi-level Optimization \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: In multi-robot systems, achieving coordinated missions remains a significant challenge due to the coupled nature of coordination behaviors and the lack of global information for individual robots. To mitigate these challenges, this paper introduces a novel approach, Bi-level Coordination Learning (Bi-CL), that leverages a bi-level optimization structure within a centralized training and decentralized execution paradigm. Our bi-level reformulation decomposes the original problem into a reinforcement learning level with reduced action space, and an imitation learning level that gains demonstrations from a global optimizer. Both levels contribute to improved learning efficiency and scalability. We note that robots' incomplete information leads to mismatches between the two levels of learning models. To address this, Bi-CL further integrates an alignment penalty mechanism, aiming to minimize the discrepancy between the two levels without degrading their training efficiency. We introduce a running example to conceptualize the problem formulation and apply Bi-CL to two variations of this example: route-based and graph-based scenarios. Simulation results demonstrate that Bi-CL can learn more efficiently and achieve comparable performance with traditional multi-agent reinforcement learning baselines for multi-robot coordination.\n",
            "Score: 2\n",
            "\n",
            "Document: 568|||| \n",
            "'arxiv_id': arXiv:2407.09469, \n",
            "'paper_link': https://arxiv.org/abs/2407.09469, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.09469, \n",
            "Title: Learning Coordinated Maneuver in Adversarial Environments \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: This paper aims to solve the coordination of a team of robots traversing a route in the presence of adversaries with random positions. Our goal is to minimize the overall cost of the team, which is determined by (i) the accumulated risk when robots stay in adversary-impacted zones and (ii) the mission completion time. During traversal, robots can reduce their speed and act as a `guard' (the slower, the better), which will decrease the risks certain adversary incurs. This leads to a trade-off between the robots' guarding behaviors and their travel speeds. The formulated problem is highly non-convex and cannot be efficiently solved by existing algorithms. Our approach includes a theoretical analysis of the robots' behaviors for the single-adversary case. As the scale of the problem expands, solving the optimal solution using optimization approaches is challenging, therefore, we employ reinforcement learning techniques by developing new encoding and policy-generating methods. Simulations demonstrate that our learning methods can efficiently produce team coordination behaviors. We discuss the reasoning behind these behaviors and explain why they reduce the overall team cost.\n",
            "Score: 2\n",
            "\n",
            "Document: 580|||| \n",
            "'arxiv_id': arXiv:2407.18760, \n",
            "'paper_link': https://arxiv.org/abs/2407.18760, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.18760, \n",
            "Title: Java-Class-Hijack: Software Supply Chain Attack for Java based on Maven Dependency Resolution and Java Classloading \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: We introduce Java-Class-Hijack, a novel software supply chain attack that enables an attacker to inject malicious code by crafting a class that shadows a legitimate class that is in the dependency tree. We describe the attack, provide a proof-of-concept demonstrating its feasibility, and replicate it in the German Corona-Warn-App server application. The proof-of-concept illustrates how a transitive dependency deep within the dependency tree can hijack a class from a direct dependency and entirely alter its behavior, posing a significant security risk to Java applications. The replication on the Corona-Warn-App demonstrates how compromising a small JSON validation library could result in a complete database takeover.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 45\n",
        "score_floor = 2\n",
        "list_of_lists_of_weights = [[\n",
        "        (\"mental health\", 5),\n",
        "        (\"psychological health\", 5),\n",
        "        (\"psycholog\", 2),  # stem vs. lemma\n",
        "        (\"mental health care\", 3),\n",
        "        (\"neuroscience\", 2),\n",
        "        (\"psychological assessment\", 2),\n",
        "        (\"personality assessment\", 2),\n",
        "        (\"personality inference\", 2),\n",
        "        (\"personality traits\", 2),\n",
        "        (\"personality dimensions\", 2),\n",
        "        (\"emotion\", 15),\n",
        "        (\"sports psychology\", 15),\n",
        "        (\"sentiment recognition\", 10),\n",
        "        (\"Emotion Recognition\", 5),\n",
        "        # (\"\", 5),\n",
        "        # (\"\", 5),\n",
        "\n",
        "        # disease terms\n",
        "        (\"depression\", 5),\n",
        "        (\"anxiety\", 5),\n",
        "        (\"mental disorders\", 2),\n",
        "        (\"social anxiety disorder\", 4),\n",
        "        (\"mental illness\", 2),\n",
        "        (\"Major Depressive Disorder\", 2),\n",
        "        (\"MDD\", 2),\n",
        "        (\"psychological stressors\", 2),\n",
        "        (\"cognitive impairment\", 2),\n",
        "        (\"mci\", 2),\n",
        "        (\"personality\", 1)\n",
        "        # (\"\", 2),\n",
        "        ],]\n",
        "match_print_save(list_of_lists_of_weights, top_n, score_floor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CixuXw-Fl3-f",
        "outputId": "d2a99e9a-a7cd-4530-cbab-d4ed04bf30d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Set Name: mental health\n",
            "Total Matches in Set: 25\n",
            "Matches Above Score-Floor in Set: 24\n",
            "2024-08-22__131153783529\n",
            "\n",
            "Showing 24 in top-25 out of 25 total results.     -> 24 of 25/25\n",
            "(Ceiling set at 45 (top_n) filtered results.)    -> 45\n",
            "(Minimum-included-score, 'Score-Floor' set at 2) -> 2\n",
            "\n",
            "\n",
            "Document: 92|||| \n",
            "'arxiv_id': arXiv:2408.11288, \n",
            "'paper_link': https://arxiv.org/abs/2408.11288, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11288, \n",
            "Title: Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Large language models (LLMs) are emerging as promising tools for mental health care, offering scalable support through their ability to generate human-like responses. However, the effectiveness of these models in clinical settings remains unclear. This scoping review aimed to assess the current generative applications of LLMs in mental health care, focusing on studies where these models were tested with human participants in real-world scenarios. A systematic search across APA PsycNet, Scopus, PubMed, and Web of Science identified 726 unique articles, of which 17 met the inclusion criteria. These studies encompassed applications such as clinical assistance, counseling, therapy, and emotional support. However, the evaluation methods were often non-standardized, with most studies relying on ad hoc scales that limit comparability and robustness. Privacy, safety, and fairness were also frequently underexplored. Moreover, reliance on proprietary models, such as OpenAI's GPT series, raises concerns about transparency and reproducibility. While LLMs show potential in expanding mental health care access, especially in underserved areas, the current evidence does not fully support their use as standalone interventions. More rigorous, standardized evaluations and ethical oversight are needed to ensure these tools can be safely and effectively integrated into clinical practice.\n",
            "Score: 23\n",
            "\n",
            "Document: 20|||| \n",
            "'arxiv_id': arXiv:2408.11133, \n",
            "'paper_link': https://arxiv.org/abs/2408.11133, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11133, \n",
            "Title: Public Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey \n",
            "Subjects: Information Retrieval (cs.IR) \n",
            "Abstract: Countless disasters have resulted from climate change, causing severe damage to infrastructure and the economy. These disasters have significant societal impacts, necessitating mental health services for the millions affected. To prepare for and respond effectively to such events, it is important to understand people's emotions and the life incidents they experience before and after a disaster strikes. In this case study, we collected a dataset of approximately 400,000 public tweets related to the storm. Using a BERT-based model, we predicted the emotions associated with each tweet. To efficiently identify these topics, we utilized the Latent Dirichlet Allocation (LDA) technique for topic modeling, which allowed us to bypass manual content analysis and extract meaningful patterns from the data. However, rather than stopping at topic identification like previous methods \\cite{math11244910}, we further refined our analysis by integrating Graph Neural Networks (GNN) and Large Language Models (LLM). The GNN was employed to generate embeddings and construct a similarity graph of the tweets, which was then used to optimize clustering. Subsequently, we used an LLM to automatically generate descriptive names for each event cluster, offering critical insights for disaster preparedness and response strategies.\n",
            "Score: 20\n",
            "\n",
            "Document: 90|||| \n",
            "'arxiv_id': arXiv:2408.11286, \n",
            "'paper_link': https://arxiv.org/abs/2408.11286, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11286, \n",
            "Title: Video Emotion Open-vocabulary Recognition Based on Multimodal Large Language Model \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Multimodal emotion recognition is a task of great concern. However, traditional data sets are based on fixed labels, resulting in models that often focus on main emotions and ignore detailed emotional changes in complex scenes. This report introduces the solution of using MLLMs technology to generate open-vocabulary emotion labels from a video. The solution includes the use of framework, data generation and processing, training methods, results generation and multi-model co-judgment. In the MER-OV (Open-Word Emotion Recognition) of the MER2024 challenge, our method achieved significant advantages, leading to its superior capabilities in complex emotion computation.\n",
            "Score: 20\n",
            "\n",
            "Document: 438|||| \n",
            "'arxiv_id': arXiv:2309.11911, \n",
            "'paper_link': https://arxiv.org/abs/2309.11911, \n",
            "'pdf_link': https://arxiv.org/pdf/2309.11911, \n",
            "Title: InstructERC: Reforming Emotion Recognition in Conversation with Multi-task Retrieval-Augmented Large Language Models \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: The field of emotion recognition of conversation (ERC) has been focusing on separating sentence feature encoding and context modeling, lacking exploration in generative paradigms based on unified designs. In this study, we propose a novel approach, InstructERC, to reformulate the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs). InstructERC makes three significant contributions: (1) it introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information. (2) We introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. (3) Pioneeringly, we unify emotion labels across benchmarks through the feeling wheel to fit real application scenarios. InstructERC still perform impressively on this unified dataset. Our LLM-based plugin framework significantly outperforms all previous models and achieves comprehensive SOTA on three commonly used ERC datasets. Extensive analysis of parameter-efficient and data-scaling experiments provides empirical guidance for applying it in practical scenarios.\n",
            "Score: 20\n",
            "\n",
            "Document: 175|||| \n",
            "'arxiv_id': arXiv:2408.11424, \n",
            "'paper_link': https://arxiv.org/abs/2408.11424, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11424, \n",
            "Title: EMO-LLaMA: Enhancing Facial Emotion Understanding with Instruction Tuning \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: Facial expression recognition (FER) is an important research topic in emotional artificial intelligence. In recent decades, researchers have made remarkable progress. However, current FER paradigms face challenges in generalization, lack semantic information aligned with natural language, and struggle to process both images and videos within a unified framework, making their application in multimodal emotion understanding and human-computer interaction difficult. Multimodal Large Language Models (MLLMs) have recently achieved success, offering advantages in addressing these issues and potentially overcoming the limitations of current FER paradigms. However, directly applying pre-trained MLLMs to FER still faces several challenges. Our zero-shot evaluations of existing open-source MLLMs on FER indicate a significant performance gap compared to GPT-4V and current supervised state-of-the-art (SOTA) methods. In this paper, we aim to enhance MLLMs' capabilities in understanding facial expressions. We first generate instruction data for five FER datasets with Gemini. We then propose a novel MLLM, named EMO-LLaMA, which incorporates facial priors from a pretrained facial analysis network to enhance human facial information. Specifically, we design a Face Info Mining module to extract both global and local facial information. Additionally, we utilize a handcrafted prompt to introduce age-gender-race attributes, considering the emotional differences across different human groups. Extensive experiments show that EMO-LLaMA achieves SOTA-comparable or competitive results across both static and dynamic FER datasets. The instruction dataset and code are available at this https URL.\n",
            "Score: 15\n",
            "\n",
            "Document: 176|||| \n",
            "'arxiv_id': arXiv:2408.11426, \n",
            "'paper_link': https://arxiv.org/abs/2408.11426, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11426, \n",
            "Title: AS-LIO: Spatial Overlap Guided Adaptive Sliding Window LiDAR-Inertial Odometry for Aggressive FOV Variation \n",
            "Subjects: Robotics (cs.RO) \n",
            "Abstract: LiDAR-Inertial Odometry (LIO) demonstrates outstanding accuracy and stability in general low-speed and smooth motion scenarios. However, in high-speed and intense motion scenarios, such as sharp turns, two primary challenges arise: firstly, due to the limitations of IMU frequency, the error in estimating significantly non-linear motion states escalates; secondly, drastic changes in the Field of View (FOV) may diminish the spatial overlap between LiDAR frame and pointcloud map (or between frames), leading to insufficient data association and constraint degradation.\n",
            "To address these issues, we propose a novel Adaptive Sliding window LIO framework (AS-LIO) guided by the Spatial Overlap Degree (SOD). Initially, we assess the SOD between the LiDAR frames and the registered map, directly evaluating the adverse impact of current FOV variation on pointcloud alignment. Subsequently, we design an adaptive sliding window to manage the continuous LiDAR stream and control state updates, dynamically adjusting the update step according to the SOD. This strategy enables our odometry to adaptively adopt higher update frequency to precisely characterize trajectory during aggressive FOV variation, thus effectively reducing the non-linear error in positioning. Meanwhile, the historical constraints within the sliding window reinforce the frame-to-map data association, ensuring the robustness of state estimation. Experiments show that our AS-LIO framework can quickly perceive and respond to challenging FOV change, outperforming other state-of-the-art LIO frameworks in terms of accuracy and robustness.\n",
            "Score: 15\n",
            "\n",
            "Document: 228|||| \n",
            "'arxiv_id': arXiv:2408.11518, \n",
            "'paper_link': https://arxiv.org/abs/2408.11518, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11518, \n",
            "Title: EmoFace: Emotion-Content Disentangled Speech-Driven 3D Talking Face with Mesh Attention \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The creation of increasingly vivid 3D virtual digital humans has become a hot topic in recent years. Currently, most speech-driven work focuses on training models to learn the relationship between phonemes and visemes to achieve more realistic lips. However, they fail to capture the correlations between emotions and facial expressions effectively. To solve this problem, we propose a new model, termed EmoFace. EmoFace employs a novel Mesh Attention mechanism, which helps to learn potential feature dependencies between mesh vertices in time and space. We also adopt, for the first time to our knowledge, an effective self-growing training scheme that combines teacher-forcing and scheduled sampling in a 3D face animation task. Additionally, since EmoFace is an autoregressive model, there is no requirement that the first frame of the training data must be a silent frame, which greatly reduces the data limitations and contributes to solve the current dilemma of insufficient datasets. Comprehensive quantitative and qualitative evaluations on our proposed high-quality reconstructed 3D emotional facial animation dataset, 3D-RAVDESS ($5.0343\\times 10^{-5}$mm for LVE and $1.0196\\times 10^{-5}$mm for EVE), and publicly available dataset VOCASET ($2.8669\\times 10^{-5}$mm for LVE and $0.4664\\times 10^{-5}$mm for EVE), demonstrate that our algorithm achieves state-of-the-art performance.\n",
            "Score: 15\n",
            "\n",
            "Document: 271|||| \n",
            "'arxiv_id': arXiv:2408.11599, \n",
            "'paper_link': https://arxiv.org/abs/2408.11599, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11599, \n",
            "Title: Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Empathetic response generation endows agents with the capability to comprehend dialogue contexts and react to expressed emotions. Previous works predominantly focus on leveraging the speaker's emotional labels, but ignore the importance of emotion cause reasoning in empathetic response generation, which hinders the model's capacity for further affective understanding and cognitive inference. In this paper, we propose a cause-aware empathetic generation approach by integrating emotions and causes through a well-designed Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can greatly promote LLMs' performance of empathy by instruction tuning and enhancing the role awareness of an empathetic listener in the prompt. Additionally, we propose to incorporate cause-oriented external knowledge from COMET into the prompt, which improves the diversity of generation and alleviates conflicts between internal and external knowledge at the same time. Experimental results on the benchmark dataset demonstrate that our approach on LLaMA-7b achieves state-of-the-art performance in both automatic and human evaluations.\n",
            "Score: 15\n",
            "\n",
            "Document: 275|||| \n",
            "'arxiv_id': arXiv:2408.11608, \n",
            "'paper_link': https://arxiv.org/abs/2408.11608, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11608, \n",
            "Title: Don't Kill the Baby: The Case for AI in Arbitration \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: Since the introduction of Generative AI (GenAI) in 2022, its ability to simulate human intelligence and generate content has sparked both enthusiasm and concern. While much criticism focuses on AI's potential to perpetuate bias, create emotional dissonance, displace jobs, and raise ethical questions, these concerns often overlook the practical benefits of AI, particularly in legal contexts.\n",
            "This article examines the integration of AI into arbitration, arguing that the Federal Arbitration Act (FAA) allows parties to contractually choose AI-driven arbitration, despite traditional reservations. The article makes three key contributions: (1) It shifts the focus from debates over AI's personhood to the practical aspects of incorporating AI into arbitration, asserting that AI can effectively serve as an arbitrator if both parties agree; (2) It positions arbitration as an ideal starting point for broader AI adoption in the legal field, given its flexibility and the autonomy it grants parties to define their standards of fairness; and (3) It outlines future research directions, emphasizing the importance of empirically comparing AI and human arbitration, which could lead to the development of distinct systems.\n",
            "By advocating for the use of AI in arbitration, this article underscores the importance of respecting contractual autonomy and creating an environment that allows AI's potential to be fully realized. Drawing on the insights of Judge Richard Posner, the article argues that the ethical obligations of AI in arbitration should be understood within the context of its technological strengths and the voluntary nature of arbitration agreements. Ultimately, it calls for a balanced, open-minded approach to AI in arbitration, recognizing its potential to enhance the efficiency, fairness, and flexibility of dispute resolution\n",
            "Score: 15\n",
            "\n",
            "Document: 340|||| \n",
            "'arxiv_id': arXiv:2408.11769, \n",
            "'paper_link': https://arxiv.org/abs/2408.11769, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11769, \n",
            "Title: Decoding Pedestrian Stress on Urban Streets using Electrodermal Activity Monitoring in Virtual Immersive Reality \n",
            "Subjects: Computers and Society (cs.CY) \n",
            "Abstract: The pedestrian stress level is shown to significantly influence human cognitive processes and, subsequently, decision-making, e.g., the decision to select a gap and cross a street. This paper systematically studies the stress experienced by a pedestrian when crossing a street under different experimental manipulations by monitoring the ElectroDermal Activity (EDA) using the Galvanic Skin Response (GSR) sensor. To fulfil the research objectives, a dynamic and immersive virtual reality (VR) platform was used, which is suitable for eliciting and capturing pedestrian's emotional responses in conjunction with monitoring their EDA. A total of 171 individuals participated in the experiment, tasked to cross a two-way street at mid-block with no signal control. Mixed effects models were employed to compare the influence of socio-demographics, social influence, vehicle technology, environment, road design, and traffic variables on the stress levels of the participants. The results indicated that having a street median in the middle of the road operates as a refuge and significantly reduced stress. Younger participants were (18-24 years) calmer than the relatively older participants (55-65 years). Arousal levels were higher when it came to the characteristics of the avatar (virtual pedestrian) in the simulation, especially for those avatars with adventurous traits. The pedestrian location influenced stress since the stress was higher on the street while crossing than waiting on the sidewalk. Significant causes of arousal were fear of accidents and an actual accident for pedestrians. The estimated random effects show a high degree of physical and mental learning by the participants while going through the scenarios.\n",
            "Score: 15\n",
            "\n",
            "Document: 422|||| \n",
            "'arxiv_id': arXiv:2304.01716, \n",
            "'paper_link': https://arxiv.org/abs/2304.01716, \n",
            "'pdf_link': https://arxiv.org/pdf/2304.01716, \n",
            "Title: Decoupling Dynamic Monocular Videos for Dynamic View Synthesis \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: The challenge of dynamic view synthesis from dynamic monocular videos, i.e., synthesizing novel views for free viewpoints given a monocular video of a dynamic scene captured by a moving camera, mainly lies in accurately modeling the \\textbf{dynamic objects} of a scene using limited 2D frames, each with a varying timestamp and viewpoint. Existing methods usually require pre-processed 2D optical flow and depth maps by off-the-shelf methods to supervise the network, making them suffer from the inaccuracy of the pre-processed supervision and the ambiguity when lifting the 2D information to 3D. In this paper, we tackle this challenge in an unsupervised fashion. Specifically, we decouple the motion of the dynamic objects into object motion and camera motion, respectively regularized by proposed unsupervised surface consistency and patch-based multi-view constraints. The former enforces the 3D geometric surfaces of moving objects to be consistent over time, while the latter regularizes their appearances to be consistent across different viewpoints. Such a fine-grained motion formulation can alleviate the learning difficulty for the network, thus enabling it to produce not only novel views with higher quality but also more accurate scene flows and depth than existing methods requiring extra supervision.\n",
            "Score: 15\n",
            "\n",
            "Document: 552|||| \n",
            "'arxiv_id': arXiv:2406.17758, \n",
            "'paper_link': https://arxiv.org/abs/2406.17758, \n",
            "'pdf_link': https://arxiv.org/pdf/2406.17758, \n",
            "Title: MotionBooth: Motion-Aware Customized Text-to-Video Generation \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: In this work, we present MotionBooth, an innovative framework designed for animating customized subjects with precise control over both object and camera movements. By leveraging a few images of a specific object, we efficiently fine-tune a text-to-video model to capture the object's shape and attributes accurately. Our approach presents subject region loss and video preservation loss to enhance the subject's learning performance, along with a subject token cross-attention loss to integrate the customized subject with motion control signals. Additionally, we propose training-free techniques for managing subject and camera motions during inference. In particular, we utilize cross-attention map manipulation to govern subject motion and introduce a novel latent shift module for camera movement control as well. MotionBooth excels in preserving the appearance of subjects while simultaneously controlling the motions in generated videos. Extensive quantitative and qualitative evaluations demonstrate the superiority and effectiveness of our method. Our project page is at this https URL\n",
            "Score: 15\n",
            "\n",
            "Document: 579|||| \n",
            "'arxiv_id': arXiv:2407.16344, \n",
            "'paper_link': https://arxiv.org/abs/2407.16344, \n",
            "'pdf_link': https://arxiv.org/pdf/2407.16344, \n",
            "Title: SOAP: Enhancing Spatio-Temporal Relation and Motion Information Capturing for Few-Shot Action Recognition \n",
            "Subjects: Computer Vision and Pattern Recognition (cs.CV) \n",
            "Abstract: High frame-rate (HFR) videos of action recognition improve fine-grained expression while reducing the spatio-temporal relation and motion information density. Thus, large amounts of video samples are continuously required for traditional data-driven training. However, samples are not always sufficient in real-world scenarios, promoting few-shot action recognition (FSAR) research. We observe that most recent FSAR works build spatio-temporal relation of video samples via temporal alignment after spatial feature extraction, cutting apart spatial and temporal features within samples. They also capture motion information via narrow perspectives between adjacent frames without considering density, leading to insufficient motion information capturing. Therefore, we propose a novel plug-and-play architecture for FSAR called Spatio-tempOral frAme tuPle enhancer (SOAP) in this paper. The model we designed with such architecture refers to SOAP-Net. Temporal connections between different feature channels and spatio-temporal relation of features are considered instead of simple feature extraction. Comprehensive motion information is also captured, using frame tuples with multiple frames containing more motion information than adjacent frames. Combining frame tuples of diverse frame counts further provides a broader perspective. SOAP-Net achieves new state-of-the-art performance across well-known benchmarks such as SthSthV2, Kinetics, UCF101, and HMDB51. Extensive empirical evaluations underscore the competitiveness, pluggability, generalization, and robustness of SOAP. The code is released at this https URL.\n",
            "Score: 15\n",
            "\n",
            "Document: 459|||| \n",
            "'arxiv_id': arXiv:2401.02984, \n",
            "'paper_link': https://arxiv.org/abs/2401.02984, \n",
            "'pdf_link': https://arxiv.org/pdf/2401.02984, \n",
            "Title: Large Language Models in Mental Health Care: a Scoping Review \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: The integration of large language models (LLMs) in mental health care is an emerging field. There is a need to systematically review the application outcomes and delineate the advantages and limitations in clinical settings. This review aims to provide a comprehensive overview of the use of LLMs in mental health care, assessing their efficacy, challenges, and potential for future applications. A systematic search was conducted across multiple databases including PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and PsyArXiv in November 2023. All forms of original research, peer-reviewed or not, published or disseminated between October 1, 2019, and December 2, 2023, are included without language restrictions if they used LLMs developed after T5 and directly addressed research questions in mental health care settings. From an initial pool of 313 articles, 34 met the inclusion criteria based on their relevance to LLM application in mental health care and the robustness of reported outcomes. Diverse applications of LLMs in mental health care are identified, including diagnosis, therapy, patient engagement enhancement, etc. Key challenges include data availability and reliability, nuanced handling of mental states, and effective evaluation methods. Despite successes in accuracy and accessibility improvement, gaps in clinical applicability and ethical considerations were evident, pointing to the need for robust data, standardized evaluations, and interdisciplinary collaboration. LLMs hold substantial promise for enhancing mental health care. For their full potential to be realized, emphasis must be placed on developing robust datasets, development and evaluation frameworks, ethical guidelines, and interdisciplinary collaborations to address current limitations.\n",
            "Score: 8\n",
            "\n",
            "Document: 170|||| \n",
            "'arxiv_id': arXiv:2408.11415, \n",
            "'paper_link': https://arxiv.org/abs/2408.11415, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11415, \n",
            "Title: Towards \"Differential AI Psychology\" and in-context Value-driven Statement Alignment with Moral Foundations Theory \n",
            "Subjects: Computation and Language (cs.CL) \n",
            "Abstract: Contemporary research in social sciences is increasingly utilizing state-of-the-art statistical language models to annotate or generate content. While these models perform benchmark-leading on common language tasks and show exemplary task-independent emergent abilities, transferring them to novel out-of-domain tasks is only insufficiently explored. The implications of the statistical black-box approach - stochastic parrots - are prominently criticized in the language model research community; however, the significance for novel generative tasks is not.\n",
            "This work investigates the alignment between personalized language models and survey participants on a Moral Foundation Theory questionnaire. We adapt text-to-text models to different political personas and survey the questionnaire repetitively to generate a synthetic population of persona and model combinations. Analyzing the intra-group variance and cross-alignment shows significant differences across models and personas. Our findings indicate that adapted models struggle to represent the survey-captured assessment of political ideologies. Thus, using language models to mimic social interactions requires measurable improvements in in-context optimization or parameter manipulation to align with psychological and sociological stereotypes. Without quantifiable alignment, generating politically nuanced content remains unfeasible. To enhance these representations, we propose a testable framework to generate agents based on moral value statements for future research.\n",
            "Score: 2\n",
            "\n",
            "Document: 262|||| \n",
            "'arxiv_id': arXiv:2408.11583, \n",
            "'paper_link': https://arxiv.org/abs/2408.11583, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11583, \n",
            "Title: Constructions of Efficiently Implementable Boolean functions Possessing High Nonlinearity and Good Resistance to Algebraic Attacks \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: We describe two new classes of functions which provide the presently best known trade-offs between low computational complexity, nonlinearity and (fast) algebraic immunity. The nonlinearity and (fast) algebraic immunity of the new functions substantially improve upon those properties of all previously known efficiently implementable functions. Appropriately chosen functions from the two new classes provide excellent solutions to the problem of designing filtering functions for use in the nonlinear filter model of stream ciphers, or in any other stream ciphers using Boolean functions for ensuring confusion. In particular, for $n\\leq 20$, we show that there are functions in our first family whose implementation efficiences are significantly lower than all previously known functions achieving a comparable combination of nonlinearity and (fast) algebraic immunity. Given positive integers $\\ell$ and $\\delta$, it is possible to choose a function from our second family whose linear bias is provably at most $2^{-\\ell}$, fast algebraic immunity is at least $\\delta$ (based on conjecture which is well supported by experimental results), and which can be implemented in time and space which is linear in $\\ell$ and $\\delta$. Further, the functions in our second family are built using homomorphic friendly operations, making these functions well suited for the application of transciphering.\n",
            "Score: 2\n",
            "\n",
            "Document: 263|||| \n",
            "'arxiv_id': arXiv:2408.11584, \n",
            "'paper_link': https://arxiv.org/abs/2408.11584, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11584, \n",
            "Title: Characterizing the Evolution of Psychological Factors Exploited by Malicious Emails \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: Cyber attacks, including cyber social engineering attacks, such as malicious emails, are always evolving with time. Thus, it is important to understand their evolution. In this paper we characterize the evolution of malicious emails through the lens of Psychological Factors, PFs, which are humans psychological attributes that can be exploited by malicious emails. That is, attackers who send them. For this purpose, we propose a methodology and apply it to conduct a case study on 1,260 malicious emails over a span of 21 years, 2004 to 2024. Our findings include attackers have been constantly seeking to exploit many PFs, especially the ones that reflect human traits. Attackers have been increasingly exploiting 9 PFs and mostly in an implicit or stealthy fashion. Some PFs are often exploited together. These insights shed light on how to design future defenses against malicious emails.\n",
            "Score: 2\n",
            "\n",
            "Document: 264|||| \n",
            "'arxiv_id': arXiv:2408.11586, \n",
            "'paper_link': https://arxiv.org/abs/2408.11586, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11586, \n",
            "Title: Characterizing the Evolution of Psychological Tactics and Techniques Exploited by Malicious Emails \n",
            "Subjects: Cryptography and Security (cs.CR) \n",
            "Abstract: The landscape of malicious emails and cyber social engineering attacks in general are constantly evolving. In order to design effective defenses against these attacks, we must deeply understand the Psychological Tactics, PTacs, and Psychological Techniques, PTechs, that are exploited by these attacks. In this paper we present a methodology for characterizing the evolution of PTacs and PTechs exploited by malicious emails. As a case study, we apply the methodology to a real-world dataset. This leads to a number insights, such as which PTacs or PTechs are more often exploited than others. These insights shed light on directions for future research towards designing psychologically-principled solutions to effectively counter malicious emails.\n",
            "Score: 2\n",
            "\n",
            "Document: 323|||| \n",
            "'arxiv_id': arXiv:2408.11744, \n",
            "'paper_link': https://arxiv.org/abs/2408.11744, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11744, \n",
            "Title: JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet \n",
            "Subjects: Artificial Intelligence (cs.AI) \n",
            "Abstract: This study proposes a novel approach to extract stylistic features of Jiehua: the utilization of the Fine-tuned Stable Diffusion Model with ControlNet (FSDMC) to refine depiction techniques from artists' Jiehua. The training data for FSDMC is based on the opensource Jiehua artist's work collected from the Internet, which were subsequently manually constructed in the format of (Original Image, Canny Edge Features, Text Prompt). By employing the optimal hyperparameters identified in this paper, it was observed FSDMC outperforms CycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27 on the dataset and also surpasses CycleGAN in terms of expert evaluation. This not only demonstrates the model's high effectiveness in extracting Jiehua's style features, but also preserves the original pre-trained semantic information. The findings of this study suggest that the application of FSDMC with appropriate hyperparameters can enhance the efficacy of the Stable Diffusion Model in the field of traditional art style migration tasks, particularly within the context of Jiehua.\n",
            "Score: 2\n",
            "\n",
            "Document: 378|||| \n",
            "'arxiv_id': arXiv:2408.11201, \n",
            "'paper_link': https://arxiv.org/abs/2408.11201, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11201, \n",
            "Title: Exact spectral gaps of random one-dimensional quantum circuits \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: The spectral gap of local random quantum circuits is a fundamental property that determines how close the moments of the circuit's unitaries match those of a Haar random distribution. When studying spectral gaps, it is common to bound these quantities using tools from statistical mechanics or via quantum information-based inequalities. By focusing on the second moment of one-dimensional unitary circuits where nearest neighboring gates act on sets of qudits (with open and closed boundary conditions), we show that one can exactly compute the associated spectral gaps. Indeed, having access to their functional form allows us to prove several important results, such as the fact that the spectral gap for closed boundary condition is exactly the square of the gap for open boundaries, as well as improve on previously known bounds for approximate design convergence. Finally, we verify our theoretical results by numerically computing the spectral gap for systems of up to 70 qubits, as well as comparing them to gaps of random orthogonal and symplectic circuits.\n",
            "Score: 2\n",
            "\n",
            "Document: 399|||| \n",
            "'arxiv_id': arXiv:2408.11754, \n",
            "'paper_link': https://arxiv.org/abs/2408.11754, \n",
            "'pdf_link': https://arxiv.org/pdf/2408.11754, \n",
            "Title: Improving the Scan-rescan Precision of AI-based CMR Biomarker Estimation \n",
            "Subjects: Quantitative Methods (q-bio.QM) \n",
            "Abstract: Quantification of cardiac biomarkers from cine cardiovascular magnetic resonance (CMR) data using deep learning (DL) methods offers many advantages, such as increased accuracy and faster analysis. However, only a few studies have focused on the scan-rescan precision of the biomarker estimates, which is important for reproducibility and longitudinal analysis. Here, we propose a cardiac biomarker estimation pipeline that not only focuses on achieving high segmentation accuracy but also on improving the scan-rescan precision of the computed biomarkers, namely left and right ventricular ejection fraction, and left ventricular myocardial mass. We evaluate two approaches to improve the apical-basal resolution of the segmentations used for estimating the biomarkers: one based on image interpolation and one based on segmentation interpolation. Using a database comprising scan-rescan cine CMR data acquired from 92 subjects, we compare the performance of these two methods against ground truth (GT) segmentations and DL segmentations obtained before interpolation (baseline). The results demonstrate that both the image-based and segmentation-based interpolation methods were able to narrow Bland-Altman scan-rescan confidence intervals for all biomarkers compared to the GT and baseline performances. Our findings highlight the importance of focusing not only on segmentation accuracy but also on the consistency of biomarkers across repeated scans, which is crucial for longitudinal analysis of cardiac function.\n",
            "Score: 2\n",
            "\n",
            "Document: 418|||| \n",
            "'arxiv_id': arXiv:2303.11081, \n",
            "'paper_link': https://arxiv.org/abs/2303.11081, \n",
            "'pdf_link': https://arxiv.org/pdf/2303.11081, \n",
            "Title: Provably Convergent Subgraph-wise Sampling for Fast GNN Training \n",
            "Subjects: Machine Learning (cs.LG) \n",
            "Abstract: Subgraph-wise sampling -- a promising class of mini-batch training techniques for graph neural networks (GNNs -- is critical for real-world applications. During the message passing (MP) in GNNs, subgraph-wise sampling methods discard messages outside the mini-batches in backward passes to avoid the well-known neighbor explosion problem, i.e., the exponentially increasing dependencies of nodes with the number of MP iterations. However, discarding messages may sacrifice the gradient estimation accuracy, posing significant challenges to their convergence analysis and convergence speeds. To address this challenge, we propose a novel subgraph-wise sampling method with a convergence guarantee, namely Local Message Compensation (LMC). To the best of our knowledge, LMC is the first subgraph-wise sampling method with provable convergence. The key idea is to retrieve the discarded messages in backward passes based on a message passing formulation of backward passes. By efficient and effective compensations for the discarded messages in both forward and backward passes, LMC computes accurate mini-batch gradients and thus accelerates convergence. Moreover, LMC is applicable to various MP-based GNN architectures, including convolutional GNNs (finite message passing iterations with different layers) and recurrent GNNs (infinite message passing iterations with a shared layer). Experiments on large-scale benchmarks demonstrate that LMC is significantly faster than state-of-the-art subgraph-wise sampling methods.\n",
            "Score: 2\n",
            "\n",
            "Document: 443|||| \n",
            "'arxiv_id': arXiv:2310.08342, \n",
            "'paper_link': https://arxiv.org/abs/2310.08342, \n",
            "'pdf_link': https://arxiv.org/pdf/2310.08342, \n",
            "Title: Discontinuous Galerkin approximations of the heterodimer model for protein-protein interaction \n",
            "Subjects: Numerical Analysis (math.NA) \n",
            "Abstract: Mathematical models of protein-protein dynamics, such as the heterodimer model, play a crucial role in understanding many physical phenomena. This model is a system of two semilinear parabolic partial differential equations describing the evolution and mutual interaction of biological species. An example is the neurodegenerative disease progression in some significant pathologies, such as Alzheimer's and Parkinson's diseases, characterized by the accumulation and propagation of toxic prionic proteins. This article presents and analyzes a flexible high-order discretization method for the numerical approximation of the heterodimer model. We propose a space discretization based on a Discontinuous Galerkin method on polygonal/polyhedral grids, which provides flexibility in handling complex geometries. Concerning the semi-discrete formulation, we prove stability and a-priori error estimates for the first time. Next, we adopt a $\\theta$-method scheme as a time integration scheme. Convergence tests are carried out to demonstrate the theoretical bounds and the ability of the method to approximate traveling wave solutions, considering also complex geometries such as brain sections reconstructed from medical images. Finally, the proposed scheme is tested in a practical test case stemming from neuroscience applications, namely the simulation of the spread of $\\alpha$-synuclein in a realistic test case of Parkinson's disease in a two-dimensional sagittal brain section geometry reconstructed from medical images.\n",
            "Score: 2\n",
            "\n",
            "Document: 654|||| \n",
            "'arxiv_id': arXiv:2404.03619, \n",
            "'paper_link': https://arxiv.org/abs/2404.03619, \n",
            "'pdf_link': https://arxiv.org/pdf/2404.03619, \n",
            "Title: Circuit Knitting Faces Exponential Sampling Overhead Scaling Bounded by Entanglement Cost \n",
            "Subjects: Quantum Physics (quant-ph) \n",
            "Abstract: Circuit knitting, a method for connecting quantum circuits across multiple processors to simulate nonlocal quantum operations, is a promising approach for distributed quantum computing. While various techniques have been developed for circuit knitting, we uncover fundamental limitations to the scalability of this technology. We prove that the sampling overhead of circuit knitting is exponentially lower bounded by the exact entanglement cost of the target bipartite dynamic, even for asymptotic overhead in the parallel cut regime. Specifically, we prove that the regularized sampling overhead assisted with local operations and classical communication (LOCC), of any bipartite quantum channel is lower bounded by the exponential of its exact entanglement cost under separable preserving operations. Furthermore, we show that the regularized sampling overhead for simulating a general bipartite channel via LOCC is lower bounded by $\\kappa$-entanglement and max-Rains information, providing efficiently computable benchmarks. Our work reveals a profound connection between virtual quantum information processing via quasi-probability decomposition and quantum Shannon theory, highlighting the critical role of entanglement in distributed quantum computing.\n",
            "Score: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Timer"
      ],
      "metadata": {
        "id": "BBVy06WenHk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end_time_whole_single_task = datetime.now()\n",
        "duration_time = duration_min_sec(start_time_whole_single_task, end_time_whole_single_task)\n",
        "print(f\"Duration to run -> {duration_time}\")"
      ],
      "metadata": {
        "id": "cCnRP_8anHbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cfcacb-0fc7-40c9-cc79-30f2b05a697a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to run -> 0_min__7.3_sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See files\n",
        "!ls"
      ],
      "metadata": {
        "id": "B7IHdEI-v2jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17291c9-ba90-4327-893a-233eb6870431"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' collective behavior_articles2024-08-22__131153711984.html'\n",
            "' collective behavior_articles_2024-08-22__131153711984.json'\n",
            "'distance measure_articles2024-08-22__131153088196.html'\n",
            "'distance measure_articles_2024-08-22__131153088196.json'\n",
            "'Manifold Approximation_articles2024-08-22__131152718331.html'\n",
            "'Manifold Approximation_articles_2024-08-22__131152718331.json'\n",
            "'mental health_articles2024-08-22__131154056098.html'\n",
            "'mental health_articles_2024-08-22__131154056098.json'\n",
            " sample_data\n",
            " survey_articles2024-08-22__131153372715.html\n",
            " survey_articles_2024-08-22__131153372715.json\n"
          ]
        }
      ]
    }
  ]
}